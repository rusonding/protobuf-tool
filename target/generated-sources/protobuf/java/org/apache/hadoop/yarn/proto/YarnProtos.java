// Generated by the protocol buffer compiler.  DO NOT EDIT!
// source: yarn_protos.proto

package org.apache.hadoop.yarn.proto;

public final class YarnProtos {
  private YarnProtos() {}
  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistryLite registry) {
  }

  public static void registerAllExtensions(
      com.google.protobuf.ExtensionRegistry registry) {
    registerAllExtensions(
        (com.google.protobuf.ExtensionRegistryLite) registry);
  }
  /**
   * Protobuf enum {@code hadoop.yarn.ContainerStateProto}
   */
  public enum ContainerStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>C_NEW = 1;</code>
     */
    C_NEW(1),
    /**
     * <code>C_RUNNING = 2;</code>
     */
    C_RUNNING(2),
    /**
     * <code>C_COMPLETE = 3;</code>
     */
    C_COMPLETE(3),
    ;

    /**
     * <code>C_NEW = 1;</code>
     */
    public static final int C_NEW_VALUE = 1;
    /**
     * <code>C_RUNNING = 2;</code>
     */
    public static final int C_RUNNING_VALUE = 2;
    /**
     * <code>C_COMPLETE = 3;</code>
     */
    public static final int C_COMPLETE_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ContainerStateProto valueOf(int value) {
      return forNumber(value);
    }

    public static ContainerStateProto forNumber(int value) {
      switch (value) {
        case 1: return C_NEW;
        case 2: return C_RUNNING;
        case 3: return C_COMPLETE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ContainerStateProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerStateProto>() {
            public ContainerStateProto findValueByNumber(int number) {
              return ContainerStateProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(0);
    }

    private static final ContainerStateProto[] VALUES = values();

    public static ContainerStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ContainerStateProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.YarnApplicationStateProto}
   */
  public enum YarnApplicationStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NEW = 1;</code>
     */
    NEW(1),
    /**
     * <code>NEW_SAVING = 2;</code>
     */
    NEW_SAVING(2),
    /**
     * <code>SUBMITTED = 3;</code>
     */
    SUBMITTED(3),
    /**
     * <code>ACCEPTED = 4;</code>
     */
    ACCEPTED(4),
    /**
     * <code>RUNNING = 5;</code>
     */
    RUNNING(5),
    /**
     * <code>FINISHED = 6;</code>
     */
    FINISHED(6),
    /**
     * <code>FAILED = 7;</code>
     */
    FAILED(7),
    /**
     * <code>KILLED = 8;</code>
     */
    KILLED(8),
    ;

    /**
     * <code>NEW = 1;</code>
     */
    public static final int NEW_VALUE = 1;
    /**
     * <code>NEW_SAVING = 2;</code>
     */
    public static final int NEW_SAVING_VALUE = 2;
    /**
     * <code>SUBMITTED = 3;</code>
     */
    public static final int SUBMITTED_VALUE = 3;
    /**
     * <code>ACCEPTED = 4;</code>
     */
    public static final int ACCEPTED_VALUE = 4;
    /**
     * <code>RUNNING = 5;</code>
     */
    public static final int RUNNING_VALUE = 5;
    /**
     * <code>FINISHED = 6;</code>
     */
    public static final int FINISHED_VALUE = 6;
    /**
     * <code>FAILED = 7;</code>
     */
    public static final int FAILED_VALUE = 7;
    /**
     * <code>KILLED = 8;</code>
     */
    public static final int KILLED_VALUE = 8;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static YarnApplicationStateProto valueOf(int value) {
      return forNumber(value);
    }

    public static YarnApplicationStateProto forNumber(int value) {
      switch (value) {
        case 1: return NEW;
        case 2: return NEW_SAVING;
        case 3: return SUBMITTED;
        case 4: return ACCEPTED;
        case 5: return RUNNING;
        case 6: return FINISHED;
        case 7: return FAILED;
        case 8: return KILLED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        YarnApplicationStateProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<YarnApplicationStateProto>() {
            public YarnApplicationStateProto findValueByNumber(int number) {
              return YarnApplicationStateProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(1);
    }

    private static final YarnApplicationStateProto[] VALUES = values();

    public static YarnApplicationStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private YarnApplicationStateProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.YarnApplicationStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.YarnApplicationAttemptStateProto}
   */
  public enum YarnApplicationAttemptStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APP_ATTEMPT_NEW = 1;</code>
     */
    APP_ATTEMPT_NEW(1),
    /**
     * <code>APP_ATTEMPT_SUBMITTED = 2;</code>
     */
    APP_ATTEMPT_SUBMITTED(2),
    /**
     * <code>APP_ATTEMPT_SCHEDULED = 3;</code>
     */
    APP_ATTEMPT_SCHEDULED(3),
    /**
     * <code>APP_ATTEMPT_ALLOCATED_SAVING = 4;</code>
     */
    APP_ATTEMPT_ALLOCATED_SAVING(4),
    /**
     * <code>APP_ATTEMPT_ALLOCATED = 5;</code>
     */
    APP_ATTEMPT_ALLOCATED(5),
    /**
     * <code>APP_ATTEMPT_LAUNCHED = 6;</code>
     */
    APP_ATTEMPT_LAUNCHED(6),
    /**
     * <code>APP_ATTEMPT_FAILED = 7;</code>
     */
    APP_ATTEMPT_FAILED(7),
    /**
     * <code>APP_ATTEMPT_RUNNING = 8;</code>
     */
    APP_ATTEMPT_RUNNING(8),
    /**
     * <code>APP_ATTEMPT_FINISHING = 9;</code>
     */
    APP_ATTEMPT_FINISHING(9),
    /**
     * <code>APP_ATTEMPT_FINISHED = 10;</code>
     */
    APP_ATTEMPT_FINISHED(10),
    /**
     * <code>APP_ATTEMPT_KILLED = 11;</code>
     */
    APP_ATTEMPT_KILLED(11),
    ;

    /**
     * <code>APP_ATTEMPT_NEW = 1;</code>
     */
    public static final int APP_ATTEMPT_NEW_VALUE = 1;
    /**
     * <code>APP_ATTEMPT_SUBMITTED = 2;</code>
     */
    public static final int APP_ATTEMPT_SUBMITTED_VALUE = 2;
    /**
     * <code>APP_ATTEMPT_SCHEDULED = 3;</code>
     */
    public static final int APP_ATTEMPT_SCHEDULED_VALUE = 3;
    /**
     * <code>APP_ATTEMPT_ALLOCATED_SAVING = 4;</code>
     */
    public static final int APP_ATTEMPT_ALLOCATED_SAVING_VALUE = 4;
    /**
     * <code>APP_ATTEMPT_ALLOCATED = 5;</code>
     */
    public static final int APP_ATTEMPT_ALLOCATED_VALUE = 5;
    /**
     * <code>APP_ATTEMPT_LAUNCHED = 6;</code>
     */
    public static final int APP_ATTEMPT_LAUNCHED_VALUE = 6;
    /**
     * <code>APP_ATTEMPT_FAILED = 7;</code>
     */
    public static final int APP_ATTEMPT_FAILED_VALUE = 7;
    /**
     * <code>APP_ATTEMPT_RUNNING = 8;</code>
     */
    public static final int APP_ATTEMPT_RUNNING_VALUE = 8;
    /**
     * <code>APP_ATTEMPT_FINISHING = 9;</code>
     */
    public static final int APP_ATTEMPT_FINISHING_VALUE = 9;
    /**
     * <code>APP_ATTEMPT_FINISHED = 10;</code>
     */
    public static final int APP_ATTEMPT_FINISHED_VALUE = 10;
    /**
     * <code>APP_ATTEMPT_KILLED = 11;</code>
     */
    public static final int APP_ATTEMPT_KILLED_VALUE = 11;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static YarnApplicationAttemptStateProto valueOf(int value) {
      return forNumber(value);
    }

    public static YarnApplicationAttemptStateProto forNumber(int value) {
      switch (value) {
        case 1: return APP_ATTEMPT_NEW;
        case 2: return APP_ATTEMPT_SUBMITTED;
        case 3: return APP_ATTEMPT_SCHEDULED;
        case 4: return APP_ATTEMPT_ALLOCATED_SAVING;
        case 5: return APP_ATTEMPT_ALLOCATED;
        case 6: return APP_ATTEMPT_LAUNCHED;
        case 7: return APP_ATTEMPT_FAILED;
        case 8: return APP_ATTEMPT_RUNNING;
        case 9: return APP_ATTEMPT_FINISHING;
        case 10: return APP_ATTEMPT_FINISHED;
        case 11: return APP_ATTEMPT_KILLED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<YarnApplicationAttemptStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        YarnApplicationAttemptStateProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<YarnApplicationAttemptStateProto>() {
            public YarnApplicationAttemptStateProto findValueByNumber(int number) {
              return YarnApplicationAttemptStateProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(2);
    }

    private static final YarnApplicationAttemptStateProto[] VALUES = values();

    public static YarnApplicationAttemptStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private YarnApplicationAttemptStateProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.YarnApplicationAttemptStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.FinalApplicationStatusProto}
   */
  public enum FinalApplicationStatusProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APP_UNDEFINED = 0;</code>
     */
    APP_UNDEFINED(0),
    /**
     * <code>APP_SUCCEEDED = 1;</code>
     */
    APP_SUCCEEDED(1),
    /**
     * <code>APP_FAILED = 2;</code>
     */
    APP_FAILED(2),
    /**
     * <code>APP_KILLED = 3;</code>
     */
    APP_KILLED(3),
    ;

    /**
     * <code>APP_UNDEFINED = 0;</code>
     */
    public static final int APP_UNDEFINED_VALUE = 0;
    /**
     * <code>APP_SUCCEEDED = 1;</code>
     */
    public static final int APP_SUCCEEDED_VALUE = 1;
    /**
     * <code>APP_FAILED = 2;</code>
     */
    public static final int APP_FAILED_VALUE = 2;
    /**
     * <code>APP_KILLED = 3;</code>
     */
    public static final int APP_KILLED_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static FinalApplicationStatusProto valueOf(int value) {
      return forNumber(value);
    }

    public static FinalApplicationStatusProto forNumber(int value) {
      switch (value) {
        case 0: return APP_UNDEFINED;
        case 1: return APP_SUCCEEDED;
        case 2: return APP_FAILED;
        case 3: return APP_KILLED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        FinalApplicationStatusProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<FinalApplicationStatusProto>() {
            public FinalApplicationStatusProto findValueByNumber(int number) {
              return FinalApplicationStatusProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(3);
    }

    private static final FinalApplicationStatusProto[] VALUES = values();

    public static FinalApplicationStatusProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private FinalApplicationStatusProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.FinalApplicationStatusProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.LocalResourceVisibilityProto}
   */
  public enum LocalResourceVisibilityProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>PUBLIC = 1;</code>
     */
    PUBLIC(1),
    /**
     * <code>PRIVATE = 2;</code>
     */
    PRIVATE(2),
    /**
     * <code>APPLICATION = 3;</code>
     */
    APPLICATION(3),
    ;

    /**
     * <code>PUBLIC = 1;</code>
     */
    public static final int PUBLIC_VALUE = 1;
    /**
     * <code>PRIVATE = 2;</code>
     */
    public static final int PRIVATE_VALUE = 2;
    /**
     * <code>APPLICATION = 3;</code>
     */
    public static final int APPLICATION_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static LocalResourceVisibilityProto valueOf(int value) {
      return forNumber(value);
    }

    public static LocalResourceVisibilityProto forNumber(int value) {
      switch (value) {
        case 1: return PUBLIC;
        case 2: return PRIVATE;
        case 3: return APPLICATION;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        LocalResourceVisibilityProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LocalResourceVisibilityProto>() {
            public LocalResourceVisibilityProto findValueByNumber(int number) {
              return LocalResourceVisibilityProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(4);
    }

    private static final LocalResourceVisibilityProto[] VALUES = values();

    public static LocalResourceVisibilityProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private LocalResourceVisibilityProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.LocalResourceVisibilityProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.LocalResourceTypeProto}
   */
  public enum LocalResourceTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>ARCHIVE = 1;</code>
     */
    ARCHIVE(1),
    /**
     * <code>FILE = 2;</code>
     */
    FILE(2),
    /**
     * <code>PATTERN = 3;</code>
     */
    PATTERN(3),
    ;

    /**
     * <code>ARCHIVE = 1;</code>
     */
    public static final int ARCHIVE_VALUE = 1;
    /**
     * <code>FILE = 2;</code>
     */
    public static final int FILE_VALUE = 2;
    /**
     * <code>PATTERN = 3;</code>
     */
    public static final int PATTERN_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static LocalResourceTypeProto valueOf(int value) {
      return forNumber(value);
    }

    public static LocalResourceTypeProto forNumber(int value) {
      switch (value) {
        case 1: return ARCHIVE;
        case 2: return FILE;
        case 3: return PATTERN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        LocalResourceTypeProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<LocalResourceTypeProto>() {
            public LocalResourceTypeProto findValueByNumber(int number) {
              return LocalResourceTypeProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(5);
    }

    private static final LocalResourceTypeProto[] VALUES = values();

    public static LocalResourceTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private LocalResourceTypeProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.LocalResourceTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.NodeStateProto}
   */
  public enum NodeStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>NS_NEW = 1;</code>
     */
    NS_NEW(1),
    /**
     * <code>NS_RUNNING = 2;</code>
     */
    NS_RUNNING(2),
    /**
     * <code>NS_UNHEALTHY = 3;</code>
     */
    NS_UNHEALTHY(3),
    /**
     * <code>NS_DECOMMISSIONED = 4;</code>
     */
    NS_DECOMMISSIONED(4),
    /**
     * <code>NS_LOST = 5;</code>
     */
    NS_LOST(5),
    /**
     * <code>NS_REBOOTED = 6;</code>
     */
    NS_REBOOTED(6),
    ;

    /**
     * <code>NS_NEW = 1;</code>
     */
    public static final int NS_NEW_VALUE = 1;
    /**
     * <code>NS_RUNNING = 2;</code>
     */
    public static final int NS_RUNNING_VALUE = 2;
    /**
     * <code>NS_UNHEALTHY = 3;</code>
     */
    public static final int NS_UNHEALTHY_VALUE = 3;
    /**
     * <code>NS_DECOMMISSIONED = 4;</code>
     */
    public static final int NS_DECOMMISSIONED_VALUE = 4;
    /**
     * <code>NS_LOST = 5;</code>
     */
    public static final int NS_LOST_VALUE = 5;
    /**
     * <code>NS_REBOOTED = 6;</code>
     */
    public static final int NS_REBOOTED_VALUE = 6;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static NodeStateProto valueOf(int value) {
      return forNumber(value);
    }

    public static NodeStateProto forNumber(int value) {
      switch (value) {
        case 1: return NS_NEW;
        case 2: return NS_RUNNING;
        case 3: return NS_UNHEALTHY;
        case 4: return NS_DECOMMISSIONED;
        case 5: return NS_LOST;
        case 6: return NS_REBOOTED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        NodeStateProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<NodeStateProto>() {
            public NodeStateProto findValueByNumber(int number) {
              return NodeStateProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(6);
    }

    private static final NodeStateProto[] VALUES = values();

    public static NodeStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private NodeStateProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.NodeStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.AMCommandProto}
   */
  public enum AMCommandProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>AM_RESYNC = 1;</code>
     */
    AM_RESYNC(1),
    /**
     * <code>AM_SHUTDOWN = 2;</code>
     */
    AM_SHUTDOWN(2),
    ;

    /**
     * <code>AM_RESYNC = 1;</code>
     */
    public static final int AM_RESYNC_VALUE = 1;
    /**
     * <code>AM_SHUTDOWN = 2;</code>
     */
    public static final int AM_SHUTDOWN_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static AMCommandProto valueOf(int value) {
      return forNumber(value);
    }

    public static AMCommandProto forNumber(int value) {
      switch (value) {
        case 1: return AM_RESYNC;
        case 2: return AM_SHUTDOWN;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        AMCommandProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<AMCommandProto>() {
            public AMCommandProto findValueByNumber(int number) {
              return AMCommandProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(7);
    }

    private static final AMCommandProto[] VALUES = values();

    public static AMCommandProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private AMCommandProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.AMCommandProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ApplicationAccessTypeProto}
   */
  public enum ApplicationAccessTypeProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>APPACCESS_VIEW_APP = 1;</code>
     */
    APPACCESS_VIEW_APP(1),
    /**
     * <code>APPACCESS_MODIFY_APP = 2;</code>
     */
    APPACCESS_MODIFY_APP(2),
    ;

    /**
     * <code>APPACCESS_VIEW_APP = 1;</code>
     */
    public static final int APPACCESS_VIEW_APP_VALUE = 1;
    /**
     * <code>APPACCESS_MODIFY_APP = 2;</code>
     */
    public static final int APPACCESS_MODIFY_APP_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ApplicationAccessTypeProto valueOf(int value) {
      return forNumber(value);
    }

    public static ApplicationAccessTypeProto forNumber(int value) {
      switch (value) {
        case 1: return APPACCESS_VIEW_APP;
        case 2: return APPACCESS_MODIFY_APP;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ApplicationAccessTypeProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ApplicationAccessTypeProto>() {
            public ApplicationAccessTypeProto findValueByNumber(int number) {
              return ApplicationAccessTypeProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(8);
    }

    private static final ApplicationAccessTypeProto[] VALUES = values();

    public static ApplicationAccessTypeProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ApplicationAccessTypeProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ApplicationAccessTypeProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.QueueStateProto}
   */
  public enum QueueStateProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>Q_STOPPED = 1;</code>
     */
    Q_STOPPED(1),
    /**
     * <code>Q_RUNNING = 2;</code>
     */
    Q_RUNNING(2),
    ;

    /**
     * <code>Q_STOPPED = 1;</code>
     */
    public static final int Q_STOPPED_VALUE = 1;
    /**
     * <code>Q_RUNNING = 2;</code>
     */
    public static final int Q_RUNNING_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static QueueStateProto valueOf(int value) {
      return forNumber(value);
    }

    public static QueueStateProto forNumber(int value) {
      switch (value) {
        case 1: return Q_STOPPED;
        case 2: return Q_RUNNING;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        QueueStateProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QueueStateProto>() {
            public QueueStateProto findValueByNumber(int number) {
              return QueueStateProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(9);
    }

    private static final QueueStateProto[] VALUES = values();

    public static QueueStateProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private QueueStateProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.QueueStateProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.QueueACLProto}
   */
  public enum QueueACLProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>QACL_SUBMIT_APPLICATIONS = 1;</code>
     */
    QACL_SUBMIT_APPLICATIONS(1),
    /**
     * <code>QACL_ADMINISTER_QUEUE = 2;</code>
     */
    QACL_ADMINISTER_QUEUE(2),
    ;

    /**
     * <code>QACL_SUBMIT_APPLICATIONS = 1;</code>
     */
    public static final int QACL_SUBMIT_APPLICATIONS_VALUE = 1;
    /**
     * <code>QACL_ADMINISTER_QUEUE = 2;</code>
     */
    public static final int QACL_ADMINISTER_QUEUE_VALUE = 2;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static QueueACLProto valueOf(int value) {
      return forNumber(value);
    }

    public static QueueACLProto forNumber(int value) {
      switch (value) {
        case 1: return QACL_SUBMIT_APPLICATIONS;
        case 2: return QACL_ADMINISTER_QUEUE;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        QueueACLProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<QueueACLProto>() {
            public QueueACLProto findValueByNumber(int number) {
              return QueueACLProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(10);
    }

    private static final QueueACLProto[] VALUES = values();

    public static QueueACLProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private QueueACLProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.QueueACLProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ReservationRequestInterpreterProto}
   */
  public enum ReservationRequestInterpreterProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>R_ANY = 0;</code>
     */
    R_ANY(0),
    /**
     * <code>R_ALL = 1;</code>
     */
    R_ALL(1),
    /**
     * <code>R_ORDER = 2;</code>
     */
    R_ORDER(2),
    /**
     * <code>R_ORDER_NO_GAP = 3;</code>
     */
    R_ORDER_NO_GAP(3),
    ;

    /**
     * <code>R_ANY = 0;</code>
     */
    public static final int R_ANY_VALUE = 0;
    /**
     * <code>R_ALL = 1;</code>
     */
    public static final int R_ALL_VALUE = 1;
    /**
     * <code>R_ORDER = 2;</code>
     */
    public static final int R_ORDER_VALUE = 2;
    /**
     * <code>R_ORDER_NO_GAP = 3;</code>
     */
    public static final int R_ORDER_NO_GAP_VALUE = 3;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ReservationRequestInterpreterProto valueOf(int value) {
      return forNumber(value);
    }

    public static ReservationRequestInterpreterProto forNumber(int value) {
      switch (value) {
        case 0: return R_ANY;
        case 1: return R_ALL;
        case 2: return R_ORDER;
        case 3: return R_ORDER_NO_GAP;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ReservationRequestInterpreterProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ReservationRequestInterpreterProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ReservationRequestInterpreterProto>() {
            public ReservationRequestInterpreterProto findValueByNumber(int number) {
              return ReservationRequestInterpreterProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(11);
    }

    private static final ReservationRequestInterpreterProto[] VALUES = values();

    public static ReservationRequestInterpreterProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ReservationRequestInterpreterProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ReservationRequestInterpreterProto)
  }

  /**
   * Protobuf enum {@code hadoop.yarn.ContainerExitStatusProto}
   */
  public enum ContainerExitStatusProto
      implements com.google.protobuf.ProtocolMessageEnum {
    /**
     * <code>SUCCESS = 0;</code>
     */
    SUCCESS(0),
    /**
     * <code>INVALID = -1000;</code>
     */
    INVALID(-1000),
    /**
     * <code>ABORTED = -100;</code>
     */
    ABORTED(-100),
    /**
     * <code>DISKS_FAILED = -101;</code>
     */
    DISKS_FAILED(-101),
    ;

    /**
     * <code>SUCCESS = 0;</code>
     */
    public static final int SUCCESS_VALUE = 0;
    /**
     * <code>INVALID = -1000;</code>
     */
    public static final int INVALID_VALUE = -1000;
    /**
     * <code>ABORTED = -100;</code>
     */
    public static final int ABORTED_VALUE = -100;
    /**
     * <code>DISKS_FAILED = -101;</code>
     */
    public static final int DISKS_FAILED_VALUE = -101;


    public final int getNumber() {
      return value;
    }

    /**
     * @deprecated Use {@link #forNumber(int)} instead.
     */
    @java.lang.Deprecated
    public static ContainerExitStatusProto valueOf(int value) {
      return forNumber(value);
    }

    public static ContainerExitStatusProto forNumber(int value) {
      switch (value) {
        case 0: return SUCCESS;
        case -1000: return INVALID;
        case -100: return ABORTED;
        case -101: return DISKS_FAILED;
        default: return null;
      }
    }

    public static com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>
        internalGetValueMap() {
      return internalValueMap;
    }
    private static final com.google.protobuf.Internal.EnumLiteMap<
        ContainerExitStatusProto> internalValueMap =
          new com.google.protobuf.Internal.EnumLiteMap<ContainerExitStatusProto>() {
            public ContainerExitStatusProto findValueByNumber(int number) {
              return ContainerExitStatusProto.forNumber(number);
            }
          };

    public final com.google.protobuf.Descriptors.EnumValueDescriptor
        getValueDescriptor() {
      return getDescriptor().getValues().get(ordinal());
    }
    public final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptorForType() {
      return getDescriptor();
    }
    public static final com.google.protobuf.Descriptors.EnumDescriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.getDescriptor().getEnumTypes().get(12);
    }

    private static final ContainerExitStatusProto[] VALUES = values();

    public static ContainerExitStatusProto valueOf(
        com.google.protobuf.Descriptors.EnumValueDescriptor desc) {
      if (desc.getType() != getDescriptor()) {
        throw new java.lang.IllegalArgumentException(
          "EnumValueDescriptor is not for this type.");
      }
      return VALUES[desc.getIndex()];
    }

    private final int value;

    private ContainerExitStatusProto(int value) {
      this.value = value;
    }

    // @@protoc_insertion_point(enum_scope:hadoop.yarn.ContainerExitStatusProto)
  }

  public interface SerializedExceptionProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.SerializedExceptionProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string message = 1;</code>
     */
    boolean hasMessage();
    /**
     * <code>optional string message = 1;</code>
     */
    java.lang.String getMessage();
    /**
     * <code>optional string message = 1;</code>
     */
    com.google.protobuf.ByteString
        getMessageBytes();

    /**
     * <code>optional string trace = 2;</code>
     */
    boolean hasTrace();
    /**
     * <code>optional string trace = 2;</code>
     */
    java.lang.String getTrace();
    /**
     * <code>optional string trace = 2;</code>
     */
    com.google.protobuf.ByteString
        getTraceBytes();

    /**
     * <code>optional string class_name = 3;</code>
     */
    boolean hasClassName();
    /**
     * <code>optional string class_name = 3;</code>
     */
    java.lang.String getClassName();
    /**
     * <code>optional string class_name = 3;</code>
     */
    com.google.protobuf.ByteString
        getClassNameBytes();

    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    boolean hasCause();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause();
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.SerializedExceptionProto}
   */
  public  static final class SerializedExceptionProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.SerializedExceptionProto)
      SerializedExceptionProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use SerializedExceptionProto.newBuilder() to construct.
    private SerializedExceptionProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private SerializedExceptionProto() {
      message_ = "";
      trace_ = "";
      className_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private SerializedExceptionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              message_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              trace_ = bs;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              className_ = bs;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = cause_.toBuilder();
              }
              cause_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(cause_);
                cause_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder.class);
    }

    private int bitField0_;
    public static final int MESSAGE_FIELD_NUMBER = 1;
    private volatile java.lang.Object message_;
    /**
     * <code>optional string message = 1;</code>
     */
    public boolean hasMessage() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string message = 1;</code>
     */
    public java.lang.String getMessage() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          message_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string message = 1;</code>
     */
    public com.google.protobuf.ByteString
        getMessageBytes() {
      java.lang.Object ref = message_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        message_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int TRACE_FIELD_NUMBER = 2;
    private volatile java.lang.Object trace_;
    /**
     * <code>optional string trace = 2;</code>
     */
    public boolean hasTrace() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string trace = 2;</code>
     */
    public java.lang.String getTrace() {
      java.lang.Object ref = trace_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trace_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string trace = 2;</code>
     */
    public com.google.protobuf.ByteString
        getTraceBytes() {
      java.lang.Object ref = trace_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trace_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CLASS_NAME_FIELD_NUMBER = 3;
    private volatile java.lang.Object className_;
    /**
     * <code>optional string class_name = 3;</code>
     */
    public boolean hasClassName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string class_name = 3;</code>
     */
    public java.lang.String getClassName() {
      java.lang.Object ref = className_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          className_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string class_name = 3;</code>
     */
    public com.google.protobuf.ByteString
        getClassNameBytes() {
      java.lang.Object ref = className_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        className_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CAUSE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto cause_;
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public boolean hasCause() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause() {
      return cause_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : cause_;
    }
    /**
     * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder() {
      return cause_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : cause_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, message_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, trace_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, className_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getCause());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, message_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, trace_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, className_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getCause());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) obj;

      boolean result = true;
      result = result && (hasMessage() == other.hasMessage());
      if (hasMessage()) {
        result = result && getMessage()
            .equals(other.getMessage());
      }
      result = result && (hasTrace() == other.hasTrace());
      if (hasTrace()) {
        result = result && getTrace()
            .equals(other.getTrace());
      }
      result = result && (hasClassName() == other.hasClassName());
      if (hasClassName()) {
        result = result && getClassName()
            .equals(other.getClassName());
      }
      result = result && (hasCause() == other.hasCause());
      if (hasCause()) {
        result = result && getCause()
            .equals(other.getCause());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMessage()) {
        hash = (37 * hash) + MESSAGE_FIELD_NUMBER;
        hash = (53 * hash) + getMessage().hashCode();
      }
      if (hasTrace()) {
        hash = (37 * hash) + TRACE_FIELD_NUMBER;
        hash = (53 * hash) + getTrace().hashCode();
      }
      if (hasClassName()) {
        hash = (37 * hash) + CLASS_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getClassName().hashCode();
      }
      if (hasCause()) {
        hash = (37 * hash) + CAUSE_FIELD_NUMBER;
        hash = (53 * hash) + getCause().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.SerializedExceptionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.SerializedExceptionProto)
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCauseFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        message_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        trace_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        className_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (causeBuilder_ == null) {
          cause_ = null;
        } else {
          causeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.message_ = message_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.trace_ = trace_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.className_ = className_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (causeBuilder_ == null) {
          result.cause_ = cause_;
        } else {
          result.cause_ = causeBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance()) return this;
        if (other.hasMessage()) {
          bitField0_ |= 0x00000001;
          message_ = other.message_;
          onChanged();
        }
        if (other.hasTrace()) {
          bitField0_ |= 0x00000002;
          trace_ = other.trace_;
          onChanged();
        }
        if (other.hasClassName()) {
          bitField0_ |= 0x00000004;
          className_ = other.className_;
          onChanged();
        }
        if (other.hasCause()) {
          mergeCause(other.getCause());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object message_ = "";
      /**
       * <code>optional string message = 1;</code>
       */
      public boolean hasMessage() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public java.lang.String getMessage() {
        java.lang.Object ref = message_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            message_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public com.google.protobuf.ByteString
          getMessageBytes() {
        java.lang.Object ref = message_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          message_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder setMessage(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        message_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder clearMessage() {
        bitField0_ = (bitField0_ & ~0x00000001);
        message_ = getDefaultInstance().getMessage();
        onChanged();
        return this;
      }
      /**
       * <code>optional string message = 1;</code>
       */
      public Builder setMessageBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        message_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object trace_ = "";
      /**
       * <code>optional string trace = 2;</code>
       */
      public boolean hasTrace() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public java.lang.String getTrace() {
        java.lang.Object ref = trace_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            trace_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public com.google.protobuf.ByteString
          getTraceBytes() {
        java.lang.Object ref = trace_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trace_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder setTrace(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trace_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder clearTrace() {
        bitField0_ = (bitField0_ & ~0x00000002);
        trace_ = getDefaultInstance().getTrace();
        onChanged();
        return this;
      }
      /**
       * <code>optional string trace = 2;</code>
       */
      public Builder setTraceBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        trace_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object className_ = "";
      /**
       * <code>optional string class_name = 3;</code>
       */
      public boolean hasClassName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public java.lang.String getClassName() {
        java.lang.Object ref = className_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            className_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public com.google.protobuf.ByteString
          getClassNameBytes() {
        java.lang.Object ref = className_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          className_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder setClassName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        className_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder clearClassName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        className_ = getDefaultInstance().getClassName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string class_name = 3;</code>
       */
      public Builder setClassNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        className_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto cause_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> causeBuilder_;
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public boolean hasCause() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getCause() {
        if (causeBuilder_ == null) {
          return cause_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : cause_;
        } else {
          return causeBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder setCause(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (causeBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          cause_ = value;
          onChanged();
        } else {
          causeBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder setCause(
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder builderForValue) {
        if (causeBuilder_ == null) {
          cause_ = builderForValue.build();
          onChanged();
        } else {
          causeBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder mergeCause(org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto value) {
        if (causeBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              cause_ != null &&
              cause_ != org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance()) {
            cause_ =
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.newBuilder(cause_).mergeFrom(value).buildPartial();
          } else {
            cause_ = value;
          }
          onChanged();
        } else {
          causeBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public Builder clearCause() {
        if (causeBuilder_ == null) {
          cause_ = null;
          onChanged();
        } else {
          causeBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder getCauseBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getCauseFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder getCauseOrBuilder() {
        if (causeBuilder_ != null) {
          return causeBuilder_.getMessageOrBuilder();
        } else {
          return cause_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.getDefaultInstance() : cause_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.SerializedExceptionProto cause = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder> 
          getCauseFieldBuilder() {
        if (causeBuilder_ == null) {
          causeBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProtoOrBuilder>(
                  getCause(),
                  getParentForChildren(),
                  isClean());
          cause_ = null;
        }
        return causeBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.SerializedExceptionProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.SerializedExceptionProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<SerializedExceptionProto>
        PARSER = new com.google.protobuf.AbstractParser<SerializedExceptionProto>() {
      public SerializedExceptionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new SerializedExceptionProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<SerializedExceptionProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<SerializedExceptionProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.SerializedExceptionProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationIdProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ApplicationIdProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional int32 id = 1;</code>
     */
    int getId();

    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    boolean hasClusterTimestamp();
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    long getClusterTimestamp();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationIdProto}
   */
  public  static final class ApplicationIdProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ApplicationIdProto)
      ApplicationIdProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationIdProto.newBuilder() to construct.
    private ApplicationIdProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationIdProto() {
      id_ = 0;
      clusterTimestamp_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              id_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              clusterTimestamp_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder.class);
    }

    private int bitField0_;
    public static final int ID_FIELD_NUMBER = 1;
    private int id_;
    /**
     * <code>optional int32 id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 id = 1;</code>
     */
    public int getId() {
      return id_;
    }

    public static final int CLUSTER_TIMESTAMP_FIELD_NUMBER = 2;
    private long clusterTimestamp_;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public boolean hasClusterTimestamp() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public long getClusterTimestamp() {
      return clusterTimestamp_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, clusterTimestamp_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, clusterTimestamp_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result && (hasClusterTimestamp() == other.hasClusterTimestamp());
      if (hasClusterTimestamp()) {
        result = result && (getClusterTimestamp()
            == other.getClusterTimestamp());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId();
      }
      if (hasClusterTimestamp()) {
        hash = (37 * hash) + CLUSTER_TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getClusterTimestamp());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ApplicationIdProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        id_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        clusterTimestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.id_ = id_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.clusterTimestamp_ = clusterTimestamp_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          setId(other.getId());
        }
        if (other.hasClusterTimestamp()) {
          setClusterTimestamp(other.getClusterTimestamp());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int id_ ;
      /**
       * <code>optional int32 id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public int getId() {
        return id_;
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public Builder setId(int value) {
        bitField0_ |= 0x00000001;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 id = 1;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        id_ = 0;
        onChanged();
        return this;
      }

      private long clusterTimestamp_ ;
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public boolean hasClusterTimestamp() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public long getClusterTimestamp() {
        return clusterTimestamp_;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder setClusterTimestamp(long value) {
        bitField0_ |= 0x00000002;
        clusterTimestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder clearClusterTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000002);
        clusterTimestamp_ = 0L;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationIdProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationIdProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApplicationIdProto>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationIdProto>() {
      public ApplicationIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ApplicationIdProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationIdProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationIdProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationAttemptIdProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ApplicationAttemptIdProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    boolean hasAttemptId();
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    int getAttemptId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationAttemptIdProto}
   */
  public  static final class ApplicationAttemptIdProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ApplicationAttemptIdProto)
      ApplicationAttemptIdProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationAttemptIdProto.newBuilder() to construct.
    private ApplicationAttemptIdProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationAttemptIdProto() {
      attemptId_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationAttemptIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              attemptId_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int ATTEMPTID_FIELD_NUMBER = 2;
    private int attemptId_;
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    public boolean hasAttemptId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 attemptId = 2;</code>
     */
    public int getAttemptId() {
      return attemptId_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, attemptId_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, attemptId_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasAttemptId() == other.hasAttemptId());
      if (hasAttemptId()) {
        result = result && (getAttemptId()
            == other.getAttemptId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasAttemptId()) {
        hash = (37 * hash) + ATTEMPTID_FIELD_NUMBER;
        hash = (53 * hash) + getAttemptId();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationAttemptIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ApplicationAttemptIdProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        attemptId_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.attemptId_ = attemptId_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasAttemptId()) {
          setAttemptId(other.getAttemptId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private int attemptId_ ;
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public boolean hasAttemptId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public int getAttemptId() {
        return attemptId_;
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public Builder setAttemptId(int value) {
        bitField0_ |= 0x00000002;
        attemptId_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 attemptId = 2;</code>
       */
      public Builder clearAttemptId() {
        bitField0_ = (bitField0_ & ~0x00000002);
        attemptId_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationAttemptIdProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationAttemptIdProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApplicationAttemptIdProto>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationAttemptIdProto>() {
      public ApplicationAttemptIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ApplicationAttemptIdProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationAttemptIdProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationAttemptIdProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerIdProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerIdProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    boolean hasAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    boolean hasAppAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder();

    /**
     * <code>optional int64 id = 3;</code>
     */
    boolean hasId();
    /**
     * <code>optional int64 id = 3;</code>
     */
    long getId();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerIdProto}
   */
  public  static final class ContainerIdProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerIdProto)
      ContainerIdProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerIdProto.newBuilder() to construct.
    private ContainerIdProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerIdProto() {
      id_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = appId_.toBuilder();
              }
              appId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appId_);
                appId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = appAttemptId_.toBuilder();
              }
              appAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appAttemptId_);
                appAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              id_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder.class);
    }

    private int bitField0_;
    public static final int APP_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public boolean hasAppId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
      return appId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : appId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
      return appId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : appId_;
    }

    public static final int APP_ATTEMPT_ID_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto appAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public boolean hasAppAttemptId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId() {
      return appAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : appAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder() {
      return appAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : appAttemptId_;
    }

    public static final int ID_FIELD_NUMBER = 3;
    private long id_;
    /**
     * <code>optional int64 id = 3;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 id = 3;</code>
     */
    public long getId() {
      return id_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getAppId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getAppAttemptId());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, id_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getAppId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getAppAttemptId());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, id_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) obj;

      boolean result = true;
      result = result && (hasAppId() == other.hasAppId());
      if (hasAppId()) {
        result = result && getAppId()
            .equals(other.getAppId());
      }
      result = result && (hasAppAttemptId() == other.hasAppAttemptId());
      if (hasAppAttemptId()) {
        result = result && getAppAttemptId()
            .equals(other.getAppAttemptId());
      }
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasAppId()) {
        hash = (37 * hash) + APP_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAppId().hashCode();
      }
      if (hasAppAttemptId()) {
        hash = (37 * hash) + APP_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAppAttemptId().hashCode();
      }
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getId());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerIdProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getAppIdFieldBuilder();
          getAppAttemptIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (appIdBuilder_ == null) {
          appId_ = null;
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = null;
        } else {
          appAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        id_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (appIdBuilder_ == null) {
          result.appId_ = appId_;
        } else {
          result.appId_ = appIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (appAttemptIdBuilder_ == null) {
          result.appAttemptId_ = appAttemptId_;
        } else {
          result.appAttemptId_ = appAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.id_ = id_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) return this;
        if (other.hasAppId()) {
          mergeAppId(other.getAppId());
        }
        if (other.hasAppAttemptId()) {
          mergeAppAttemptId(other.getAppAttemptId());
        }
        if (other.hasId()) {
          setId(other.getId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto appId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> appIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public boolean hasAppId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getAppId() {
        if (appIdBuilder_ == null) {
          return appId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : appId_;
        } else {
          return appIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder setAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appId_ = value;
          onChanged();
        } else {
          appIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder setAppId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (appIdBuilder_ == null) {
          appId_ = builderForValue.build();
          onChanged();
        } else {
          appIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder mergeAppId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (appIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              appId_ != null &&
              appId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            appId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(appId_).mergeFrom(value).buildPartial();
          } else {
            appId_ = value;
          }
          onChanged();
        } else {
          appIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public Builder clearAppId() {
        if (appIdBuilder_ == null) {
          appId_ = null;
          onChanged();
        } else {
          appIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getAppIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getAppIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getAppIdOrBuilder() {
        if (appIdBuilder_ != null) {
          return appIdBuilder_.getMessageOrBuilder();
        } else {
          return appId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : appId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto app_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getAppIdFieldBuilder() {
        if (appIdBuilder_ == null) {
          appIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getAppId(),
                  getParentForChildren(),
                  isClean());
          appId_ = null;
        }
        return appIdBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto appAttemptId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> appAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public boolean hasAppAttemptId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getAppAttemptId() {
        if (appAttemptIdBuilder_ == null) {
          return appAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : appAttemptId_;
        } else {
          return appAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder setAppAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (appAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appAttemptId_ = value;
          onChanged();
        } else {
          appAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder setAppAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          appAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder mergeAppAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (appAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              appAttemptId_ != null &&
              appAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            appAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(appAttemptId_).mergeFrom(value).buildPartial();
          } else {
            appAttemptId_ = value;
          }
          onChanged();
        } else {
          appAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public Builder clearAppAttemptId() {
        if (appAttemptIdBuilder_ == null) {
          appAttemptId_ = null;
          onChanged();
        } else {
          appAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getAppAttemptIdBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getAppAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getAppAttemptIdOrBuilder() {
        if (appAttemptIdBuilder_ != null) {
          return appAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return appAttemptId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : appAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto app_attempt_id = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getAppAttemptIdFieldBuilder() {
        if (appAttemptIdBuilder_ == null) {
          appAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  getAppAttemptId(),
                  getParentForChildren(),
                  isClean());
          appAttemptId_ = null;
        }
        return appAttemptIdBuilder_;
      }

      private long id_ ;
      /**
       * <code>optional int64 id = 3;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 id = 3;</code>
       */
      public long getId() {
        return id_;
      }
      /**
       * <code>optional int64 id = 3;</code>
       */
      public Builder setId(long value) {
        bitField0_ |= 0x00000004;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 id = 3;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000004);
        id_ = 0L;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerIdProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerIdProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerIdProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerIdProto>() {
      public ContainerIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerIdProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerIdProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerIdProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourceProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ResourceProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 memory = 1;</code>
     */
    boolean hasMemory();
    /**
     * <code>optional int32 memory = 1;</code>
     */
    int getMemory();

    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    boolean hasVirtualCores();
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    int getVirtualCores();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceProto}
   */
  public  static final class ResourceProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ResourceProto)
      ResourceProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ResourceProto.newBuilder() to construct.
    private ResourceProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ResourceProto() {
      memory_ = 0;
      virtualCores_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              memory_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              virtualCores_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder.class);
    }

    private int bitField0_;
    public static final int MEMORY_FIELD_NUMBER = 1;
    private int memory_;
    /**
     * <code>optional int32 memory = 1;</code>
     */
    public boolean hasMemory() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 memory = 1;</code>
     */
    public int getMemory() {
      return memory_;
    }

    public static final int VIRTUAL_CORES_FIELD_NUMBER = 2;
    private int virtualCores_;
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    public boolean hasVirtualCores() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 virtual_cores = 2;</code>
     */
    public int getVirtualCores() {
      return virtualCores_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, memory_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, virtualCores_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, memory_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, virtualCores_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) obj;

      boolean result = true;
      result = result && (hasMemory() == other.hasMemory());
      if (hasMemory()) {
        result = result && (getMemory()
            == other.getMemory());
      }
      result = result && (hasVirtualCores() == other.hasVirtualCores());
      if (hasVirtualCores()) {
        result = result && (getVirtualCores()
            == other.getVirtualCores());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasMemory()) {
        hash = (37 * hash) + MEMORY_FIELD_NUMBER;
        hash = (53 * hash) + getMemory();
      }
      if (hasVirtualCores()) {
        hash = (37 * hash) + VIRTUAL_CORES_FIELD_NUMBER;
        hash = (53 * hash) + getVirtualCores();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ResourceProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        memory_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        virtualCores_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.memory_ = memory_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.virtualCores_ = virtualCores_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) return this;
        if (other.hasMemory()) {
          setMemory(other.getMemory());
        }
        if (other.hasVirtualCores()) {
          setVirtualCores(other.getVirtualCores());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int memory_ ;
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public boolean hasMemory() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public int getMemory() {
        return memory_;
      }
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public Builder setMemory(int value) {
        bitField0_ |= 0x00000001;
        memory_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 memory = 1;</code>
       */
      public Builder clearMemory() {
        bitField0_ = (bitField0_ & ~0x00000001);
        memory_ = 0;
        onChanged();
        return this;
      }

      private int virtualCores_ ;
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public boolean hasVirtualCores() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public int getVirtualCores() {
        return virtualCores_;
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public Builder setVirtualCores(int value) {
        bitField0_ |= 0x00000002;
        virtualCores_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 virtual_cores = 2;</code>
       */
      public Builder clearVirtualCores() {
        bitField0_ = (bitField0_ & ~0x00000002);
        virtualCores_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ResourceProto>
        PARSER = new com.google.protobuf.AbstractParser<ResourceProto>() {
      public ResourceProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ResourceProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ResourceProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourceOptionProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ResourceOptionProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    boolean hasOverCommitTimeout();
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    int getOverCommitTimeout();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceOptionProto}
   */
  public  static final class ResourceOptionProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ResourceOptionProto)
      ResourceOptionProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ResourceOptionProto.newBuilder() to construct.
    private ResourceOptionProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ResourceOptionProto() {
      overCommitTimeout_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceOptionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              overCommitTimeout_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }

    public static final int OVER_COMMIT_TIMEOUT_FIELD_NUMBER = 2;
    private int overCommitTimeout_;
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    public boolean hasOverCommitTimeout() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 over_commit_timeout = 2;</code>
     */
    public int getOverCommitTimeout() {
      return overCommitTimeout_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getResource());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, overCommitTimeout_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getResource());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, overCommitTimeout_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasOverCommitTimeout() == other.hasOverCommitTimeout());
      if (hasOverCommitTimeout()) {
        result = result && (getOverCommitTimeout()
            == other.getOverCommitTimeout());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasOverCommitTimeout()) {
        hash = (37 * hash) + OVER_COMMIT_TIMEOUT_FIELD_NUMBER;
        hash = (53 * hash) + getOverCommitTimeout();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceOptionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ResourceOptionProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = null;
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        overCommitTimeout_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.overCommitTimeout_ = overCommitTimeout_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasOverCommitTimeout()) {
          setOverCommitTimeout(other.getOverCommitTimeout());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != null &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = null;
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getResource(),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      private int overCommitTimeout_ ;
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public boolean hasOverCommitTimeout() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public int getOverCommitTimeout() {
        return overCommitTimeout_;
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public Builder setOverCommitTimeout(int value) {
        bitField0_ |= 0x00000002;
        overCommitTimeout_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 over_commit_timeout = 2;</code>
       */
      public Builder clearOverCommitTimeout() {
        bitField0_ = (bitField0_ & ~0x00000002);
        overCommitTimeout_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceOptionProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceOptionProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ResourceOptionProto>
        PARSER = new com.google.protobuf.AbstractParser<ResourceOptionProto>() {
      public ResourceOptionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ResourceOptionProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ResourceOptionProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceOptionProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface NodeResourceMapProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.NodeResourceMapProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    boolean hasResourceOption();
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption();
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeResourceMapProto}
   */
  public  static final class NodeResourceMapProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.NodeResourceMapProto)
      NodeResourceMapProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use NodeResourceMapProto.newBuilder() to construct.
    private NodeResourceMapProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private NodeResourceMapProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private NodeResourceMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = resourceOption_.toBuilder();
              }
              resourceOption_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resourceOption_);
                resourceOption_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.Builder.class);
    }

    private int bitField0_;
    public static final int NODE_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }

    public static final int RESOURCE_OPTION_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto resourceOption_;
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public boolean hasResourceOption() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption() {
      return resourceOption_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance() : resourceOption_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder() {
      return resourceOption_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance() : resourceOption_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getNodeId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getResourceOption());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNodeId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getResourceOption());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasResourceOption() == other.hasResourceOption());
      if (hasResourceOption()) {
        result = result && getResourceOption()
            .equals(other.getResourceOption());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasResourceOption()) {
        hash = (37 * hash) + RESOURCE_OPTION_FIELD_NUMBER;
        hash = (53 * hash) + getResourceOption().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeResourceMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.NodeResourceMapProto)
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getResourceOptionFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = null;
        } else {
          resourceOptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (resourceOptionBuilder_ == null) {
          result.resourceOption_ = resourceOption_;
        } else {
          result.resourceOption_ = resourceOptionBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasResourceOption()) {
          mergeResourceOption(other.getResourceOption());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != null &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  getNodeId(),
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto resourceOption_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder> resourceOptionBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public boolean hasResourceOption() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto getResourceOption() {
        if (resourceOptionBuilder_ == null) {
          return resourceOption_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance() : resourceOption_;
        } else {
          return resourceOptionBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder setResourceOption(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto value) {
        if (resourceOptionBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resourceOption_ = value;
          onChanged();
        } else {
          resourceOptionBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder setResourceOption(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder builderForValue) {
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = builderForValue.build();
          onChanged();
        } else {
          resourceOptionBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder mergeResourceOption(org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto value) {
        if (resourceOptionBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              resourceOption_ != null &&
              resourceOption_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance()) {
            resourceOption_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.newBuilder(resourceOption_).mergeFrom(value).buildPartial();
          } else {
            resourceOption_ = value;
          }
          onChanged();
        } else {
          resourceOptionBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public Builder clearResourceOption() {
        if (resourceOptionBuilder_ == null) {
          resourceOption_ = null;
          onChanged();
        } else {
          resourceOptionBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder getResourceOptionBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getResourceOptionFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder getResourceOptionOrBuilder() {
        if (resourceOptionBuilder_ != null) {
          return resourceOptionBuilder_.getMessageOrBuilder();
        } else {
          return resourceOption_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.getDefaultInstance() : resourceOption_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceOptionProto resource_option = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder> 
          getResourceOptionFieldBuilder() {
        if (resourceOptionBuilder_ == null) {
          resourceOptionBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceOptionProtoOrBuilder>(
                  getResourceOption(),
                  getParentForChildren(),
                  isClean());
          resourceOption_ = null;
        }
        return resourceOptionBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeResourceMapProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeResourceMapProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<NodeResourceMapProto>
        PARSER = new com.google.protobuf.AbstractParser<NodeResourceMapProto>() {
      public NodeResourceMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new NodeResourceMapProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<NodeResourceMapProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<NodeResourceMapProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.NodeResourceMapProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PriorityProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.PriorityProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 priority = 1;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional int32 priority = 1;</code>
     */
    int getPriority();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PriorityProto}
   */
  public  static final class PriorityProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.PriorityProto)
      PriorityProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PriorityProto.newBuilder() to construct.
    private PriorityProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PriorityProto() {
      priority_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PriorityProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              priority_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder.class);
    }

    private int bitField0_;
    public static final int PRIORITY_FIELD_NUMBER = 1;
    private int priority_;
    /**
     * <code>optional int32 priority = 1;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 priority = 1;</code>
     */
    public int getPriority() {
      return priority_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, priority_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, priority_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) obj;

      boolean result = true;
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && (getPriority()
            == other.getPriority());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PriorityProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.PriorityProto)
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        priority_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PriorityProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.priority_ = priority_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) return this;
        if (other.hasPriority()) {
          setPriority(other.getPriority());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int priority_ ;
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public int getPriority() {
        return priority_;
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public Builder setPriority(int value) {
        bitField0_ |= 0x00000001;
        priority_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 priority = 1;</code>
       */
      public Builder clearPriority() {
        bitField0_ = (bitField0_ & ~0x00000001);
        priority_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PriorityProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PriorityProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<PriorityProto>
        PARSER = new com.google.protobuf.AbstractParser<PriorityProto>() {
      public PriorityProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new PriorityProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PriorityProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PriorityProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    /**
     * <code>optional string node_http_address = 3;</code>
     */
    boolean hasNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    java.lang.String getNodeHttpAddress();
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    com.google.protobuf.ByteString
        getNodeHttpAddressBytes();

    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    boolean hasContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerProto}
   */
  public  static final class ContainerProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerProto)
      ContainerProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerProto.newBuilder() to construct.
    private ContainerProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerProto() {
      nodeHttpAddress_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = id_.toBuilder();
              }
              id_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(id_);
                id_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              nodeHttpAddress_ = bs;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 50: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000020) == 0x00000020)) {
                subBuilder = containerToken_.toBuilder();
              }
              containerToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerToken_);
                containerToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000020;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder.class);
    }

    private int bitField0_;
    public static final int ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
      return id_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
      return id_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
    }

    public static final int NODEID_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }

    public static final int NODE_HTTP_ADDRESS_FIELD_NUMBER = 3;
    private volatile java.lang.Object nodeHttpAddress_;
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public boolean hasNodeHttpAddress() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public java.lang.String getNodeHttpAddress() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeHttpAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_http_address = 3;</code>
     */
    public com.google.protobuf.ByteString
        getNodeHttpAddressBytes() {
      java.lang.Object ref = nodeHttpAddress_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeHttpAddress_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RESOURCE_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }

    public static final int PRIORITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }

    public static final int CONTAINER_TOKEN_FIELD_NUMBER = 6;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public boolean hasContainerToken() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
      return containerToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
      return containerToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasContainerToken()) {
        if (!getContainerToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getNodeId());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, nodeHttpAddress_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getResource());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, getPriority());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeMessage(6, getContainerToken());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getNodeId());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, nodeHttpAddress_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getResource());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getPriority());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, getContainerToken());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && getId()
            .equals(other.getId());
      }
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasNodeHttpAddress() == other.hasNodeHttpAddress());
      if (hasNodeHttpAddress()) {
        result = result && getNodeHttpAddress()
            .equals(other.getNodeHttpAddress());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasContainerToken() == other.hasContainerToken());
      if (hasContainerToken()) {
        result = result && getContainerToken()
            .equals(other.getContainerToken());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId().hashCode();
      }
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasNodeHttpAddress()) {
        hash = (37 * hash) + NODE_HTTP_ADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeHttpAddress().hashCode();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasContainerToken()) {
        hash = (37 * hash) + CONTAINER_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getContainerToken().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getIdFieldBuilder();
          getNodeIdFieldBuilder();
          getResourceFieldBuilder();
          getPriorityFieldBuilder();
          getContainerTokenFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (idBuilder_ == null) {
          id_ = null;
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        nodeHttpAddress_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (resourceBuilder_ == null) {
          resource_ = null;
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (priorityBuilder_ == null) {
          priority_ = null;
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        if (containerTokenBuilder_ == null) {
          containerToken_ = null;
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (idBuilder_ == null) {
          result.id_ = id_;
        } else {
          result.id_ = idBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.nodeHttpAddress_ = nodeHttpAddress_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        if (containerTokenBuilder_ == null) {
          result.containerToken_ = containerToken_;
        } else {
          result.containerToken_ = containerTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          mergeId(other.getId());
        }
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasNodeHttpAddress()) {
          bitField0_ |= 0x00000004;
          nodeHttpAddress_ = other.nodeHttpAddress_;
          onChanged();
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasContainerToken()) {
          mergeContainerToken(other.getContainerToken());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasContainerToken()) {
          if (!getContainerToken().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> idBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
        if (idBuilder_ == null) {
          return id_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
        } else {
          return idBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          id_ = value;
          onChanged();
        } else {
          idBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (idBuilder_ == null) {
          id_ = builderForValue.build();
          onChanged();
        } else {
          idBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder mergeId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              id_ != null &&
              id_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            id_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(id_).mergeFrom(value).buildPartial();
          } else {
            id_ = value;
          }
          onChanged();
        } else {
          idBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder clearId() {
        if (idBuilder_ == null) {
          id_ = null;
          onChanged();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
        if (idBuilder_ != null) {
          return idBuilder_.getMessageOrBuilder();
        } else {
          return id_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getIdFieldBuilder() {
        if (idBuilder_ == null) {
          idBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getId(),
                  getParentForChildren(),
                  isClean());
          id_ = null;
        }
        return idBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              nodeId_ != null &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  getNodeId(),
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      private java.lang.Object nodeHttpAddress_ = "";
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public boolean hasNodeHttpAddress() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public java.lang.String getNodeHttpAddress() {
        java.lang.Object ref = nodeHttpAddress_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            nodeHttpAddress_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public com.google.protobuf.ByteString
          getNodeHttpAddressBytes() {
        java.lang.Object ref = nodeHttpAddress_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeHttpAddress_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder setNodeHttpAddress(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder clearNodeHttpAddress() {
        bitField0_ = (bitField0_ & ~0x00000004);
        nodeHttpAddress_ = getDefaultInstance().getNodeHttpAddress();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_http_address = 3;</code>
       */
      public Builder setNodeHttpAddressBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        nodeHttpAddress_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              resource_ != null &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = null;
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getResource(),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              priority_ != null &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = null;
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  getPriority(),
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> containerTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public boolean hasContainerToken() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
        if (containerTokenBuilder_ == null) {
          return containerToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
        } else {
          return containerTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder setContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerToken_ = value;
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder setContainerToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (containerTokenBuilder_ == null) {
          containerToken_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder mergeContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020) &&
              containerToken_ != null &&
              containerToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            containerToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(containerToken_).mergeFrom(value).buildPartial();
          } else {
            containerToken_ = value;
          }
          onChanged();
        } else {
          containerTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000020;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public Builder clearContainerToken() {
        if (containerTokenBuilder_ == null) {
          containerToken_ = null;
          onChanged();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getContainerTokenBuilder() {
        bitField0_ |= 0x00000020;
        onChanged();
        return getContainerTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
        if (containerTokenBuilder_ != null) {
          return containerTokenBuilder_.getMessageOrBuilder();
        } else {
          return containerToken_ == null ?
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 6;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getContainerTokenFieldBuilder() {
        if (containerTokenBuilder_ == null) {
          containerTokenBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  getContainerToken(),
                  getParentForChildren(),
                  isClean());
          containerToken_ = null;
        }
        return containerTokenBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerProto>() {
      public ContainerProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerReportProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerReportProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    boolean hasCreationTime();
    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    long getCreationTime();

    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    boolean hasFinishTime();
    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    long getFinishTime();

    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    boolean hasDiagnosticsInfo();
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    java.lang.String getDiagnosticsInfo();
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsInfoBytes();

    /**
     * <code>optional string log_url = 8;</code>
     */
    boolean hasLogUrl();
    /**
     * <code>optional string log_url = 8;</code>
     */
    java.lang.String getLogUrl();
    /**
     * <code>optional string log_url = 8;</code>
     */
    com.google.protobuf.ByteString
        getLogUrlBytes();

    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    boolean hasContainerExitStatus();
    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    int getContainerExitStatus();

    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    boolean hasContainerState();
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerReportProto}
   */
  public  static final class ContainerReportProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerReportProto)
      ContainerReportProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerReportProto.newBuilder() to construct.
    private ContainerReportProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerReportProto() {
      creationTime_ = 0L;
      finishTime_ = 0L;
      diagnosticsInfo_ = "N/A";
      logUrl_ = "";
      containerExitStatus_ = 0;
      containerState_ = 1;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              creationTime_ = input.readInt64();
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              finishTime_ = input.readInt64();
              break;
            }
            case 58: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000040;
              diagnosticsInfo_ = bs;
              break;
            }
            case 66: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000080;
              logUrl_ = bs;
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              containerExitStatus_ = input.readInt32();
              break;
            }
            case 80: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(10, rawValue);
              } else {
                bitField0_ |= 0x00000200;
                containerState_ = rawValue;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int RESOURCE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }

    public static final int NODE_ID_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }

    public static final int PRIORITY_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }

    public static final int CREATION_TIME_FIELD_NUMBER = 5;
    private long creationTime_;
    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    public boolean hasCreationTime() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional int64 creation_time = 5;</code>
     */
    public long getCreationTime() {
      return creationTime_;
    }

    public static final int FINISH_TIME_FIELD_NUMBER = 6;
    private long finishTime_;
    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    public boolean hasFinishTime() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int64 finish_time = 6;</code>
     */
    public long getFinishTime() {
      return finishTime_;
    }

    public static final int DIAGNOSTICS_INFO_FIELD_NUMBER = 7;
    private volatile java.lang.Object diagnosticsInfo_;
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    public boolean hasDiagnosticsInfo() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnosticsInfo() {
      java.lang.Object ref = diagnosticsInfo_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnosticsInfo_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsInfoBytes() {
      java.lang.Object ref = diagnosticsInfo_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnosticsInfo_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LOG_URL_FIELD_NUMBER = 8;
    private volatile java.lang.Object logUrl_;
    /**
     * <code>optional string log_url = 8;</code>
     */
    public boolean hasLogUrl() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string log_url = 8;</code>
     */
    public java.lang.String getLogUrl() {
      java.lang.Object ref = logUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          logUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string log_url = 8;</code>
     */
    public com.google.protobuf.ByteString
        getLogUrlBytes() {
      java.lang.Object ref = logUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        logUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CONTAINER_EXIT_STATUS_FIELD_NUMBER = 9;
    private int containerExitStatus_;
    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    public boolean hasContainerExitStatus() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int32 container_exit_status = 9;</code>
     */
    public int getContainerExitStatus() {
      return containerExitStatus_;
    }

    public static final int CONTAINER_STATE_FIELD_NUMBER = 10;
    private int containerState_;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    public boolean hasContainerState() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState() {
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(containerState_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW : result;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getResource());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getNodeId());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getPriority());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeInt64(5, creationTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt64(6, finishTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 7, diagnosticsInfo_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, logUrl_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt32(9, containerExitStatus_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        output.writeEnum(10, containerState_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getResource());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getNodeId());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getPriority());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(5, creationTime_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, finishTime_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(7, diagnosticsInfo_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, logUrl_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(9, containerExitStatus_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(10, containerState_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasCreationTime() == other.hasCreationTime());
      if (hasCreationTime()) {
        result = result && (getCreationTime()
            == other.getCreationTime());
      }
      result = result && (hasFinishTime() == other.hasFinishTime());
      if (hasFinishTime()) {
        result = result && (getFinishTime()
            == other.getFinishTime());
      }
      result = result && (hasDiagnosticsInfo() == other.hasDiagnosticsInfo());
      if (hasDiagnosticsInfo()) {
        result = result && getDiagnosticsInfo()
            .equals(other.getDiagnosticsInfo());
      }
      result = result && (hasLogUrl() == other.hasLogUrl());
      if (hasLogUrl()) {
        result = result && getLogUrl()
            .equals(other.getLogUrl());
      }
      result = result && (hasContainerExitStatus() == other.hasContainerExitStatus());
      if (hasContainerExitStatus()) {
        result = result && (getContainerExitStatus()
            == other.getContainerExitStatus());
      }
      result = result && (hasContainerState() == other.hasContainerState());
      if (hasContainerState()) {
        result = result && containerState_ == other.containerState_;
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasNodeId()) {
        hash = (37 * hash) + NODE_ID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasCreationTime()) {
        hash = (37 * hash) + CREATION_TIME_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getCreationTime());
      }
      if (hasFinishTime()) {
        hash = (37 * hash) + FINISH_TIME_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getFinishTime());
      }
      if (hasDiagnosticsInfo()) {
        hash = (37 * hash) + DIAGNOSTICS_INFO_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnosticsInfo().hashCode();
      }
      if (hasLogUrl()) {
        hash = (37 * hash) + LOG_URL_FIELD_NUMBER;
        hash = (53 * hash) + getLogUrl().hashCode();
      }
      if (hasContainerExitStatus()) {
        hash = (37 * hash) + CONTAINER_EXIT_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getContainerExitStatus();
      }
      if (hasContainerState()) {
        hash = (37 * hash) + CONTAINER_STATE_FIELD_NUMBER;
        hash = (53 * hash) + containerState_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerReportProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getResourceFieldBuilder();
          getNodeIdFieldBuilder();
          getPriorityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (resourceBuilder_ == null) {
          resource_ = null;
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (priorityBuilder_ == null) {
          priority_ = null;
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        creationTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000010);
        finishTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        diagnosticsInfo_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000040);
        logUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        containerExitStatus_ = 0;
        bitField0_ = (bitField0_ & ~0x00000100);
        containerState_ = 1;
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.creationTime_ = creationTime_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.finishTime_ = finishTime_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.diagnosticsInfo_ = diagnosticsInfo_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.logUrl_ = logUrl_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.containerExitStatus_ = containerExitStatus_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.containerState_ = containerState_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasCreationTime()) {
          setCreationTime(other.getCreationTime());
        }
        if (other.hasFinishTime()) {
          setFinishTime(other.getFinishTime());
        }
        if (other.hasDiagnosticsInfo()) {
          bitField0_ |= 0x00000040;
          diagnosticsInfo_ = other.diagnosticsInfo_;
          onChanged();
        }
        if (other.hasLogUrl()) {
          bitField0_ |= 0x00000080;
          logUrl_ = other.logUrl_;
          onChanged();
        }
        if (other.hasContainerExitStatus()) {
          setContainerExitStatus(other.getContainerExitStatus());
        }
        if (other.hasContainerState()) {
          setContainerState(other.getContainerState());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              resource_ != null &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = null;
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getResource(),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              nodeId_ != null &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto node_id = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  getNodeId(),
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              priority_ != null &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = null;
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  getPriority(),
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      private long creationTime_ ;
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public boolean hasCreationTime() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public long getCreationTime() {
        return creationTime_;
      }
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public Builder setCreationTime(long value) {
        bitField0_ |= 0x00000010;
        creationTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 creation_time = 5;</code>
       */
      public Builder clearCreationTime() {
        bitField0_ = (bitField0_ & ~0x00000010);
        creationTime_ = 0L;
        onChanged();
        return this;
      }

      private long finishTime_ ;
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public boolean hasFinishTime() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public long getFinishTime() {
        return finishTime_;
      }
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public Builder setFinishTime(long value) {
        bitField0_ |= 0x00000020;
        finishTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finish_time = 6;</code>
       */
      public Builder clearFinishTime() {
        bitField0_ = (bitField0_ & ~0x00000020);
        finishTime_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object diagnosticsInfo_ = "N/A";
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public boolean hasDiagnosticsInfo() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnosticsInfo() {
        java.lang.Object ref = diagnosticsInfo_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            diagnosticsInfo_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsInfoBytes() {
        java.lang.Object ref = diagnosticsInfo_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnosticsInfo_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsInfo(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000040;
        diagnosticsInfo_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public Builder clearDiagnosticsInfo() {
        bitField0_ = (bitField0_ & ~0x00000040);
        diagnosticsInfo_ = getDefaultInstance().getDiagnosticsInfo();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics_info = 7 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsInfoBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000040;
        diagnosticsInfo_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object logUrl_ = "";
      /**
       * <code>optional string log_url = 8;</code>
       */
      public boolean hasLogUrl() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public java.lang.String getLogUrl() {
        java.lang.Object ref = logUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            logUrl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public com.google.protobuf.ByteString
          getLogUrlBytes() {
        java.lang.Object ref = logUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          logUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public Builder setLogUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        logUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public Builder clearLogUrl() {
        bitField0_ = (bitField0_ & ~0x00000080);
        logUrl_ = getDefaultInstance().getLogUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string log_url = 8;</code>
       */
      public Builder setLogUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        logUrl_ = value;
        onChanged();
        return this;
      }

      private int containerExitStatus_ ;
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public boolean hasContainerExitStatus() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public int getContainerExitStatus() {
        return containerExitStatus_;
      }
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public Builder setContainerExitStatus(int value) {
        bitField0_ |= 0x00000100;
        containerExitStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 container_exit_status = 9;</code>
       */
      public Builder clearContainerExitStatus() {
        bitField0_ = (bitField0_ & ~0x00000100);
        containerExitStatus_ = 0;
        onChanged();
        return this;
      }

      private int containerState_ = 1;
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public boolean hasContainerState() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getContainerState() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(containerState_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW : result;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public Builder setContainerState(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000200;
        containerState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto container_state = 10;</code>
       */
      public Builder clearContainerState() {
        bitField0_ = (bitField0_ & ~0x00000200);
        containerState_ = 1;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerReportProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerReportProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerReportProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerReportProto>() {
      public ContainerReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerReportProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerReportProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerReportProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerReportProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface URLProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.URLProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string scheme = 1;</code>
     */
    boolean hasScheme();
    /**
     * <code>optional string scheme = 1;</code>
     */
    java.lang.String getScheme();
    /**
     * <code>optional string scheme = 1;</code>
     */
    com.google.protobuf.ByteString
        getSchemeBytes();

    /**
     * <code>optional string host = 2;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 2;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 2;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    /**
     * <code>optional int32 port = 3;</code>
     */
    boolean hasPort();
    /**
     * <code>optional int32 port = 3;</code>
     */
    int getPort();

    /**
     * <code>optional string file = 4;</code>
     */
    boolean hasFile();
    /**
     * <code>optional string file = 4;</code>
     */
    java.lang.String getFile();
    /**
     * <code>optional string file = 4;</code>
     */
    com.google.protobuf.ByteString
        getFileBytes();

    /**
     * <code>optional string userInfo = 5;</code>
     */
    boolean hasUserInfo();
    /**
     * <code>optional string userInfo = 5;</code>
     */
    java.lang.String getUserInfo();
    /**
     * <code>optional string userInfo = 5;</code>
     */
    com.google.protobuf.ByteString
        getUserInfoBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.URLProto}
   */
  public  static final class URLProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.URLProto)
      URLProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use URLProto.newBuilder() to construct.
    private URLProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private URLProto() {
      scheme_ = "";
      host_ = "";
      port_ = 0;
      file_ = "";
      userInfo_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private URLProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              scheme_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              host_ = bs;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              port_ = input.readInt32();
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000008;
              file_ = bs;
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000010;
              userInfo_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.class, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder.class);
    }

    private int bitField0_;
    public static final int SCHEME_FIELD_NUMBER = 1;
    private volatile java.lang.Object scheme_;
    /**
     * <code>optional string scheme = 1;</code>
     */
    public boolean hasScheme() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string scheme = 1;</code>
     */
    public java.lang.String getScheme() {
      java.lang.Object ref = scheme_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          scheme_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string scheme = 1;</code>
     */
    public com.google.protobuf.ByteString
        getSchemeBytes() {
      java.lang.Object ref = scheme_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        scheme_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int HOST_FIELD_NUMBER = 2;
    private volatile java.lang.Object host_;
    /**
     * <code>optional string host = 2;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PORT_FIELD_NUMBER = 3;
    private int port_;
    /**
     * <code>optional int32 port = 3;</code>
     */
    public boolean hasPort() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 port = 3;</code>
     */
    public int getPort() {
      return port_;
    }

    public static final int FILE_FIELD_NUMBER = 4;
    private volatile java.lang.Object file_;
    /**
     * <code>optional string file = 4;</code>
     */
    public boolean hasFile() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string file = 4;</code>
     */
    public java.lang.String getFile() {
      java.lang.Object ref = file_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          file_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string file = 4;</code>
     */
    public com.google.protobuf.ByteString
        getFileBytes() {
      java.lang.Object ref = file_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        file_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int USERINFO_FIELD_NUMBER = 5;
    private volatile java.lang.Object userInfo_;
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public boolean hasUserInfo() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public java.lang.String getUserInfo() {
      java.lang.Object ref = userInfo_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          userInfo_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string userInfo = 5;</code>
     */
    public com.google.protobuf.ByteString
        getUserInfoBytes() {
      java.lang.Object ref = userInfo_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        userInfo_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, scheme_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, host_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, port_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, file_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, userInfo_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, scheme_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, host_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, port_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, file_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, userInfo_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.URLProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.URLProto other = (org.apache.hadoop.yarn.proto.YarnProtos.URLProto) obj;

      boolean result = true;
      result = result && (hasScheme() == other.hasScheme());
      if (hasScheme()) {
        result = result && getScheme()
            .equals(other.getScheme());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasPort() == other.hasPort());
      if (hasPort()) {
        result = result && (getPort()
            == other.getPort());
      }
      result = result && (hasFile() == other.hasFile());
      if (hasFile()) {
        result = result && getFile()
            .equals(other.getFile());
      }
      result = result && (hasUserInfo() == other.hasUserInfo());
      if (hasUserInfo()) {
        result = result && getUserInfo()
            .equals(other.getUserInfo());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasScheme()) {
        hash = (37 * hash) + SCHEME_FIELD_NUMBER;
        hash = (53 * hash) + getScheme().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasPort()) {
        hash = (37 * hash) + PORT_FIELD_NUMBER;
        hash = (53 * hash) + getPort();
      }
      if (hasFile()) {
        hash = (37 * hash) + FILE_FIELD_NUMBER;
        hash = (53 * hash) + getFile().hashCode();
      }
      if (hasUserInfo()) {
        hash = (37 * hash) + USERINFO_FIELD_NUMBER;
        hash = (53 * hash) + getUserInfo().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.URLProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.URLProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.URLProto)
        org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.URLProto.class, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.URLProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        scheme_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        port_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        file_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        userInfo_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_URLProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto result = new org.apache.hadoop.yarn.proto.YarnProtos.URLProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.scheme_ = scheme_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.port_ = port_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.file_ = file_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.userInfo_ = userInfo_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.URLProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.URLProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.URLProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance()) return this;
        if (other.hasScheme()) {
          bitField0_ |= 0x00000001;
          scheme_ = other.scheme_;
          onChanged();
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000002;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasPort()) {
          setPort(other.getPort());
        }
        if (other.hasFile()) {
          bitField0_ |= 0x00000008;
          file_ = other.file_;
          onChanged();
        }
        if (other.hasUserInfo()) {
          bitField0_ |= 0x00000010;
          userInfo_ = other.userInfo_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.URLProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.URLProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object scheme_ = "";
      /**
       * <code>optional string scheme = 1;</code>
       */
      public boolean hasScheme() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public java.lang.String getScheme() {
        java.lang.Object ref = scheme_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            scheme_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public com.google.protobuf.ByteString
          getSchemeBytes() {
        java.lang.Object ref = scheme_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          scheme_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder setScheme(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        scheme_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder clearScheme() {
        bitField0_ = (bitField0_ & ~0x00000001);
        scheme_ = getDefaultInstance().getScheme();
        onChanged();
        return this;
      }
      /**
       * <code>optional string scheme = 1;</code>
       */
      public Builder setSchemeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        scheme_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 2;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            host_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000002);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }

      private int port_ ;
      /**
       * <code>optional int32 port = 3;</code>
       */
      public boolean hasPort() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public int getPort() {
        return port_;
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public Builder setPort(int value) {
        bitField0_ |= 0x00000004;
        port_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 port = 3;</code>
       */
      public Builder clearPort() {
        bitField0_ = (bitField0_ & ~0x00000004);
        port_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object file_ = "";
      /**
       * <code>optional string file = 4;</code>
       */
      public boolean hasFile() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public java.lang.String getFile() {
        java.lang.Object ref = file_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            file_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public com.google.protobuf.ByteString
          getFileBytes() {
        java.lang.Object ref = file_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          file_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder setFile(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        file_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder clearFile() {
        bitField0_ = (bitField0_ & ~0x00000008);
        file_ = getDefaultInstance().getFile();
        onChanged();
        return this;
      }
      /**
       * <code>optional string file = 4;</code>
       */
      public Builder setFileBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        file_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object userInfo_ = "";
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public boolean hasUserInfo() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public java.lang.String getUserInfo() {
        java.lang.Object ref = userInfo_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            userInfo_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public com.google.protobuf.ByteString
          getUserInfoBytes() {
        java.lang.Object ref = userInfo_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          userInfo_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder setUserInfo(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        userInfo_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder clearUserInfo() {
        bitField0_ = (bitField0_ & ~0x00000010);
        userInfo_ = getDefaultInstance().getUserInfo();
        onChanged();
        return this;
      }
      /**
       * <code>optional string userInfo = 5;</code>
       */
      public Builder setUserInfoBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        userInfo_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.URLProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.URLProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.URLProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.URLProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.URLProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<URLProto>
        PARSER = new com.google.protobuf.AbstractParser<URLProto>() {
      public URLProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new URLProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<URLProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<URLProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface LocalResourceProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.LocalResourceProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource();
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder();

    /**
     * <code>optional int64 size = 2;</code>
     */
    boolean hasSize();
    /**
     * <code>optional int64 size = 2;</code>
     */
    long getSize();

    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    boolean hasTimestamp();
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    long getTimestamp();

    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    boolean hasType();
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType();

    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    boolean hasVisibility();
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility();

    /**
     * <code>optional string pattern = 6;</code>
     */
    boolean hasPattern();
    /**
     * <code>optional string pattern = 6;</code>
     */
    java.lang.String getPattern();
    /**
     * <code>optional string pattern = 6;</code>
     */
    com.google.protobuf.ByteString
        getPatternBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.LocalResourceProto}
   */
  public  static final class LocalResourceProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.LocalResourceProto)
      LocalResourceProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use LocalResourceProto.newBuilder() to construct.
    private LocalResourceProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private LocalResourceProto() {
      size_ = 0L;
      timestamp_ = 0L;
      type_ = 1;
      visibility_ = 1;
      pattern_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private LocalResourceProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.URLProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              size_ = input.readInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              timestamp_ = input.readInt64();
              break;
            }
            case 32: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(4, rawValue);
              } else {
                bitField0_ |= 0x00000008;
                type_ = rawValue;
              }
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto value = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                visibility_ = rawValue;
              }
              break;
            }
            case 50: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000020;
              pattern_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.URLProto resource_;
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance() : resource_;
    }
    /**
     * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance() : resource_;
    }

    public static final int SIZE_FIELD_NUMBER = 2;
    private long size_;
    /**
     * <code>optional int64 size = 2;</code>
     */
    public boolean hasSize() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 size = 2;</code>
     */
    public long getSize() {
      return size_;
    }

    public static final int TIMESTAMP_FIELD_NUMBER = 3;
    private long timestamp_;
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    public boolean hasTimestamp() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 timestamp = 3;</code>
     */
    public long getTimestamp() {
      return timestamp_;
    }

    public static final int TYPE_FIELD_NUMBER = 4;
    private int type_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    public boolean hasType() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType() {
      org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto result = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.valueOf(type_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE : result;
    }

    public static final int VISIBILITY_FIELD_NUMBER = 5;
    private int visibility_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    public boolean hasVisibility() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility() {
      org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto result = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.valueOf(visibility_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC : result;
    }

    public static final int PATTERN_FIELD_NUMBER = 6;
    private volatile java.lang.Object pattern_;
    /**
     * <code>optional string pattern = 6;</code>
     */
    public boolean hasPattern() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string pattern = 6;</code>
     */
    public java.lang.String getPattern() {
      java.lang.Object ref = pattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          pattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string pattern = 6;</code>
     */
    public com.google.protobuf.ByteString
        getPatternBytes() {
      java.lang.Object ref = pattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        pattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getResource());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, size_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeEnum(4, type_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, visibility_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, pattern_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getResource());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, size_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, timestamp_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(4, type_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, visibility_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, pattern_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto other = (org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasSize() == other.hasSize());
      if (hasSize()) {
        result = result && (getSize()
            == other.getSize());
      }
      result = result && (hasTimestamp() == other.hasTimestamp());
      if (hasTimestamp()) {
        result = result && (getTimestamp()
            == other.getTimestamp());
      }
      result = result && (hasType() == other.hasType());
      if (hasType()) {
        result = result && type_ == other.type_;
      }
      result = result && (hasVisibility() == other.hasVisibility());
      if (hasVisibility()) {
        result = result && visibility_ == other.visibility_;
      }
      result = result && (hasPattern() == other.hasPattern());
      if (hasPattern()) {
        result = result && getPattern()
            .equals(other.getPattern());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasSize()) {
        hash = (37 * hash) + SIZE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getSize());
      }
      if (hasTimestamp()) {
        hash = (37 * hash) + TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getTimestamp());
      }
      if (hasType()) {
        hash = (37 * hash) + TYPE_FIELD_NUMBER;
        hash = (53 * hash) + type_;
      }
      if (hasVisibility()) {
        hash = (37 * hash) + VISIBILITY_FIELD_NUMBER;
        hash = (53 * hash) + visibility_;
      }
      if (hasPattern()) {
        hash = (37 * hash) + PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getPattern().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.LocalResourceProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.LocalResourceProto)
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = null;
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        size_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        timestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        type_ = 1;
        bitField0_ = (bitField0_ & ~0x00000008);
        visibility_ = 1;
        bitField0_ = (bitField0_ & ~0x00000010);
        pattern_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LocalResourceProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto result = new org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.size_ = size_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.timestamp_ = timestamp_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.type_ = type_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.visibility_ = visibility_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.pattern_ = pattern_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasSize()) {
          setSize(other.getSize());
        }
        if (other.hasTimestamp()) {
          setTimestamp(other.getTimestamp());
        }
        if (other.hasType()) {
          setType(other.getType());
        }
        if (other.hasVisibility()) {
          setVisibility(other.getVisibility());
        }
        if (other.hasPattern()) {
          bitField0_ |= 0x00000020;
          pattern_ = other.pattern_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.URLProto resource_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance() : resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.URLProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.URLProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != null &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = null;
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto.getDefaultInstance() : resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.URLProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.URLProto, org.apache.hadoop.yarn.proto.YarnProtos.URLProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.URLProtoOrBuilder>(
                  getResource(),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      private long size_ ;
      /**
       * <code>optional int64 size = 2;</code>
       */
      public boolean hasSize() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public long getSize() {
        return size_;
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public Builder setSize(long value) {
        bitField0_ |= 0x00000002;
        size_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 size = 2;</code>
       */
      public Builder clearSize() {
        bitField0_ = (bitField0_ & ~0x00000002);
        size_ = 0L;
        onChanged();
        return this;
      }

      private long timestamp_ ;
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public boolean hasTimestamp() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public long getTimestamp() {
        return timestamp_;
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public Builder setTimestamp(long value) {
        bitField0_ |= 0x00000004;
        timestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 timestamp = 3;</code>
       */
      public Builder clearTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000004);
        timestamp_ = 0L;
        onChanged();
        return this;
      }

      private int type_ = 1;
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public boolean hasType() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto getType() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto result = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.valueOf(type_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto.ARCHIVE : result;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public Builder setType(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000008;
        type_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceTypeProto type = 4;</code>
       */
      public Builder clearType() {
        bitField0_ = (bitField0_ & ~0x00000008);
        type_ = 1;
        onChanged();
        return this;
      }

      private int visibility_ = 1;
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public boolean hasVisibility() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto getVisibility() {
        org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto result = org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.valueOf(visibility_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto.PUBLIC : result;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public Builder setVisibility(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceVisibilityProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        visibility_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceVisibilityProto visibility = 5;</code>
       */
      public Builder clearVisibility() {
        bitField0_ = (bitField0_ & ~0x00000010);
        visibility_ = 1;
        onChanged();
        return this;
      }

      private java.lang.Object pattern_ = "";
      /**
       * <code>optional string pattern = 6;</code>
       */
      public boolean hasPattern() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public java.lang.String getPattern() {
        java.lang.Object ref = pattern_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            pattern_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public com.google.protobuf.ByteString
          getPatternBytes() {
        java.lang.Object ref = pattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          pattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder setPattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        pattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder clearPattern() {
        bitField0_ = (bitField0_ & ~0x00000020);
        pattern_ = getDefaultInstance().getPattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string pattern = 6;</code>
       */
      public Builder setPatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        pattern_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.LocalResourceProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.LocalResourceProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<LocalResourceProto>
        PARSER = new com.google.protobuf.AbstractParser<LocalResourceProto>() {
      public LocalResourceProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new LocalResourceProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<LocalResourceProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<LocalResourceProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationResourceUsageReportProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ApplicationResourceUsageReportProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    boolean hasNumUsedContainers();
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    int getNumUsedContainers();

    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    boolean hasNumReservedContainers();
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    int getNumReservedContainers();

    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    boolean hasUsedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    boolean hasReservedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    boolean hasNeededResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources();
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder();

    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    boolean hasMemorySeconds();
    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    long getMemorySeconds();

    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    boolean hasVcoreSeconds();
    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    long getVcoreSeconds();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationResourceUsageReportProto}
   */
  public  static final class ApplicationResourceUsageReportProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ApplicationResourceUsageReportProto)
      ApplicationResourceUsageReportProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationResourceUsageReportProto.newBuilder() to construct.
    private ApplicationResourceUsageReportProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationResourceUsageReportProto() {
      numUsedContainers_ = 0;
      numReservedContainers_ = 0;
      memorySeconds_ = 0L;
      vcoreSeconds_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationResourceUsageReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numUsedContainers_ = input.readInt32();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numReservedContainers_ = input.readInt32();
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = usedResources_.toBuilder();
              }
              usedResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(usedResources_);
                usedResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = reservedResources_.toBuilder();
              }
              reservedResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservedResources_);
                reservedResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = neededResources_.toBuilder();
              }
              neededResources_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(neededResources_);
                neededResources_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              memorySeconds_ = input.readInt64();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              vcoreSeconds_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder.class);
    }

    private int bitField0_;
    public static final int NUM_USED_CONTAINERS_FIELD_NUMBER = 1;
    private int numUsedContainers_;
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    public boolean hasNumUsedContainers() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 num_used_containers = 1;</code>
     */
    public int getNumUsedContainers() {
      return numUsedContainers_;
    }

    public static final int NUM_RESERVED_CONTAINERS_FIELD_NUMBER = 2;
    private int numReservedContainers_;
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    public boolean hasNumReservedContainers() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 num_reserved_containers = 2;</code>
     */
    public int getNumReservedContainers() {
      return numReservedContainers_;
    }

    public static final int USED_RESOURCES_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto usedResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public boolean hasUsedResources() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources() {
      return usedResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : usedResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder() {
      return usedResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : usedResources_;
    }

    public static final int RESERVED_RESOURCES_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto reservedResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public boolean hasReservedResources() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources() {
      return reservedResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : reservedResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder() {
      return reservedResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : reservedResources_;
    }

    public static final int NEEDED_RESOURCES_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto neededResources_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public boolean hasNeededResources() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources() {
      return neededResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : neededResources_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder() {
      return neededResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : neededResources_;
    }

    public static final int MEMORY_SECONDS_FIELD_NUMBER = 6;
    private long memorySeconds_;
    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    public boolean hasMemorySeconds() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int64 memory_seconds = 6;</code>
     */
    public long getMemorySeconds() {
      return memorySeconds_;
    }

    public static final int VCORE_SECONDS_FIELD_NUMBER = 7;
    private long vcoreSeconds_;
    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    public boolean hasVcoreSeconds() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional int64 vcore_seconds = 7;</code>
     */
    public long getVcoreSeconds() {
      return vcoreSeconds_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, numUsedContainers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, numReservedContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getUsedResources());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getReservedResources());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, getNeededResources());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt64(6, memorySeconds_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeInt64(7, vcoreSeconds_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, numUsedContainers_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, numReservedContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getUsedResources());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getReservedResources());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getNeededResources());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(6, memorySeconds_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(7, vcoreSeconds_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) obj;

      boolean result = true;
      result = result && (hasNumUsedContainers() == other.hasNumUsedContainers());
      if (hasNumUsedContainers()) {
        result = result && (getNumUsedContainers()
            == other.getNumUsedContainers());
      }
      result = result && (hasNumReservedContainers() == other.hasNumReservedContainers());
      if (hasNumReservedContainers()) {
        result = result && (getNumReservedContainers()
            == other.getNumReservedContainers());
      }
      result = result && (hasUsedResources() == other.hasUsedResources());
      if (hasUsedResources()) {
        result = result && getUsedResources()
            .equals(other.getUsedResources());
      }
      result = result && (hasReservedResources() == other.hasReservedResources());
      if (hasReservedResources()) {
        result = result && getReservedResources()
            .equals(other.getReservedResources());
      }
      result = result && (hasNeededResources() == other.hasNeededResources());
      if (hasNeededResources()) {
        result = result && getNeededResources()
            .equals(other.getNeededResources());
      }
      result = result && (hasMemorySeconds() == other.hasMemorySeconds());
      if (hasMemorySeconds()) {
        result = result && (getMemorySeconds()
            == other.getMemorySeconds());
      }
      result = result && (hasVcoreSeconds() == other.hasVcoreSeconds());
      if (hasVcoreSeconds()) {
        result = result && (getVcoreSeconds()
            == other.getVcoreSeconds());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNumUsedContainers()) {
        hash = (37 * hash) + NUM_USED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumUsedContainers();
      }
      if (hasNumReservedContainers()) {
        hash = (37 * hash) + NUM_RESERVED_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumReservedContainers();
      }
      if (hasUsedResources()) {
        hash = (37 * hash) + USED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getUsedResources().hashCode();
      }
      if (hasReservedResources()) {
        hash = (37 * hash) + RESERVED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getReservedResources().hashCode();
      }
      if (hasNeededResources()) {
        hash = (37 * hash) + NEEDED_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getNeededResources().hashCode();
      }
      if (hasMemorySeconds()) {
        hash = (37 * hash) + MEMORY_SECONDS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getMemorySeconds());
      }
      if (hasVcoreSeconds()) {
        hash = (37 * hash) + VCORE_SECONDS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getVcoreSeconds());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationResourceUsageReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ApplicationResourceUsageReportProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getUsedResourcesFieldBuilder();
          getReservedResourcesFieldBuilder();
          getNeededResourcesFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        numUsedContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        numReservedContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (usedResourcesBuilder_ == null) {
          usedResources_ = null;
        } else {
          usedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = null;
        } else {
          reservedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (neededResourcesBuilder_ == null) {
          neededResources_ = null;
        } else {
          neededResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        memorySeconds_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000020);
        vcoreSeconds_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numUsedContainers_ = numUsedContainers_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numReservedContainers_ = numReservedContainers_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (usedResourcesBuilder_ == null) {
          result.usedResources_ = usedResources_;
        } else {
          result.usedResources_ = usedResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (reservedResourcesBuilder_ == null) {
          result.reservedResources_ = reservedResources_;
        } else {
          result.reservedResources_ = reservedResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (neededResourcesBuilder_ == null) {
          result.neededResources_ = neededResources_;
        } else {
          result.neededResources_ = neededResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.memorySeconds_ = memorySeconds_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.vcoreSeconds_ = vcoreSeconds_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance()) return this;
        if (other.hasNumUsedContainers()) {
          setNumUsedContainers(other.getNumUsedContainers());
        }
        if (other.hasNumReservedContainers()) {
          setNumReservedContainers(other.getNumReservedContainers());
        }
        if (other.hasUsedResources()) {
          mergeUsedResources(other.getUsedResources());
        }
        if (other.hasReservedResources()) {
          mergeReservedResources(other.getReservedResources());
        }
        if (other.hasNeededResources()) {
          mergeNeededResources(other.getNeededResources());
        }
        if (other.hasMemorySeconds()) {
          setMemorySeconds(other.getMemorySeconds());
        }
        if (other.hasVcoreSeconds()) {
          setVcoreSeconds(other.getVcoreSeconds());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int numUsedContainers_ ;
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public boolean hasNumUsedContainers() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public int getNumUsedContainers() {
        return numUsedContainers_;
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public Builder setNumUsedContainers(int value) {
        bitField0_ |= 0x00000001;
        numUsedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_used_containers = 1;</code>
       */
      public Builder clearNumUsedContainers() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numUsedContainers_ = 0;
        onChanged();
        return this;
      }

      private int numReservedContainers_ ;
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public boolean hasNumReservedContainers() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public int getNumReservedContainers() {
        return numReservedContainers_;
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public Builder setNumReservedContainers(int value) {
        bitField0_ |= 0x00000002;
        numReservedContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_reserved_containers = 2;</code>
       */
      public Builder clearNumReservedContainers() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numReservedContainers_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto usedResources_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> usedResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public boolean hasUsedResources() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsedResources() {
        if (usedResourcesBuilder_ == null) {
          return usedResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : usedResources_;
        } else {
          return usedResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder setUsedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          usedResources_ = value;
          onChanged();
        } else {
          usedResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder setUsedResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (usedResourcesBuilder_ == null) {
          usedResources_ = builderForValue.build();
          onChanged();
        } else {
          usedResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder mergeUsedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              usedResources_ != null &&
              usedResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            usedResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(usedResources_).mergeFrom(value).buildPartial();
          } else {
            usedResources_ = value;
          }
          onChanged();
        } else {
          usedResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public Builder clearUsedResources() {
        if (usedResourcesBuilder_ == null) {
          usedResources_ = null;
          onChanged();
        } else {
          usedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getUsedResourcesBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getUsedResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedResourcesOrBuilder() {
        if (usedResourcesBuilder_ != null) {
          return usedResourcesBuilder_.getMessageOrBuilder();
        } else {
          return usedResources_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : usedResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used_resources = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getUsedResourcesFieldBuilder() {
        if (usedResourcesBuilder_ == null) {
          usedResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getUsedResources(),
                  getParentForChildren(),
                  isClean());
          usedResources_ = null;
        }
        return usedResourcesBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto reservedResources_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> reservedResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public boolean hasReservedResources() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getReservedResources() {
        if (reservedResourcesBuilder_ == null) {
          return reservedResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : reservedResources_;
        } else {
          return reservedResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder setReservedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (reservedResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservedResources_ = value;
          onChanged();
        } else {
          reservedResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder setReservedResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = builderForValue.build();
          onChanged();
        } else {
          reservedResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder mergeReservedResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (reservedResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              reservedResources_ != null &&
              reservedResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            reservedResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(reservedResources_).mergeFrom(value).buildPartial();
          } else {
            reservedResources_ = value;
          }
          onChanged();
        } else {
          reservedResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public Builder clearReservedResources() {
        if (reservedResourcesBuilder_ == null) {
          reservedResources_ = null;
          onChanged();
        } else {
          reservedResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getReservedResourcesBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getReservedResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getReservedResourcesOrBuilder() {
        if (reservedResourcesBuilder_ != null) {
          return reservedResourcesBuilder_.getMessageOrBuilder();
        } else {
          return reservedResources_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : reservedResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto reserved_resources = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getReservedResourcesFieldBuilder() {
        if (reservedResourcesBuilder_ == null) {
          reservedResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getReservedResources(),
                  getParentForChildren(),
                  isClean());
          reservedResources_ = null;
        }
        return reservedResourcesBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto neededResources_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> neededResourcesBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public boolean hasNeededResources() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getNeededResources() {
        if (neededResourcesBuilder_ == null) {
          return neededResources_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : neededResources_;
        } else {
          return neededResourcesBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder setNeededResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (neededResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          neededResources_ = value;
          onChanged();
        } else {
          neededResourcesBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder setNeededResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (neededResourcesBuilder_ == null) {
          neededResources_ = builderForValue.build();
          onChanged();
        } else {
          neededResourcesBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder mergeNeededResources(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (neededResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              neededResources_ != null &&
              neededResources_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            neededResources_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(neededResources_).mergeFrom(value).buildPartial();
          } else {
            neededResources_ = value;
          }
          onChanged();
        } else {
          neededResourcesBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public Builder clearNeededResources() {
        if (neededResourcesBuilder_ == null) {
          neededResources_ = null;
          onChanged();
        } else {
          neededResourcesBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getNeededResourcesBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getNeededResourcesFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getNeededResourcesOrBuilder() {
        if (neededResourcesBuilder_ != null) {
          return neededResourcesBuilder_.getMessageOrBuilder();
        } else {
          return neededResources_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : neededResources_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto needed_resources = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getNeededResourcesFieldBuilder() {
        if (neededResourcesBuilder_ == null) {
          neededResourcesBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getNeededResources(),
                  getParentForChildren(),
                  isClean());
          neededResources_ = null;
        }
        return neededResourcesBuilder_;
      }

      private long memorySeconds_ ;
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public boolean hasMemorySeconds() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public long getMemorySeconds() {
        return memorySeconds_;
      }
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public Builder setMemorySeconds(long value) {
        bitField0_ |= 0x00000020;
        memorySeconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 memory_seconds = 6;</code>
       */
      public Builder clearMemorySeconds() {
        bitField0_ = (bitField0_ & ~0x00000020);
        memorySeconds_ = 0L;
        onChanged();
        return this;
      }

      private long vcoreSeconds_ ;
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public boolean hasVcoreSeconds() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public long getVcoreSeconds() {
        return vcoreSeconds_;
      }
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public Builder setVcoreSeconds(long value) {
        bitField0_ |= 0x00000040;
        vcoreSeconds_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 vcore_seconds = 7;</code>
       */
      public Builder clearVcoreSeconds() {
        bitField0_ = (bitField0_ & ~0x00000040);
        vcoreSeconds_ = 0L;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationResourceUsageReportProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationResourceUsageReportProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApplicationResourceUsageReportProto>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationResourceUsageReportProto>() {
      public ApplicationResourceUsageReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ApplicationResourceUsageReportProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationResourceUsageReportProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationResourceUsageReportProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationReportProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ApplicationReportProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>optional string user = 2;</code>
     */
    boolean hasUser();
    /**
     * <code>optional string user = 2;</code>
     */
    java.lang.String getUser();
    /**
     * <code>optional string user = 2;</code>
     */
    com.google.protobuf.ByteString
        getUserBytes();

    /**
     * <code>optional string queue = 3;</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 3;</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 3;</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    /**
     * <code>optional string name = 4;</code>
     */
    boolean hasName();
    /**
     * <code>optional string name = 4;</code>
     */
    java.lang.String getName();
    /**
     * <code>optional string name = 4;</code>
     */
    com.google.protobuf.ByteString
        getNameBytes();

    /**
     * <code>optional string host = 5;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 5;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 5;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    boolean hasRpcPort();
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    int getRpcPort();

    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    boolean hasClientToAmToken();
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken();
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder();

    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    boolean hasYarnApplicationState();
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState();

    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    boolean hasTrackingUrl();
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    java.lang.String getTrackingUrl();
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    com.google.protobuf.ByteString
        getTrackingUrlBytes();

    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    /**
     * <code>optional int64 startTime = 11;</code>
     */
    boolean hasStartTime();
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    long getStartTime();

    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    boolean hasFinishTime();
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    long getFinishTime();

    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    boolean hasFinalApplicationStatus();
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus();

    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    boolean hasAppResourceUsage();
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage();
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder();

    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    boolean hasOriginalTrackingUrl();
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    java.lang.String getOriginalTrackingUrl();
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes();

    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    boolean hasCurrentApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder();

    /**
     * <code>optional float progress = 17;</code>
     */
    boolean hasProgress();
    /**
     * <code>optional float progress = 17;</code>
     */
    float getProgress();

    /**
     * <code>optional string applicationType = 18;</code>
     */
    boolean hasApplicationType();
    /**
     * <code>optional string applicationType = 18;</code>
     */
    java.lang.String getApplicationType();
    /**
     * <code>optional string applicationType = 18;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTypeBytes();

    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    boolean hasAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken();
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder();

    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    java.util.List<java.lang.String>
        getApplicationTagsList();
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    int getApplicationTagsCount();
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    java.lang.String getApplicationTags(int index);
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTagsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationReportProto}
   */
  public  static final class ApplicationReportProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ApplicationReportProto)
      ApplicationReportProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationReportProto.newBuilder() to construct.
    private ApplicationReportProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationReportProto() {
      user_ = "";
      queue_ = "";
      name_ = "";
      host_ = "";
      rpcPort_ = 0;
      yarnApplicationState_ = 1;
      trackingUrl_ = "";
      diagnostics_ = "N/A";
      startTime_ = 0L;
      finishTime_ = 0L;
      finalApplicationStatus_ = 0;
      originalTrackingUrl_ = "";
      progress_ = 0F;
      applicationType_ = "";
      applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              user_ = bs;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              queue_ = bs;
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000008;
              name_ = bs;
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000010;
              host_ = bs;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              rpcPort_ = input.readInt32();
              break;
            }
            case 58: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = clientToAmToken_.toBuilder();
              }
              clientToAmToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(clientToAmToken_);
                clientToAmToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 64: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(8, rawValue);
              } else {
                bitField0_ |= 0x00000080;
                yarnApplicationState_ = rawValue;
              }
              break;
            }
            case 74: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000100;
              trackingUrl_ = bs;
              break;
            }
            case 82: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000200;
              diagnostics_ = bs;
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              startTime_ = input.readInt64();
              break;
            }
            case 96: {
              bitField0_ |= 0x00000800;
              finishTime_ = input.readInt64();
              break;
            }
            case 104: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(13, rawValue);
              } else {
                bitField0_ |= 0x00001000;
                finalApplicationStatus_ = rawValue;
              }
              break;
            }
            case 114: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00002000) == 0x00002000)) {
                subBuilder = appResourceUsage_.toBuilder();
              }
              appResourceUsage_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(appResourceUsage_);
                appResourceUsage_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00002000;
              break;
            }
            case 122: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00004000;
              originalTrackingUrl_ = bs;
              break;
            }
            case 130: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00008000) == 0x00008000)) {
                subBuilder = currentApplicationAttemptId_.toBuilder();
              }
              currentApplicationAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(currentApplicationAttemptId_);
                currentApplicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00008000;
              break;
            }
            case 141: {
              bitField0_ |= 0x00010000;
              progress_ = input.readFloat();
              break;
            }
            case 146: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00020000;
              applicationType_ = bs;
              break;
            }
            case 154: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00040000) == 0x00040000)) {
                subBuilder = amRmToken_.toBuilder();
              }
              amRmToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amRmToken_);
                amRmToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00040000;
              break;
            }
            case 162: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00080000) == 0x00080000)) {
                applicationTags_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00080000;
              }
              applicationTags_.add(bs);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00080000) == 0x00080000)) {
          applicationTags_ = applicationTags_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATIONID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int USER_FIELD_NUMBER = 2;
    private volatile java.lang.Object user_;
    /**
     * <code>optional string user = 2;</code>
     */
    public boolean hasUser() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string user = 2;</code>
     */
    public java.lang.String getUser() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          user_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string user = 2;</code>
     */
    public com.google.protobuf.ByteString
        getUserBytes() {
      java.lang.Object ref = user_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        user_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int QUEUE_FIELD_NUMBER = 3;
    private volatile java.lang.Object queue_;
    /**
     * <code>optional string queue = 3;</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string queue = 3;</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 3;</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int NAME_FIELD_NUMBER = 4;
    private volatile java.lang.Object name_;
    /**
     * <code>optional string name = 4;</code>
     */
    public boolean hasName() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string name = 4;</code>
     */
    public java.lang.String getName() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          name_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string name = 4;</code>
     */
    public com.google.protobuf.ByteString
        getNameBytes() {
      java.lang.Object ref = name_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        name_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int HOST_FIELD_NUMBER = 5;
    private volatile java.lang.Object host_;
    /**
     * <code>optional string host = 5;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string host = 5;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 5;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RPC_PORT_FIELD_NUMBER = 6;
    private int rpcPort_;
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    public boolean hasRpcPort() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 rpc_port = 6;</code>
     */
    public int getRpcPort() {
      return rpcPort_;
    }

    public static final int CLIENT_TO_AM_TOKEN_FIELD_NUMBER = 7;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto clientToAmToken_;
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public boolean hasClientToAmToken() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken() {
      return clientToAmToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : clientToAmToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder() {
      return clientToAmToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : clientToAmToken_;
    }

    public static final int YARN_APPLICATION_STATE_FIELD_NUMBER = 8;
    private int yarnApplicationState_;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    public boolean hasYarnApplicationState() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState() {
      org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(yarnApplicationState_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW : result;
    }

    public static final int TRACKINGURL_FIELD_NUMBER = 9;
    private volatile java.lang.Object trackingUrl_;
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public java.lang.String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string trackingUrl = 9;</code>
     */
    public com.google.protobuf.ByteString
        getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DIAGNOSTICS_FIELD_NUMBER = 10;
    private volatile java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 10 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int STARTTIME_FIELD_NUMBER = 11;
    private long startTime_;
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    public boolean hasStartTime() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional int64 startTime = 11;</code>
     */
    public long getStartTime() {
      return startTime_;
    }

    public static final int FINISHTIME_FIELD_NUMBER = 12;
    private long finishTime_;
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    public boolean hasFinishTime() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional int64 finishTime = 12;</code>
     */
    public long getFinishTime() {
      return finishTime_;
    }

    public static final int FINAL_APPLICATION_STATUS_FIELD_NUMBER = 13;
    private int finalApplicationStatus_;
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    public boolean hasFinalApplicationStatus() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    /**
     * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
      org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto result = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(finalApplicationStatus_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED : result;
    }

    public static final int APP_RESOURCE_USAGE_FIELD_NUMBER = 14;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto appResourceUsage_;
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public boolean hasAppResourceUsage() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage() {
      return appResourceUsage_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance() : appResourceUsage_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder() {
      return appResourceUsage_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance() : appResourceUsage_;
    }

    public static final int ORIGINALTRACKINGURL_FIELD_NUMBER = 15;
    private volatile java.lang.Object originalTrackingUrl_;
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public boolean hasOriginalTrackingUrl() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public java.lang.String getOriginalTrackingUrl() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          originalTrackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string originalTrackingUrl = 15;</code>
     */
    public com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        originalTrackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CURRENTAPPLICATIONATTEMPTID_FIELD_NUMBER = 16;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto currentApplicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public boolean hasCurrentApplicationAttemptId() {
      return ((bitField0_ & 0x00008000) == 0x00008000);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId() {
      return currentApplicationAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : currentApplicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder() {
      return currentApplicationAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : currentApplicationAttemptId_;
    }

    public static final int PROGRESS_FIELD_NUMBER = 17;
    private float progress_;
    /**
     * <code>optional float progress = 17;</code>
     */
    public boolean hasProgress() {
      return ((bitField0_ & 0x00010000) == 0x00010000);
    }
    /**
     * <code>optional float progress = 17;</code>
     */
    public float getProgress() {
      return progress_;
    }

    public static final int APPLICATIONTYPE_FIELD_NUMBER = 18;
    private volatile java.lang.Object applicationType_;
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public boolean hasApplicationType() {
      return ((bitField0_ & 0x00020000) == 0x00020000);
    }
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public java.lang.String getApplicationType() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationType_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string applicationType = 18;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTypeBytes() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int AM_RM_TOKEN_FIELD_NUMBER = 19;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_;
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public boolean hasAmRmToken() {
      return ((bitField0_ & 0x00040000) == 0x00040000);
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
      return amRmToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
      return amRmToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
    }

    public static final int APPLICATIONTAGS_FIELD_NUMBER = 20;
    private com.google.protobuf.LazyStringList applicationTags_;
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getApplicationTagsList() {
      return applicationTags_;
    }
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public int getApplicationTagsCount() {
      return applicationTags_.size();
    }
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public java.lang.String getApplicationTags(int index) {
      return applicationTags_.get(index);
    }
    /**
     * <code>repeated string applicationTags = 20;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTagsBytes(int index) {
      return applicationTags_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasClientToAmToken()) {
        if (!getClientToAmToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      if (hasAmRmToken()) {
        if (!getAmRmToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, user_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, queue_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, name_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, host_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, rpcPort_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(7, getClientToAmToken());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeEnum(8, yarnApplicationState_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 9, trackingUrl_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, diagnostics_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeInt64(11, startTime_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeInt64(12, finishTime_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeEnum(13, finalApplicationStatus_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeMessage(14, getAppResourceUsage());
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 15, originalTrackingUrl_);
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        output.writeMessage(16, getCurrentApplicationAttemptId());
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        output.writeFloat(17, progress_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 18, applicationType_);
      }
      if (((bitField0_ & 0x00040000) == 0x00040000)) {
        output.writeMessage(19, getAmRmToken());
      }
      for (int i = 0; i < applicationTags_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 20, applicationTags_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, user_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, queue_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, name_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, host_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, rpcPort_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getClientToAmToken());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(8, yarnApplicationState_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(9, trackingUrl_);
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(10, diagnostics_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(11, startTime_);
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(12, finishTime_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(13, finalApplicationStatus_);
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getAppResourceUsage());
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(15, originalTrackingUrl_);
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(16, getCurrentApplicationAttemptId());
      }
      if (((bitField0_ & 0x00010000) == 0x00010000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(17, progress_);
      }
      if (((bitField0_ & 0x00020000) == 0x00020000)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(18, applicationType_);
      }
      if (((bitField0_ & 0x00040000) == 0x00040000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(19, getAmRmToken());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < applicationTags_.size(); i++) {
          dataSize += computeStringSizeNoTag(applicationTags_.getRaw(i));
        }
        size += dataSize;
        size += 2 * getApplicationTagsList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasUser() == other.hasUser());
      if (hasUser()) {
        result = result && getUser()
            .equals(other.getUser());
      }
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasName() == other.hasName());
      if (hasName()) {
        result = result && getName()
            .equals(other.getName());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasRpcPort() == other.hasRpcPort());
      if (hasRpcPort()) {
        result = result && (getRpcPort()
            == other.getRpcPort());
      }
      result = result && (hasClientToAmToken() == other.hasClientToAmToken());
      if (hasClientToAmToken()) {
        result = result && getClientToAmToken()
            .equals(other.getClientToAmToken());
      }
      result = result && (hasYarnApplicationState() == other.hasYarnApplicationState());
      if (hasYarnApplicationState()) {
        result = result && yarnApplicationState_ == other.yarnApplicationState_;
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasStartTime() == other.hasStartTime());
      if (hasStartTime()) {
        result = result && (getStartTime()
            == other.getStartTime());
      }
      result = result && (hasFinishTime() == other.hasFinishTime());
      if (hasFinishTime()) {
        result = result && (getFinishTime()
            == other.getFinishTime());
      }
      result = result && (hasFinalApplicationStatus() == other.hasFinalApplicationStatus());
      if (hasFinalApplicationStatus()) {
        result = result && finalApplicationStatus_ == other.finalApplicationStatus_;
      }
      result = result && (hasAppResourceUsage() == other.hasAppResourceUsage());
      if (hasAppResourceUsage()) {
        result = result && getAppResourceUsage()
            .equals(other.getAppResourceUsage());
      }
      result = result && (hasOriginalTrackingUrl() == other.hasOriginalTrackingUrl());
      if (hasOriginalTrackingUrl()) {
        result = result && getOriginalTrackingUrl()
            .equals(other.getOriginalTrackingUrl());
      }
      result = result && (hasCurrentApplicationAttemptId() == other.hasCurrentApplicationAttemptId());
      if (hasCurrentApplicationAttemptId()) {
        result = result && getCurrentApplicationAttemptId()
            .equals(other.getCurrentApplicationAttemptId());
      }
      result = result && (hasProgress() == other.hasProgress());
      if (hasProgress()) {
        result = result && (
            java.lang.Float.floatToIntBits(getProgress())
            == java.lang.Float.floatToIntBits(
                other.getProgress()));
      }
      result = result && (hasApplicationType() == other.hasApplicationType());
      if (hasApplicationType()) {
        result = result && getApplicationType()
            .equals(other.getApplicationType());
      }
      result = result && (hasAmRmToken() == other.hasAmRmToken());
      if (hasAmRmToken()) {
        result = result && getAmRmToken()
            .equals(other.getAmRmToken());
      }
      result = result && getApplicationTagsList()
          .equals(other.getApplicationTagsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATIONID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasUser()) {
        hash = (37 * hash) + USER_FIELD_NUMBER;
        hash = (53 * hash) + getUser().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasName()) {
        hash = (37 * hash) + NAME_FIELD_NUMBER;
        hash = (53 * hash) + getName().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasRpcPort()) {
        hash = (37 * hash) + RPC_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getRpcPort();
      }
      if (hasClientToAmToken()) {
        hash = (37 * hash) + CLIENT_TO_AM_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getClientToAmToken().hashCode();
      }
      if (hasYarnApplicationState()) {
        hash = (37 * hash) + YARN_APPLICATION_STATE_FIELD_NUMBER;
        hash = (53 * hash) + yarnApplicationState_;
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKINGURL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasStartTime()) {
        hash = (37 * hash) + STARTTIME_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getStartTime());
      }
      if (hasFinishTime()) {
        hash = (37 * hash) + FINISHTIME_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getFinishTime());
      }
      if (hasFinalApplicationStatus()) {
        hash = (37 * hash) + FINAL_APPLICATION_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + finalApplicationStatus_;
      }
      if (hasAppResourceUsage()) {
        hash = (37 * hash) + APP_RESOURCE_USAGE_FIELD_NUMBER;
        hash = (53 * hash) + getAppResourceUsage().hashCode();
      }
      if (hasOriginalTrackingUrl()) {
        hash = (37 * hash) + ORIGINALTRACKINGURL_FIELD_NUMBER;
        hash = (53 * hash) + getOriginalTrackingUrl().hashCode();
      }
      if (hasCurrentApplicationAttemptId()) {
        hash = (37 * hash) + CURRENTAPPLICATIONATTEMPTID_FIELD_NUMBER;
        hash = (53 * hash) + getCurrentApplicationAttemptId().hashCode();
      }
      if (hasProgress()) {
        hash = (37 * hash) + PROGRESS_FIELD_NUMBER;
        hash = (53 * hash) + java.lang.Float.floatToIntBits(
            getProgress());
      }
      if (hasApplicationType()) {
        hash = (37 * hash) + APPLICATIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationType().hashCode();
      }
      if (hasAmRmToken()) {
        hash = (37 * hash) + AM_RM_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getAmRmToken().hashCode();
      }
      if (getApplicationTagsCount() > 0) {
        hash = (37 * hash) + APPLICATIONTAGS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTagsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ApplicationReportProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getClientToAmTokenFieldBuilder();
          getAppResourceUsageFieldBuilder();
          getCurrentApplicationAttemptIdFieldBuilder();
          getAmRmTokenFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        user_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        queue_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        name_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000010);
        rpcPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = null;
        } else {
          clientToAmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        yarnApplicationState_ = 1;
        bitField0_ = (bitField0_ & ~0x00000080);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000100);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000200);
        startTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000400);
        finishTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000800);
        finalApplicationStatus_ = 0;
        bitField0_ = (bitField0_ & ~0x00001000);
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = null;
        } else {
          appResourceUsageBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        originalTrackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00004000);
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = null;
        } else {
          currentApplicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00008000);
        progress_ = 0F;
        bitField0_ = (bitField0_ & ~0x00010000);
        applicationType_ = "";
        bitField0_ = (bitField0_ & ~0x00020000);
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = null;
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00040000);
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00080000);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.user_ = user_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.name_ = name_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.rpcPort_ = rpcPort_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        if (clientToAmTokenBuilder_ == null) {
          result.clientToAmToken_ = clientToAmToken_;
        } else {
          result.clientToAmToken_ = clientToAmTokenBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.yarnApplicationState_ = yarnApplicationState_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.trackingUrl_ = trackingUrl_;
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.startTime_ = startTime_;
        if (((from_bitField0_ & 0x00000800) == 0x00000800)) {
          to_bitField0_ |= 0x00000800;
        }
        result.finishTime_ = finishTime_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00001000;
        }
        result.finalApplicationStatus_ = finalApplicationStatus_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00002000;
        }
        if (appResourceUsageBuilder_ == null) {
          result.appResourceUsage_ = appResourceUsage_;
        } else {
          result.appResourceUsage_ = appResourceUsageBuilder_.build();
        }
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.originalTrackingUrl_ = originalTrackingUrl_;
        if (((from_bitField0_ & 0x00008000) == 0x00008000)) {
          to_bitField0_ |= 0x00008000;
        }
        if (currentApplicationAttemptIdBuilder_ == null) {
          result.currentApplicationAttemptId_ = currentApplicationAttemptId_;
        } else {
          result.currentApplicationAttemptId_ = currentApplicationAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00010000) == 0x00010000)) {
          to_bitField0_ |= 0x00010000;
        }
        result.progress_ = progress_;
        if (((from_bitField0_ & 0x00020000) == 0x00020000)) {
          to_bitField0_ |= 0x00020000;
        }
        result.applicationType_ = applicationType_;
        if (((from_bitField0_ & 0x00040000) == 0x00040000)) {
          to_bitField0_ |= 0x00040000;
        }
        if (amRmTokenBuilder_ == null) {
          result.amRmToken_ = amRmToken_;
        } else {
          result.amRmToken_ = amRmTokenBuilder_.build();
        }
        if (((bitField0_ & 0x00080000) == 0x00080000)) {
          applicationTags_ = applicationTags_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00080000);
        }
        result.applicationTags_ = applicationTags_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasUser()) {
          bitField0_ |= 0x00000002;
          user_ = other.user_;
          onChanged();
        }
        if (other.hasQueue()) {
          bitField0_ |= 0x00000004;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasName()) {
          bitField0_ |= 0x00000008;
          name_ = other.name_;
          onChanged();
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000010;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasRpcPort()) {
          setRpcPort(other.getRpcPort());
        }
        if (other.hasClientToAmToken()) {
          mergeClientToAmToken(other.getClientToAmToken());
        }
        if (other.hasYarnApplicationState()) {
          setYarnApplicationState(other.getYarnApplicationState());
        }
        if (other.hasTrackingUrl()) {
          bitField0_ |= 0x00000100;
          trackingUrl_ = other.trackingUrl_;
          onChanged();
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000200;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasStartTime()) {
          setStartTime(other.getStartTime());
        }
        if (other.hasFinishTime()) {
          setFinishTime(other.getFinishTime());
        }
        if (other.hasFinalApplicationStatus()) {
          setFinalApplicationStatus(other.getFinalApplicationStatus());
        }
        if (other.hasAppResourceUsage()) {
          mergeAppResourceUsage(other.getAppResourceUsage());
        }
        if (other.hasOriginalTrackingUrl()) {
          bitField0_ |= 0x00004000;
          originalTrackingUrl_ = other.originalTrackingUrl_;
          onChanged();
        }
        if (other.hasCurrentApplicationAttemptId()) {
          mergeCurrentApplicationAttemptId(other.getCurrentApplicationAttemptId());
        }
        if (other.hasProgress()) {
          setProgress(other.getProgress());
        }
        if (other.hasApplicationType()) {
          bitField0_ |= 0x00020000;
          applicationType_ = other.applicationType_;
          onChanged();
        }
        if (other.hasAmRmToken()) {
          mergeAmRmToken(other.getAmRmToken());
        }
        if (!other.applicationTags_.isEmpty()) {
          if (applicationTags_.isEmpty()) {
            applicationTags_ = other.applicationTags_;
            bitField0_ = (bitField0_ & ~0x00080000);
          } else {
            ensureApplicationTagsIsMutable();
            applicationTags_.addAll(other.applicationTags_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasClientToAmToken()) {
          if (!getClientToAmToken().isInitialized()) {
            return false;
          }
        }
        if (hasAmRmToken()) {
          if (!getAmRmToken().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto applicationId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private java.lang.Object user_ = "";
      /**
       * <code>optional string user = 2;</code>
       */
      public boolean hasUser() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public java.lang.String getUser() {
        java.lang.Object ref = user_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            user_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public com.google.protobuf.ByteString
          getUserBytes() {
        java.lang.Object ref = user_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          user_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder setUser(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        user_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder clearUser() {
        bitField0_ = (bitField0_ & ~0x00000002);
        user_ = getDefaultInstance().getUser();
        onChanged();
        return this;
      }
      /**
       * <code>optional string user = 2;</code>
       */
      public Builder setUserBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        user_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object queue_ = "";
      /**
       * <code>optional string queue = 3;</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000004);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3;</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object name_ = "";
      /**
       * <code>optional string name = 4;</code>
       */
      public boolean hasName() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public java.lang.String getName() {
        java.lang.Object ref = name_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            name_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public com.google.protobuf.ByteString
          getNameBytes() {
        java.lang.Object ref = name_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          name_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder setName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        name_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder clearName() {
        bitField0_ = (bitField0_ & ~0x00000008);
        name_ = getDefaultInstance().getName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string name = 4;</code>
       */
      public Builder setNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        name_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 5;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            host_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000010);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 5;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        host_ = value;
        onChanged();
        return this;
      }

      private int rpcPort_ ;
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public boolean hasRpcPort() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public int getRpcPort() {
        return rpcPort_;
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public Builder setRpcPort(int value) {
        bitField0_ |= 0x00000020;
        rpcPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 rpc_port = 6;</code>
       */
      public Builder clearRpcPort() {
        bitField0_ = (bitField0_ & ~0x00000020);
        rpcPort_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto clientToAmToken_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> clientToAmTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public boolean hasClientToAmToken() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getClientToAmToken() {
        if (clientToAmTokenBuilder_ == null) {
          return clientToAmToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : clientToAmToken_;
        } else {
          return clientToAmTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder setClientToAmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (clientToAmTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          clientToAmToken_ = value;
          onChanged();
        } else {
          clientToAmTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder setClientToAmToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = builderForValue.build();
          onChanged();
        } else {
          clientToAmTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder mergeClientToAmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (clientToAmTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              clientToAmToken_ != null &&
              clientToAmToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            clientToAmToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(clientToAmToken_).mergeFrom(value).buildPartial();
          } else {
            clientToAmToken_ = value;
          }
          onChanged();
        } else {
          clientToAmTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public Builder clearClientToAmToken() {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmToken_ = null;
          onChanged();
        } else {
          clientToAmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getClientToAmTokenBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getClientToAmTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getClientToAmTokenOrBuilder() {
        if (clientToAmTokenBuilder_ != null) {
          return clientToAmTokenBuilder_.getMessageOrBuilder();
        } else {
          return clientToAmToken_ == null ?
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : clientToAmToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto client_to_am_token = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getClientToAmTokenFieldBuilder() {
        if (clientToAmTokenBuilder_ == null) {
          clientToAmTokenBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  getClientToAmToken(),
                  getParentForChildren(),
                  isClean());
          clientToAmToken_ = null;
        }
        return clientToAmTokenBuilder_;
      }

      private int yarnApplicationState_ = 1;
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public boolean hasYarnApplicationState() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto getYarnApplicationState() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.valueOf(yarnApplicationState_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto.NEW : result;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public Builder setYarnApplicationState(org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000080;
        yarnApplicationState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationStateProto yarn_application_state = 8;</code>
       */
      public Builder clearYarnApplicationState() {
        bitField0_ = (bitField0_ & ~0x00000080);
        yarnApplicationState_ = 1;
        onChanged();
        return this;
      }

      private java.lang.Object trackingUrl_ = "";
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public java.lang.String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            trackingUrl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public com.google.protobuf.ByteString
          getTrackingUrlBytes() {
        java.lang.Object ref = trackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder setTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000100);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string trackingUrl = 9;</code>
       */
      public Builder setTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        trackingUrl_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            diagnostics_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000200);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 10 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      private long startTime_ ;
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public boolean hasStartTime() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public long getStartTime() {
        return startTime_;
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public Builder setStartTime(long value) {
        bitField0_ |= 0x00000400;
        startTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 startTime = 11;</code>
       */
      public Builder clearStartTime() {
        bitField0_ = (bitField0_ & ~0x00000400);
        startTime_ = 0L;
        onChanged();
        return this;
      }

      private long finishTime_ ;
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public boolean hasFinishTime() {
        return ((bitField0_ & 0x00000800) == 0x00000800);
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public long getFinishTime() {
        return finishTime_;
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public Builder setFinishTime(long value) {
        bitField0_ |= 0x00000800;
        finishTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 finishTime = 12;</code>
       */
      public Builder clearFinishTime() {
        bitField0_ = (bitField0_ & ~0x00000800);
        finishTime_ = 0L;
        onChanged();
        return this;
      }

      private int finalApplicationStatus_ = 0;
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public boolean hasFinalApplicationStatus() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto getFinalApplicationStatus() {
        org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto result = org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.valueOf(finalApplicationStatus_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto.APP_UNDEFINED : result;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public Builder setFinalApplicationStatus(org.apache.hadoop.yarn.proto.YarnProtos.FinalApplicationStatusProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00001000;
        finalApplicationStatus_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.FinalApplicationStatusProto final_application_status = 13;</code>
       */
      public Builder clearFinalApplicationStatus() {
        bitField0_ = (bitField0_ & ~0x00001000);
        finalApplicationStatus_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto appResourceUsage_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder> appResourceUsageBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public boolean hasAppResourceUsage() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto getAppResourceUsage() {
        if (appResourceUsageBuilder_ == null) {
          return appResourceUsage_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance() : appResourceUsage_;
        } else {
          return appResourceUsageBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder setAppResourceUsage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto value) {
        if (appResourceUsageBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          appResourceUsage_ = value;
          onChanged();
        } else {
          appResourceUsageBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder setAppResourceUsage(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder builderForValue) {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = builderForValue.build();
          onChanged();
        } else {
          appResourceUsageBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder mergeAppResourceUsage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto value) {
        if (appResourceUsageBuilder_ == null) {
          if (((bitField0_ & 0x00002000) == 0x00002000) &&
              appResourceUsage_ != null &&
              appResourceUsage_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance()) {
            appResourceUsage_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.newBuilder(appResourceUsage_).mergeFrom(value).buildPartial();
          } else {
            appResourceUsage_ = value;
          }
          onChanged();
        } else {
          appResourceUsageBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public Builder clearAppResourceUsage() {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsage_ = null;
          onChanged();
        } else {
          appResourceUsageBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder getAppResourceUsageBuilder() {
        bitField0_ |= 0x00002000;
        onChanged();
        return getAppResourceUsageFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder getAppResourceUsageOrBuilder() {
        if (appResourceUsageBuilder_ != null) {
          return appResourceUsageBuilder_.getMessageOrBuilder();
        } else {
          return appResourceUsage_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.getDefaultInstance() : appResourceUsage_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationResourceUsageReportProto app_resource_Usage = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder> 
          getAppResourceUsageFieldBuilder() {
        if (appResourceUsageBuilder_ == null) {
          appResourceUsageBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationResourceUsageReportProtoOrBuilder>(
                  getAppResourceUsage(),
                  getParentForChildren(),
                  isClean());
          appResourceUsage_ = null;
        }
        return appResourceUsageBuilder_;
      }

      private java.lang.Object originalTrackingUrl_ = "";
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public boolean hasOriginalTrackingUrl() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public java.lang.String getOriginalTrackingUrl() {
        java.lang.Object ref = originalTrackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            originalTrackingUrl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public com.google.protobuf.ByteString
          getOriginalTrackingUrlBytes() {
        java.lang.Object ref = originalTrackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          originalTrackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder setOriginalTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00004000;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder clearOriginalTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00004000);
        originalTrackingUrl_ = getDefaultInstance().getOriginalTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string originalTrackingUrl = 15;</code>
       */
      public Builder setOriginalTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00004000;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto currentApplicationAttemptId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> currentApplicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public boolean hasCurrentApplicationAttemptId() {
        return ((bitField0_ & 0x00008000) == 0x00008000);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getCurrentApplicationAttemptId() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          return currentApplicationAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : currentApplicationAttemptId_;
        } else {
          return currentApplicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder setCurrentApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          currentApplicationAttemptId_ = value;
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder setCurrentApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder mergeCurrentApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (currentApplicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00008000) == 0x00008000) &&
              currentApplicationAttemptId_ != null &&
              currentApplicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            currentApplicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(currentApplicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            currentApplicationAttemptId_ = value;
          }
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00008000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public Builder clearCurrentApplicationAttemptId() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptId_ = null;
          onChanged();
        } else {
          currentApplicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00008000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getCurrentApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00008000;
        onChanged();
        return getCurrentApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getCurrentApplicationAttemptIdOrBuilder() {
        if (currentApplicationAttemptIdBuilder_ != null) {
          return currentApplicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return currentApplicationAttemptId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : currentApplicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto currentApplicationAttemptId = 16;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getCurrentApplicationAttemptIdFieldBuilder() {
        if (currentApplicationAttemptIdBuilder_ == null) {
          currentApplicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  getCurrentApplicationAttemptId(),
                  getParentForChildren(),
                  isClean());
          currentApplicationAttemptId_ = null;
        }
        return currentApplicationAttemptIdBuilder_;
      }

      private float progress_ ;
      /**
       * <code>optional float progress = 17;</code>
       */
      public boolean hasProgress() {
        return ((bitField0_ & 0x00010000) == 0x00010000);
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public float getProgress() {
        return progress_;
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public Builder setProgress(float value) {
        bitField0_ |= 0x00010000;
        progress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float progress = 17;</code>
       */
      public Builder clearProgress() {
        bitField0_ = (bitField0_ & ~0x00010000);
        progress_ = 0F;
        onChanged();
        return this;
      }

      private java.lang.Object applicationType_ = "";
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public boolean hasApplicationType() {
        return ((bitField0_ & 0x00020000) == 0x00020000);
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public java.lang.String getApplicationType() {
        java.lang.Object ref = applicationType_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            applicationType_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTypeBytes() {
        java.lang.Object ref = applicationType_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationType_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder setApplicationType(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00020000;
        applicationType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder clearApplicationType() {
        bitField0_ = (bitField0_ & ~0x00020000);
        applicationType_ = getDefaultInstance().getApplicationType();
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 18;</code>
       */
      public Builder setApplicationTypeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00020000;
        applicationType_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto amRmToken_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> amRmTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public boolean hasAmRmToken() {
        return ((bitField0_ & 0x00040000) == 0x00040000);
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          return amRmToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
        } else {
          return amRmTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder setAmRmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amRmToken_ = value;
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder setAmRmToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = builderForValue.build();
          onChanged();
        } else {
          amRmTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder mergeAmRmToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (amRmTokenBuilder_ == null) {
          if (((bitField0_ & 0x00040000) == 0x00040000) &&
              amRmToken_ != null &&
              amRmToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            amRmToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(amRmToken_).mergeFrom(value).buildPartial();
          } else {
            amRmToken_ = value;
          }
          onChanged();
        } else {
          amRmTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00040000;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public Builder clearAmRmToken() {
        if (amRmTokenBuilder_ == null) {
          amRmToken_ = null;
          onChanged();
        } else {
          amRmTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00040000);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getAmRmTokenBuilder() {
        bitField0_ |= 0x00040000;
        onChanged();
        return getAmRmTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getAmRmTokenOrBuilder() {
        if (amRmTokenBuilder_ != null) {
          return amRmTokenBuilder_.getMessageOrBuilder();
        } else {
          return amRmToken_ == null ?
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : amRmToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto am_rm_token = 19;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getAmRmTokenFieldBuilder() {
        if (amRmTokenBuilder_ == null) {
          amRmTokenBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  getAmRmToken(),
                  getParentForChildren(),
                  isClean());
          amRmToken_ = null;
        }
        return amRmTokenBuilder_;
      }

      private com.google.protobuf.LazyStringList applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureApplicationTagsIsMutable() {
        if (!((bitField0_ & 0x00080000) == 0x00080000)) {
          applicationTags_ = new com.google.protobuf.LazyStringArrayList(applicationTags_);
          bitField0_ |= 0x00080000;
         }
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getApplicationTagsList() {
        return applicationTags_.getUnmodifiableView();
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public int getApplicationTagsCount() {
        return applicationTags_.size();
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public java.lang.String getApplicationTags(int index) {
        return applicationTags_.get(index);
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTagsBytes(int index) {
        return applicationTags_.getByteString(index);
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder setApplicationTags(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder addApplicationTags(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder addAllApplicationTags(
          java.lang.Iterable<java.lang.String> values) {
        ensureApplicationTagsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, applicationTags_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder clearApplicationTags() {
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00080000);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 20;</code>
       */
      public Builder addApplicationTagsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationReportProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationReportProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApplicationReportProto>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationReportProto>() {
      public ApplicationReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ApplicationReportProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationReportProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationReportProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationAttemptReportProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ApplicationAttemptReportProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    boolean hasApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId();
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder();

    /**
     * <code>optional string host = 2;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 2;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 2;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    boolean hasRpcPort();
    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    int getRpcPort();

    /**
     * <code>optional string tracking_url = 4;</code>
     */
    boolean hasTrackingUrl();
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    java.lang.String getTrackingUrl();
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    com.google.protobuf.ByteString
        getTrackingUrlBytes();

    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    boolean hasYarnApplicationAttemptState();
    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto getYarnApplicationAttemptState();

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    boolean hasAmContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getAmContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getAmContainerIdOrBuilder();

    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    boolean hasOriginalTrackingUrl();
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    java.lang.String getOriginalTrackingUrl();
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationAttemptReportProto}
   */
  public  static final class ApplicationAttemptReportProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ApplicationAttemptReportProto)
      ApplicationAttemptReportProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationAttemptReportProto.newBuilder() to construct.
    private ApplicationAttemptReportProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationAttemptReportProto() {
      host_ = "";
      rpcPort_ = 0;
      trackingUrl_ = "";
      diagnostics_ = "N/A";
      yarnApplicationAttemptState_ = 1;
      originalTrackingUrl_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationAttemptReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationAttemptId_.toBuilder();
              }
              applicationAttemptId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationAttemptId_);
                applicationAttemptId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              host_ = bs;
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              rpcPort_ = input.readInt32();
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000008;
              trackingUrl_ = bs;
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000010;
              diagnostics_ = bs;
              break;
            }
            case 48: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(6, rawValue);
              } else {
                bitField0_ |= 0x00000020;
                yarnApplicationAttemptState_ = rawValue;
              }
              break;
            }
            case 58: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000040) == 0x00000040)) {
                subBuilder = amContainerId_.toBuilder();
              }
              amContainerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amContainerId_);
                amContainerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000040;
              break;
            }
            case 66: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000080;
              originalTrackingUrl_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ATTEMPT_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public boolean hasApplicationAttemptId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
      return applicationAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
      return applicationAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
    }

    public static final int HOST_FIELD_NUMBER = 2;
    private volatile java.lang.Object host_;
    /**
     * <code>optional string host = 2;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RPC_PORT_FIELD_NUMBER = 3;
    private int rpcPort_;
    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    public boolean hasRpcPort() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 rpc_port = 3;</code>
     */
    public int getRpcPort() {
      return rpcPort_;
    }

    public static final int TRACKING_URL_FIELD_NUMBER = 4;
    private volatile java.lang.Object trackingUrl_;
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    public boolean hasTrackingUrl() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    public java.lang.String getTrackingUrl() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          trackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string tracking_url = 4;</code>
     */
    public com.google.protobuf.ByteString
        getTrackingUrlBytes() {
      java.lang.Object ref = trackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        trackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int DIAGNOSTICS_FIELD_NUMBER = 5;
    private volatile java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 5 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int YARN_APPLICATION_ATTEMPT_STATE_FIELD_NUMBER = 6;
    private int yarnApplicationAttemptState_;
    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    public boolean hasYarnApplicationAttemptState() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto getYarnApplicationAttemptState() {
      org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.valueOf(yarnApplicationAttemptState_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.APP_ATTEMPT_NEW : result;
    }

    public static final int AM_CONTAINER_ID_FIELD_NUMBER = 7;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto amContainerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    public boolean hasAmContainerId() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getAmContainerId() {
      return amContainerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : amContainerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getAmContainerIdOrBuilder() {
      return amContainerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : amContainerId_;
    }

    public static final int ORIGINAL_TRACKING_URL_FIELD_NUMBER = 8;
    private volatile java.lang.Object originalTrackingUrl_;
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    public boolean hasOriginalTrackingUrl() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    public java.lang.String getOriginalTrackingUrl() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          originalTrackingUrl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string original_tracking_url = 8;</code>
     */
    public com.google.protobuf.ByteString
        getOriginalTrackingUrlBytes() {
      java.lang.Object ref = originalTrackingUrl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        originalTrackingUrl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationAttemptId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, host_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, rpcPort_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, trackingUrl_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, diagnostics_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeEnum(6, yarnApplicationAttemptState_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeMessage(7, getAmContainerId());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, originalTrackingUrl_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationAttemptId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, host_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, rpcPort_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, trackingUrl_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(5, diagnostics_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(6, yarnApplicationAttemptState_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, getAmContainerId());
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, originalTrackingUrl_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto) obj;

      boolean result = true;
      result = result && (hasApplicationAttemptId() == other.hasApplicationAttemptId());
      if (hasApplicationAttemptId()) {
        result = result && getApplicationAttemptId()
            .equals(other.getApplicationAttemptId());
      }
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasRpcPort() == other.hasRpcPort());
      if (hasRpcPort()) {
        result = result && (getRpcPort()
            == other.getRpcPort());
      }
      result = result && (hasTrackingUrl() == other.hasTrackingUrl());
      if (hasTrackingUrl()) {
        result = result && getTrackingUrl()
            .equals(other.getTrackingUrl());
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasYarnApplicationAttemptState() == other.hasYarnApplicationAttemptState());
      if (hasYarnApplicationAttemptState()) {
        result = result && yarnApplicationAttemptState_ == other.yarnApplicationAttemptState_;
      }
      result = result && (hasAmContainerId() == other.hasAmContainerId());
      if (hasAmContainerId()) {
        result = result && getAmContainerId()
            .equals(other.getAmContainerId());
      }
      result = result && (hasOriginalTrackingUrl() == other.hasOriginalTrackingUrl());
      if (hasOriginalTrackingUrl()) {
        result = result && getOriginalTrackingUrl()
            .equals(other.getOriginalTrackingUrl());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasApplicationAttemptId()) {
        hash = (37 * hash) + APPLICATION_ATTEMPT_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationAttemptId().hashCode();
      }
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasRpcPort()) {
        hash = (37 * hash) + RPC_PORT_FIELD_NUMBER;
        hash = (53 * hash) + getRpcPort();
      }
      if (hasTrackingUrl()) {
        hash = (37 * hash) + TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getTrackingUrl().hashCode();
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasYarnApplicationAttemptState()) {
        hash = (37 * hash) + YARN_APPLICATION_ATTEMPT_STATE_FIELD_NUMBER;
        hash = (53 * hash) + yarnApplicationAttemptState_;
      }
      if (hasAmContainerId()) {
        hash = (37 * hash) + AM_CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getAmContainerId().hashCode();
      }
      if (hasOriginalTrackingUrl()) {
        hash = (37 * hash) + ORIGINAL_TRACKING_URL_FIELD_NUMBER;
        hash = (53 * hash) + getOriginalTrackingUrl().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationAttemptReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ApplicationAttemptReportProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationAttemptIdFieldBuilder();
          getAmContainerIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        rpcPort_ = 0;
        bitField0_ = (bitField0_ & ~0x00000004);
        trackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000010);
        yarnApplicationAttemptState_ = 1;
        bitField0_ = (bitField0_ & ~0x00000020);
        if (amContainerIdBuilder_ == null) {
          amContainerId_ = null;
        } else {
          amContainerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        originalTrackingUrl_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationAttemptIdBuilder_ == null) {
          result.applicationAttemptId_ = applicationAttemptId_;
        } else {
          result.applicationAttemptId_ = applicationAttemptIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rpcPort_ = rpcPort_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.trackingUrl_ = trackingUrl_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.yarnApplicationAttemptState_ = yarnApplicationAttemptState_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        if (amContainerIdBuilder_ == null) {
          result.amContainerId_ = amContainerId_;
        } else {
          result.amContainerId_ = amContainerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.originalTrackingUrl_ = originalTrackingUrl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto.getDefaultInstance()) return this;
        if (other.hasApplicationAttemptId()) {
          mergeApplicationAttemptId(other.getApplicationAttemptId());
        }
        if (other.hasHost()) {
          bitField0_ |= 0x00000002;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasRpcPort()) {
          setRpcPort(other.getRpcPort());
        }
        if (other.hasTrackingUrl()) {
          bitField0_ |= 0x00000008;
          trackingUrl_ = other.trackingUrl_;
          onChanged();
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000010;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasYarnApplicationAttemptState()) {
          setYarnApplicationAttemptState(other.getYarnApplicationAttemptState());
        }
        if (other.hasAmContainerId()) {
          mergeAmContainerId(other.getAmContainerId());
        }
        if (other.hasOriginalTrackingUrl()) {
          bitField0_ |= 0x00000080;
          originalTrackingUrl_ = other.originalTrackingUrl_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto applicationAttemptId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> applicationAttemptIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public boolean hasApplicationAttemptId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto getApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          return applicationAttemptId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        } else {
          return applicationAttemptIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationAttemptId_ = value;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder setApplicationAttemptId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder builderForValue) {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = builderForValue.build();
          onChanged();
        } else {
          applicationAttemptIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder mergeApplicationAttemptId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto value) {
        if (applicationAttemptIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationAttemptId_ != null &&
              applicationAttemptId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance()) {
            applicationAttemptId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.newBuilder(applicationAttemptId_).mergeFrom(value).buildPartial();
          } else {
            applicationAttemptId_ = value;
          }
          onChanged();
        } else {
          applicationAttemptIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public Builder clearApplicationAttemptId() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptId_ = null;
          onChanged();
        } else {
          applicationAttemptIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder getApplicationAttemptIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationAttemptIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder getApplicationAttemptIdOrBuilder() {
        if (applicationAttemptIdBuilder_ != null) {
          return applicationAttemptIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationAttemptId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.getDefaultInstance() : applicationAttemptId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAttemptIdProto application_attempt_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder> 
          getApplicationAttemptIdFieldBuilder() {
        if (applicationAttemptIdBuilder_ == null) {
          applicationAttemptIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptIdProtoOrBuilder>(
                  getApplicationAttemptId(),
                  getParentForChildren(),
                  isClean());
          applicationAttemptId_ = null;
        }
        return applicationAttemptIdBuilder_;
      }

      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 2;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            host_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000002);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 2;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        host_ = value;
        onChanged();
        return this;
      }

      private int rpcPort_ ;
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public boolean hasRpcPort() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public int getRpcPort() {
        return rpcPort_;
      }
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public Builder setRpcPort(int value) {
        bitField0_ |= 0x00000004;
        rpcPort_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 rpc_port = 3;</code>
       */
      public Builder clearRpcPort() {
        bitField0_ = (bitField0_ & ~0x00000004);
        rpcPort_ = 0;
        onChanged();
        return this;
      }

      private java.lang.Object trackingUrl_ = "";
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public boolean hasTrackingUrl() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public java.lang.String getTrackingUrl() {
        java.lang.Object ref = trackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            trackingUrl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public com.google.protobuf.ByteString
          getTrackingUrlBytes() {
        java.lang.Object ref = trackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          trackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public Builder setTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        trackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public Builder clearTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000008);
        trackingUrl_ = getDefaultInstance().getTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string tracking_url = 4;</code>
       */
      public Builder setTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        trackingUrl_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            diagnostics_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000010);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 5 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000010;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      private int yarnApplicationAttemptState_ = 1;
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public boolean hasYarnApplicationAttemptState() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto getYarnApplicationAttemptState() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.valueOf(yarnApplicationAttemptState_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto.APP_ATTEMPT_NEW : result;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public Builder setYarnApplicationAttemptState(org.apache.hadoop.yarn.proto.YarnProtos.YarnApplicationAttemptStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000020;
        yarnApplicationAttemptState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.YarnApplicationAttemptStateProto yarn_application_attempt_state = 6;</code>
       */
      public Builder clearYarnApplicationAttemptState() {
        bitField0_ = (bitField0_ & ~0x00000020);
        yarnApplicationAttemptState_ = 1;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto amContainerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> amContainerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public boolean hasAmContainerId() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getAmContainerId() {
        if (amContainerIdBuilder_ == null) {
          return amContainerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : amContainerId_;
        } else {
          return amContainerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder setAmContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (amContainerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amContainerId_ = value;
          onChanged();
        } else {
          amContainerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder setAmContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (amContainerIdBuilder_ == null) {
          amContainerId_ = builderForValue.build();
          onChanged();
        } else {
          amContainerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder mergeAmContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (amContainerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040) &&
              amContainerId_ != null &&
              amContainerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            amContainerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(amContainerId_).mergeFrom(value).buildPartial();
          } else {
            amContainerId_ = value;
          }
          onChanged();
        } else {
          amContainerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000040;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public Builder clearAmContainerId() {
        if (amContainerIdBuilder_ == null) {
          amContainerId_ = null;
          onChanged();
        } else {
          amContainerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000040);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getAmContainerIdBuilder() {
        bitField0_ |= 0x00000040;
        onChanged();
        return getAmContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getAmContainerIdOrBuilder() {
        if (amContainerIdBuilder_ != null) {
          return amContainerIdBuilder_.getMessageOrBuilder();
        } else {
          return amContainerId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : amContainerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto am_container_id = 7;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getAmContainerIdFieldBuilder() {
        if (amContainerIdBuilder_ == null) {
          amContainerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getAmContainerId(),
                  getParentForChildren(),
                  isClean());
          amContainerId_ = null;
        }
        return amContainerIdBuilder_;
      }

      private java.lang.Object originalTrackingUrl_ = "";
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public boolean hasOriginalTrackingUrl() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public java.lang.String getOriginalTrackingUrl() {
        java.lang.Object ref = originalTrackingUrl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            originalTrackingUrl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public com.google.protobuf.ByteString
          getOriginalTrackingUrlBytes() {
        java.lang.Object ref = originalTrackingUrl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          originalTrackingUrl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public Builder setOriginalTrackingUrl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public Builder clearOriginalTrackingUrl() {
        bitField0_ = (bitField0_ & ~0x00000080);
        originalTrackingUrl_ = getDefaultInstance().getOriginalTrackingUrl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string original_tracking_url = 8;</code>
       */
      public Builder setOriginalTrackingUrlBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        originalTrackingUrl_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationAttemptReportProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationAttemptReportProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApplicationAttemptReportProto>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationAttemptReportProto>() {
      public ApplicationAttemptReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ApplicationAttemptReportProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationAttemptReportProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationAttemptReportProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAttemptReportProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface NodeIdProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.NodeIdProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string host = 1;</code>
     */
    boolean hasHost();
    /**
     * <code>optional string host = 1;</code>
     */
    java.lang.String getHost();
    /**
     * <code>optional string host = 1;</code>
     */
    com.google.protobuf.ByteString
        getHostBytes();

    /**
     * <code>optional int32 port = 2;</code>
     */
    boolean hasPort();
    /**
     * <code>optional int32 port = 2;</code>
     */
    int getPort();
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeIdProto}
   */
  public  static final class NodeIdProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.NodeIdProto)
      NodeIdProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use NodeIdProto.newBuilder() to construct.
    private NodeIdProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private NodeIdProto() {
      host_ = "";
      port_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private NodeIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              host_ = bs;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              port_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder.class);
    }

    private int bitField0_;
    public static final int HOST_FIELD_NUMBER = 1;
    private volatile java.lang.Object host_;
    /**
     * <code>optional string host = 1;</code>
     */
    public boolean hasHost() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public java.lang.String getHost() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          host_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string host = 1;</code>
     */
    public com.google.protobuf.ByteString
        getHostBytes() {
      java.lang.Object ref = host_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        host_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PORT_FIELD_NUMBER = 2;
    private int port_;
    /**
     * <code>optional int32 port = 2;</code>
     */
    public boolean hasPort() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 port = 2;</code>
     */
    public int getPort() {
      return port_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, host_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, port_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, host_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, port_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) obj;

      boolean result = true;
      result = result && (hasHost() == other.hasHost());
      if (hasHost()) {
        result = result && getHost()
            .equals(other.getHost());
      }
      result = result && (hasPort() == other.hasPort());
      if (hasPort()) {
        result = result && (getPort()
            == other.getPort());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasHost()) {
        hash = (37 * hash) + HOST_FIELD_NUMBER;
        hash = (53 * hash) + getHost().hashCode();
      }
      if (hasPort()) {
        hash = (37 * hash) + PORT_FIELD_NUMBER;
        hash = (53 * hash) + getPort();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.NodeIdProto)
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        host_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        port_ = 0;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.host_ = host_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.port_ = port_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) return this;
        if (other.hasHost()) {
          bitField0_ |= 0x00000001;
          host_ = other.host_;
          onChanged();
        }
        if (other.hasPort()) {
          setPort(other.getPort());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object host_ = "";
      /**
       * <code>optional string host = 1;</code>
       */
      public boolean hasHost() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public java.lang.String getHost() {
        java.lang.Object ref = host_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            host_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public com.google.protobuf.ByteString
          getHostBytes() {
        java.lang.Object ref = host_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          host_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHost(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder clearHost() {
        bitField0_ = (bitField0_ & ~0x00000001);
        host_ = getDefaultInstance().getHost();
        onChanged();
        return this;
      }
      /**
       * <code>optional string host = 1;</code>
       */
      public Builder setHostBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        host_ = value;
        onChanged();
        return this;
      }

      private int port_ ;
      /**
       * <code>optional int32 port = 2;</code>
       */
      public boolean hasPort() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public int getPort() {
        return port_;
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public Builder setPort(int value) {
        bitField0_ |= 0x00000002;
        port_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 port = 2;</code>
       */
      public Builder clearPort() {
        bitField0_ = (bitField0_ & ~0x00000002);
        port_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeIdProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeIdProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<NodeIdProto>
        PARSER = new com.google.protobuf.AbstractParser<NodeIdProto>() {
      public NodeIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new NodeIdProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<NodeIdProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<NodeIdProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface NodeReportProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.NodeReportProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    /**
     * <code>optional string httpAddress = 2;</code>
     */
    boolean hasHttpAddress();
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    java.lang.String getHttpAddress();
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    com.google.protobuf.ByteString
        getHttpAddressBytes();

    /**
     * <code>optional string rackName = 3;</code>
     */
    boolean hasRackName();
    /**
     * <code>optional string rackName = 3;</code>
     */
    java.lang.String getRackName();
    /**
     * <code>optional string rackName = 3;</code>
     */
    com.google.protobuf.ByteString
        getRackNameBytes();

    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    boolean hasUsed();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed();
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    int getNumContainers();

    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    boolean hasNodeState();
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState();

    /**
     * <code>optional string health_report = 8;</code>
     */
    boolean hasHealthReport();
    /**
     * <code>optional string health_report = 8;</code>
     */
    java.lang.String getHealthReport();
    /**
     * <code>optional string health_report = 8;</code>
     */
    com.google.protobuf.ByteString
        getHealthReportBytes();

    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    boolean hasLastHealthReportTime();
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    long getLastHealthReportTime();

    /**
     * <code>repeated string node_labels = 10;</code>
     */
    java.util.List<java.lang.String>
        getNodeLabelsList();
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    int getNodeLabelsCount();
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    java.lang.String getNodeLabels(int index);
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeReportProto}
   */
  public  static final class NodeReportProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.NodeReportProto)
      NodeReportProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use NodeReportProto.newBuilder() to construct.
    private NodeReportProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private NodeReportProto() {
      httpAddress_ = "";
      rackName_ = "";
      numContainers_ = 0;
      nodeState_ = 1;
      healthReport_ = "";
      lastHealthReportTime_ = 0L;
      nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private NodeReportProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              httpAddress_ = bs;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              rackName_ = bs;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = used_.toBuilder();
              }
              used_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(used_);
                used_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              numContainers_ = input.readInt32();
              break;
            }
            case 56: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(7, rawValue);
              } else {
                bitField0_ |= 0x00000040;
                nodeState_ = rawValue;
              }
              break;
            }
            case 66: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000080;
              healthReport_ = bs;
              break;
            }
            case 72: {
              bitField0_ |= 0x00000100;
              lastHealthReportTime_ = input.readInt64();
              break;
            }
            case 82: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
                nodeLabels_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000200;
              }
              nodeLabels_.add(bs);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000200) == 0x00000200)) {
          nodeLabels_ = nodeLabels_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder.class);
    }

    private int bitField0_;
    public static final int NODEID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }

    public static final int HTTPADDRESS_FIELD_NUMBER = 2;
    private volatile java.lang.Object httpAddress_;
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public boolean hasHttpAddress() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public java.lang.String getHttpAddress() {
      java.lang.Object ref = httpAddress_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          httpAddress_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string httpAddress = 2;</code>
     */
    public com.google.protobuf.ByteString
        getHttpAddressBytes() {
      java.lang.Object ref = httpAddress_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        httpAddress_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int RACKNAME_FIELD_NUMBER = 3;
    private volatile java.lang.Object rackName_;
    /**
     * <code>optional string rackName = 3;</code>
     */
    public boolean hasRackName() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string rackName = 3;</code>
     */
    public java.lang.String getRackName() {
      java.lang.Object ref = rackName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          rackName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string rackName = 3;</code>
     */
    public com.google.protobuf.ByteString
        getRackNameBytes() {
      java.lang.Object ref = rackName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        rackName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int USED_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto used_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public boolean hasUsed() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed() {
      return used_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : used_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder() {
      return used_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : used_;
    }

    public static final int CAPABILITY_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }

    public static final int NUMCONTAINERS_FIELD_NUMBER = 6;
    private int numContainers_;
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional int32 numContainers = 6;</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    public static final int NODE_STATE_FIELD_NUMBER = 7;
    private int nodeState_;
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    public boolean hasNodeState() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState() {
      org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(nodeState_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW : result;
    }

    public static final int HEALTH_REPORT_FIELD_NUMBER = 8;
    private volatile java.lang.Object healthReport_;
    /**
     * <code>optional string health_report = 8;</code>
     */
    public boolean hasHealthReport() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional string health_report = 8;</code>
     */
    public java.lang.String getHealthReport() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          healthReport_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string health_report = 8;</code>
     */
    public com.google.protobuf.ByteString
        getHealthReportBytes() {
      java.lang.Object ref = healthReport_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        healthReport_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int LAST_HEALTH_REPORT_TIME_FIELD_NUMBER = 9;
    private long lastHealthReportTime_;
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    public boolean hasLastHealthReportTime() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional int64 last_health_report_time = 9;</code>
     */
    public long getLastHealthReportTime() {
      return lastHealthReportTime_;
    }

    public static final int NODE_LABELS_FIELD_NUMBER = 10;
    private com.google.protobuf.LazyStringList nodeLabels_;
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getNodeLabelsList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public int getNodeLabelsCount() {
      return nodeLabels_.size();
    }
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public java.lang.String getNodeLabels(int index) {
      return nodeLabels_.get(index);
    }
    /**
     * <code>repeated string node_labels = 10;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelsBytes(int index) {
      return nodeLabels_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getNodeId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, httpAddress_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, rackName_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getUsed());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, getCapability());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeInt32(6, numContainers_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeEnum(7, nodeState_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, healthReport_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeInt64(9, lastHealthReportTime_);
      }
      for (int i = 0; i < nodeLabels_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, nodeLabels_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNodeId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, httpAddress_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, rackName_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getUsed());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getCapability());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(6, numContainers_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(7, nodeState_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(8, healthReport_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(9, lastHealthReportTime_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < nodeLabels_.size(); i++) {
          dataSize += computeStringSizeNoTag(nodeLabels_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getNodeLabelsList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && (hasHttpAddress() == other.hasHttpAddress());
      if (hasHttpAddress()) {
        result = result && getHttpAddress()
            .equals(other.getHttpAddress());
      }
      result = result && (hasRackName() == other.hasRackName());
      if (hasRackName()) {
        result = result && getRackName()
            .equals(other.getRackName());
      }
      result = result && (hasUsed() == other.hasUsed());
      if (hasUsed()) {
        result = result && getUsed()
            .equals(other.getUsed());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasNodeState() == other.hasNodeState());
      if (hasNodeState()) {
        result = result && nodeState_ == other.nodeState_;
      }
      result = result && (hasHealthReport() == other.hasHealthReport());
      if (hasHealthReport()) {
        result = result && getHealthReport()
            .equals(other.getHealthReport());
      }
      result = result && (hasLastHealthReportTime() == other.hasLastHealthReportTime());
      if (hasLastHealthReportTime()) {
        result = result && (getLastHealthReportTime()
            == other.getLastHealthReportTime());
      }
      result = result && getNodeLabelsList()
          .equals(other.getNodeLabelsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (hasHttpAddress()) {
        hash = (37 * hash) + HTTPADDRESS_FIELD_NUMBER;
        hash = (53 * hash) + getHttpAddress().hashCode();
      }
      if (hasRackName()) {
        hash = (37 * hash) + RACKNAME_FIELD_NUMBER;
        hash = (53 * hash) + getRackName().hashCode();
      }
      if (hasUsed()) {
        hash = (37 * hash) + USED_FIELD_NUMBER;
        hash = (53 * hash) + getUsed().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUMCONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasNodeState()) {
        hash = (37 * hash) + NODE_STATE_FIELD_NUMBER;
        hash = (53 * hash) + nodeState_;
      }
      if (hasHealthReport()) {
        hash = (37 * hash) + HEALTH_REPORT_FIELD_NUMBER;
        hash = (53 * hash) + getHealthReport().hashCode();
      }
      if (hasLastHealthReportTime()) {
        hash = (37 * hash) + LAST_HEALTH_REPORT_TIME_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getLastHealthReportTime());
      }
      if (getNodeLabelsCount() > 0) {
        hash = (37 * hash) + NODE_LABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeReportProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.NodeReportProto)
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
          getUsedFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        httpAddress_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        rackName_ = "";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (usedBuilder_ == null) {
          used_ = null;
        } else {
          usedBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (capabilityBuilder_ == null) {
          capability_ = null;
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        numContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000020);
        nodeState_ = 1;
        bitField0_ = (bitField0_ & ~0x00000040);
        healthReport_ = "";
        bitField0_ = (bitField0_ & ~0x00000080);
        lastHealthReportTime_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000100);
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000200);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeReportProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.httpAddress_ = httpAddress_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.rackName_ = rackName_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (usedBuilder_ == null) {
          result.used_ = used_;
        } else {
          result.used_ = usedBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.nodeState_ = nodeState_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.healthReport_ = healthReport_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        result.lastHealthReportTime_ = lastHealthReportTime_;
        if (((bitField0_ & 0x00000200) == 0x00000200)) {
          nodeLabels_ = nodeLabels_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000200);
        }
        result.nodeLabels_ = nodeLabels_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (other.hasHttpAddress()) {
          bitField0_ |= 0x00000002;
          httpAddress_ = other.httpAddress_;
          onChanged();
        }
        if (other.hasRackName()) {
          bitField0_ |= 0x00000004;
          rackName_ = other.rackName_;
          onChanged();
        }
        if (other.hasUsed()) {
          mergeUsed(other.getUsed());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasNodeState()) {
          setNodeState(other.getNodeState());
        }
        if (other.hasHealthReport()) {
          bitField0_ |= 0x00000080;
          healthReport_ = other.healthReport_;
          onChanged();
        }
        if (other.hasLastHealthReportTime()) {
          setLastHealthReportTime(other.getLastHealthReportTime());
        }
        if (!other.nodeLabels_.isEmpty()) {
          if (nodeLabels_.isEmpty()) {
            nodeLabels_ = other.nodeLabels_;
            bitField0_ = (bitField0_ & ~0x00000200);
          } else {
            ensureNodeLabelsIsMutable();
            nodeLabels_.addAll(other.nodeLabels_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != null &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  getNodeId(),
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      private java.lang.Object httpAddress_ = "";
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public boolean hasHttpAddress() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public java.lang.String getHttpAddress() {
        java.lang.Object ref = httpAddress_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            httpAddress_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public com.google.protobuf.ByteString
          getHttpAddressBytes() {
        java.lang.Object ref = httpAddress_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          httpAddress_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder setHttpAddress(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        httpAddress_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder clearHttpAddress() {
        bitField0_ = (bitField0_ & ~0x00000002);
        httpAddress_ = getDefaultInstance().getHttpAddress();
        onChanged();
        return this;
      }
      /**
       * <code>optional string httpAddress = 2;</code>
       */
      public Builder setHttpAddressBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        httpAddress_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object rackName_ = "";
      /**
       * <code>optional string rackName = 3;</code>
       */
      public boolean hasRackName() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public java.lang.String getRackName() {
        java.lang.Object ref = rackName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            rackName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public com.google.protobuf.ByteString
          getRackNameBytes() {
        java.lang.Object ref = rackName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          rackName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder setRackName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rackName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder clearRackName() {
        bitField0_ = (bitField0_ & ~0x00000004);
        rackName_ = getDefaultInstance().getRackName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string rackName = 3;</code>
       */
      public Builder setRackNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        rackName_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto used_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> usedBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public boolean hasUsed() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getUsed() {
        if (usedBuilder_ == null) {
          return used_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : used_;
        } else {
          return usedBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder setUsed(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          used_ = value;
          onChanged();
        } else {
          usedBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder setUsed(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (usedBuilder_ == null) {
          used_ = builderForValue.build();
          onChanged();
        } else {
          usedBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder mergeUsed(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (usedBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              used_ != null &&
              used_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            used_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(used_).mergeFrom(value).buildPartial();
          } else {
            used_ = value;
          }
          onChanged();
        } else {
          usedBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public Builder clearUsed() {
        if (usedBuilder_ == null) {
          used_ = null;
          onChanged();
        } else {
          usedBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getUsedBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getUsedFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getUsedOrBuilder() {
        if (usedBuilder_ != null) {
          return usedBuilder_.getMessageOrBuilder();
        } else {
          return used_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : used_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto used = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getUsedFieldBuilder() {
        if (usedBuilder_ == null) {
          usedBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getUsed(),
                  getParentForChildren(),
                  isClean());
          used_ = null;
        }
        return usedBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              capability_ != null &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = null;
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getCapability(),
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      private int numContainers_ ;
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000020;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 numContainers = 6;</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000020);
        numContainers_ = 0;
        onChanged();
        return this;
      }

      private int nodeState_ = 1;
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public boolean hasNodeState() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto getNodeState() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.valueOf(nodeState_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto.NS_NEW : result;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public Builder setNodeState(org.apache.hadoop.yarn.proto.YarnProtos.NodeStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000040;
        nodeState_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeStateProto node_state = 7;</code>
       */
      public Builder clearNodeState() {
        bitField0_ = (bitField0_ & ~0x00000040);
        nodeState_ = 1;
        onChanged();
        return this;
      }

      private java.lang.Object healthReport_ = "";
      /**
       * <code>optional string health_report = 8;</code>
       */
      public boolean hasHealthReport() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public java.lang.String getHealthReport() {
        java.lang.Object ref = healthReport_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            healthReport_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public com.google.protobuf.ByteString
          getHealthReportBytes() {
        java.lang.Object ref = healthReport_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          healthReport_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder setHealthReport(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        healthReport_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder clearHealthReport() {
        bitField0_ = (bitField0_ & ~0x00000080);
        healthReport_ = getDefaultInstance().getHealthReport();
        onChanged();
        return this;
      }
      /**
       * <code>optional string health_report = 8;</code>
       */
      public Builder setHealthReportBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000080;
        healthReport_ = value;
        onChanged();
        return this;
      }

      private long lastHealthReportTime_ ;
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public boolean hasLastHealthReportTime() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public long getLastHealthReportTime() {
        return lastHealthReportTime_;
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public Builder setLastHealthReportTime(long value) {
        bitField0_ |= 0x00000100;
        lastHealthReportTime_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 last_health_report_time = 9;</code>
       */
      public Builder clearLastHealthReportTime() {
        bitField0_ = (bitField0_ & ~0x00000100);
        lastHealthReportTime_ = 0L;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000200) == 0x00000200)) {
          nodeLabels_ = new com.google.protobuf.LazyStringArrayList(nodeLabels_);
          bitField0_ |= 0x00000200;
         }
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getNodeLabelsList() {
        return nodeLabels_.getUnmodifiableView();
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public int getNodeLabelsCount() {
        return nodeLabels_.size();
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public java.lang.String getNodeLabels(int index) {
        return nodeLabels_.get(index);
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelsBytes(int index) {
        return nodeLabels_.getByteString(index);
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder setNodeLabels(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder addNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder addAllNodeLabels(
          java.lang.Iterable<java.lang.String> values) {
        ensureNodeLabelsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, nodeLabels_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder clearNodeLabels() {
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000200);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string node_labels = 10;</code>
       */
      public Builder addNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeReportProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeReportProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<NodeReportProto>
        PARSER = new com.google.protobuf.AbstractParser<NodeReportProto>() {
      public NodeReportProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new NodeReportProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<NodeReportProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<NodeReportProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.NodeReportProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface NodeIdToLabelsProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.NodeIdToLabelsProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    boolean hasNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId();
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder();

    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    java.util.List<java.lang.String>
        getNodeLabelsList();
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    int getNodeLabelsCount();
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    java.lang.String getNodeLabels(int index);
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.NodeIdToLabelsProto}
   */
  public  static final class NodeIdToLabelsProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.NodeIdToLabelsProto)
      NodeIdToLabelsProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use NodeIdToLabelsProto.newBuilder() to construct.
    private NodeIdToLabelsProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private NodeIdToLabelsProto() {
      nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private NodeIdToLabelsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = nodeId_.toBuilder();
              }
              nodeId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(nodeId_);
                nodeId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                nodeLabels_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              nodeLabels_.add(bs);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          nodeLabels_ = nodeLabels_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.Builder.class);
    }

    private int bitField0_;
    public static final int NODEID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_;
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public boolean hasNodeId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }
    /**
     * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
      return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
    }

    public static final int NODELABELS_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList nodeLabels_;
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getNodeLabelsList() {
      return nodeLabels_;
    }
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public int getNodeLabelsCount() {
      return nodeLabels_.size();
    }
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public java.lang.String getNodeLabels(int index) {
      return nodeLabels_.get(index);
    }
    /**
     * <code>repeated string nodeLabels = 2;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelsBytes(int index) {
      return nodeLabels_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getNodeId());
      }
      for (int i = 0; i < nodeLabels_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, nodeLabels_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getNodeId());
      }
      {
        int dataSize = 0;
        for (int i = 0; i < nodeLabels_.size(); i++) {
          dataSize += computeStringSizeNoTag(nodeLabels_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getNodeLabelsList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto) obj;

      boolean result = true;
      result = result && (hasNodeId() == other.hasNodeId());
      if (hasNodeId()) {
        result = result && getNodeId()
            .equals(other.getNodeId());
      }
      result = result && getNodeLabelsList()
          .equals(other.getNodeLabelsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNodeId()) {
        hash = (37 * hash) + NODEID_FIELD_NUMBER;
        hash = (53 * hash) + getNodeId().hashCode();
      }
      if (getNodeLabelsCount() > 0) {
        hash = (37 * hash) + NODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.NodeIdToLabelsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.NodeIdToLabelsProto)
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getNodeIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (nodeIdBuilder_ == null) {
          result.nodeId_ = nodeId_;
        } else {
          result.nodeId_ = nodeIdBuilder_.build();
        }
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          nodeLabels_ = nodeLabels_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.nodeLabels_ = nodeLabels_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto.getDefaultInstance()) return this;
        if (other.hasNodeId()) {
          mergeNodeId(other.getNodeId());
        }
        if (!other.nodeLabels_.isEmpty()) {
          if (nodeLabels_.isEmpty()) {
            nodeLabels_ = other.nodeLabels_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureNodeLabelsIsMutable();
            nodeLabels_.addAll(other.nodeLabels_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto nodeId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> nodeIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public boolean hasNodeId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto getNodeId() {
        if (nodeIdBuilder_ == null) {
          return nodeId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        } else {
          return nodeIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          nodeId_ = value;
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder setNodeId(
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder builderForValue) {
        if (nodeIdBuilder_ == null) {
          nodeId_ = builderForValue.build();
          onChanged();
        } else {
          nodeIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder mergeNodeId(org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto value) {
        if (nodeIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              nodeId_ != null &&
              nodeId_ != org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance()) {
            nodeId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.newBuilder(nodeId_).mergeFrom(value).buildPartial();
          } else {
            nodeId_ = value;
          }
          onChanged();
        } else {
          nodeIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public Builder clearNodeId() {
        if (nodeIdBuilder_ == null) {
          nodeId_ = null;
          onChanged();
        } else {
          nodeIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder getNodeIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getNodeIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder getNodeIdOrBuilder() {
        if (nodeIdBuilder_ != null) {
          return nodeIdBuilder_.getMessageOrBuilder();
        } else {
          return nodeId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.getDefaultInstance() : nodeId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.NodeIdProto nodeId = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder> 
          getNodeIdFieldBuilder() {
        if (nodeIdBuilder_ == null) {
          nodeIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.NodeIdProtoOrBuilder>(
                  getNodeId(),
                  getParentForChildren(),
                  isClean());
          nodeId_ = null;
        }
        return nodeIdBuilder_;
      }

      private com.google.protobuf.LazyStringList nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          nodeLabels_ = new com.google.protobuf.LazyStringArrayList(nodeLabels_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getNodeLabelsList() {
        return nodeLabels_.getUnmodifiableView();
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public int getNodeLabelsCount() {
        return nodeLabels_.size();
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public java.lang.String getNodeLabels(int index) {
        return nodeLabels_.get(index);
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelsBytes(int index) {
        return nodeLabels_.getByteString(index);
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder setNodeLabels(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder addNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder addAllNodeLabels(
          java.lang.Iterable<java.lang.String> values) {
        ensureNodeLabelsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, nodeLabels_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder clearNodeLabels() {
        nodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string nodeLabels = 2;</code>
       */
      public Builder addNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureNodeLabelsIsMutable();
        nodeLabels_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.NodeIdToLabelsProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.NodeIdToLabelsProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<NodeIdToLabelsProto>
        PARSER = new com.google.protobuf.AbstractParser<NodeIdToLabelsProto>() {
      public NodeIdToLabelsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new NodeIdToLabelsProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<NodeIdToLabelsProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<NodeIdToLabelsProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.NodeIdToLabelsProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourceRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ResourceRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    /**
     * <code>optional string resource_name = 2;</code>
     */
    boolean hasResourceName();
    /**
     * <code>optional string resource_name = 2;</code>
     */
    java.lang.String getResourceName();
    /**
     * <code>optional string resource_name = 2;</code>
     */
    com.google.protobuf.ByteString
        getResourceNameBytes();

    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    int getNumContainers();

    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    boolean hasRelaxLocality();
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    boolean getRelaxLocality();

    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    boolean hasNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    java.lang.String getNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelExpressionBytes();
  }
  /**
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From AM_RM_Protocol /////////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   *
   * Protobuf type {@code hadoop.yarn.ResourceRequestProto}
   */
  public  static final class ResourceRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ResourceRequestProto)
      ResourceRequestProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ResourceRequestProto.newBuilder() to construct.
    private ResourceRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ResourceRequestProto() {
      resourceName_ = "";
      numContainers_ = 0;
      relaxLocality_ = true;
      nodeLabelExpression_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              resourceName_ = bs;
              break;
            }
            case 26: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              numContainers_ = input.readInt32();
              break;
            }
            case 40: {
              bitField0_ |= 0x00000010;
              relaxLocality_ = input.readBool();
              break;
            }
            case 50: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000020;
              nodeLabelExpression_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int PRIORITY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }

    public static final int RESOURCE_NAME_FIELD_NUMBER = 2;
    private volatile java.lang.Object resourceName_;
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public boolean hasResourceName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public java.lang.String getResourceName() {
      java.lang.Object ref = resourceName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          resourceName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string resource_name = 2;</code>
     */
    public com.google.protobuf.ByteString
        getResourceNameBytes() {
      java.lang.Object ref = resourceName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        resourceName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CAPABILITY_FIELD_NUMBER = 3;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }

    public static final int NUM_CONTAINERS_FIELD_NUMBER = 4;
    private int numContainers_;
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 num_containers = 4;</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    public static final int RELAX_LOCALITY_FIELD_NUMBER = 5;
    private boolean relaxLocality_;
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    public boolean hasRelaxLocality() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional bool relax_locality = 5 [default = true];</code>
     */
    public boolean getRelaxLocality() {
      return relaxLocality_;
    }

    public static final int NODE_LABEL_EXPRESSION_FIELD_NUMBER = 6;
    private volatile java.lang.Object nodeLabelExpression_;
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    public boolean hasNodeLabelExpression() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    public java.lang.String getNodeLabelExpression() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_label_expression = 6;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelExpressionBytes() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getPriority());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, resourceName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getCapability());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, numContainers_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeBool(5, relaxLocality_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 6, nodeLabelExpression_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getPriority());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, resourceName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getCapability());
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, numContainers_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(5, relaxLocality_);
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(6, nodeLabelExpression_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasResourceName() == other.hasResourceName());
      if (hasResourceName()) {
        result = result && getResourceName()
            .equals(other.getResourceName());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasRelaxLocality() == other.hasRelaxLocality());
      if (hasRelaxLocality()) {
        result = result && (getRelaxLocality()
            == other.getRelaxLocality());
      }
      result = result && (hasNodeLabelExpression() == other.hasNodeLabelExpression());
      if (hasNodeLabelExpression()) {
        result = result && getNodeLabelExpression()
            .equals(other.getNodeLabelExpression());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasResourceName()) {
        hash = (37 * hash) + RESOURCE_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getResourceName().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUM_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasRelaxLocality()) {
        hash = (37 * hash) + RELAX_LOCALITY_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getRelaxLocality());
      }
      if (hasNodeLabelExpression()) {
        hash = (37 * hash) + NODE_LABEL_EXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelExpression().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From AM_RM_Protocol /////////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     *
     * Protobuf type {@code hadoop.yarn.ResourceRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ResourceRequestProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getPriorityFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (priorityBuilder_ == null) {
          priority_ = null;
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        resourceName_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        if (capabilityBuilder_ == null) {
          capability_ = null;
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        numContainers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000008);
        relaxLocality_ = true;
        bitField0_ = (bitField0_ & ~0x00000010);
        nodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00000020);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.resourceName_ = resourceName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.relaxLocality_ = relaxLocality_;
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.nodeLabelExpression_ = nodeLabelExpression_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasResourceName()) {
          bitField0_ |= 0x00000002;
          resourceName_ = other.resourceName_;
          onChanged();
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasRelaxLocality()) {
          setRelaxLocality(other.getRelaxLocality());
        }
        if (other.hasNodeLabelExpression()) {
          bitField0_ |= 0x00000020;
          nodeLabelExpression_ = other.nodeLabelExpression_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              priority_ != null &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = null;
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  getPriority(),
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      private java.lang.Object resourceName_ = "";
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public boolean hasResourceName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public java.lang.String getResourceName() {
        java.lang.Object ref = resourceName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            resourceName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public com.google.protobuf.ByteString
          getResourceNameBytes() {
        java.lang.Object ref = resourceName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          resourceName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder setResourceName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder clearResourceName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        resourceName_ = getDefaultInstance().getResourceName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string resource_name = 2;</code>
       */
      public Builder setResourceNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        resourceName_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              capability_ != null &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = null;
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getCapability(),
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      private int numContainers_ ;
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000008;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_containers = 4;</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000008);
        numContainers_ = 0;
        onChanged();
        return this;
      }

      private boolean relaxLocality_ = true;
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public boolean hasRelaxLocality() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public boolean getRelaxLocality() {
        return relaxLocality_;
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public Builder setRelaxLocality(boolean value) {
        bitField0_ |= 0x00000010;
        relaxLocality_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool relax_locality = 5 [default = true];</code>
       */
      public Builder clearRelaxLocality() {
        bitField0_ = (bitField0_ & ~0x00000010);
        relaxLocality_ = true;
        onChanged();
        return this;
      }

      private java.lang.Object nodeLabelExpression_ = "";
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public boolean hasNodeLabelExpression() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public java.lang.String getNodeLabelExpression() {
        java.lang.Object ref = nodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            nodeLabelExpression_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelExpressionBytes() {
        java.lang.Object ref = nodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public Builder setNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public Builder clearNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00000020);
        nodeLabelExpression_ = getDefaultInstance().getNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 6;</code>
       */
      public Builder setNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000020;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceRequestProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ResourceRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ResourceRequestProto>() {
      public ResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ResourceRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ResourceRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceRequestProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PreemptionMessageProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.PreemptionMessageProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    boolean hasStrictContract();
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract();
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder();

    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    boolean hasContract();
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract();
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionMessageProto}
   */
  public  static final class PreemptionMessageProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.PreemptionMessageProto)
      PreemptionMessageProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PreemptionMessageProto.newBuilder() to construct.
    private PreemptionMessageProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PreemptionMessageProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionMessageProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = strictContract_.toBuilder();
              }
              strictContract_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(strictContract_);
                strictContract_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = contract_.toBuilder();
              }
              contract_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(contract_);
                contract_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder.class);
    }

    private int bitField0_;
    public static final int STRICTCONTRACT_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto strictContract_;
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public boolean hasStrictContract() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract() {
      return strictContract_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance() : strictContract_;
    }
    /**
     * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder() {
      return strictContract_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance() : strictContract_;
    }

    public static final int CONTRACT_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto contract_;
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public boolean hasContract() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract() {
      return contract_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance() : contract_;
    }
    /**
     * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder() {
      return contract_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance() : contract_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getStrictContract());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getContract());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getStrictContract());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getContract());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) obj;

      boolean result = true;
      result = result && (hasStrictContract() == other.hasStrictContract());
      if (hasStrictContract()) {
        result = result && getStrictContract()
            .equals(other.getStrictContract());
      }
      result = result && (hasContract() == other.hasContract());
      if (hasContract()) {
        result = result && getContract()
            .equals(other.getContract());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasStrictContract()) {
        hash = (37 * hash) + STRICTCONTRACT_FIELD_NUMBER;
        hash = (53 * hash) + getStrictContract().hashCode();
      }
      if (hasContract()) {
        hash = (37 * hash) + CONTRACT_FIELD_NUMBER;
        hash = (53 * hash) + getContract().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionMessageProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.PreemptionMessageProto)
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getStrictContractFieldBuilder();
          getContractFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (strictContractBuilder_ == null) {
          strictContract_ = null;
        } else {
          strictContractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (contractBuilder_ == null) {
          contract_ = null;
        } else {
          contractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (strictContractBuilder_ == null) {
          result.strictContract_ = strictContract_;
        } else {
          result.strictContract_ = strictContractBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (contractBuilder_ == null) {
          result.contract_ = contract_;
        } else {
          result.contract_ = contractBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto.getDefaultInstance()) return this;
        if (other.hasStrictContract()) {
          mergeStrictContract(other.getStrictContract());
        }
        if (other.hasContract()) {
          mergeContract(other.getContract());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto strictContract_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder> strictContractBuilder_;
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public boolean hasStrictContract() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getStrictContract() {
        if (strictContractBuilder_ == null) {
          return strictContract_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance() : strictContract_;
        } else {
          return strictContractBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder setStrictContract(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto value) {
        if (strictContractBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          strictContract_ = value;
          onChanged();
        } else {
          strictContractBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder setStrictContract(
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder builderForValue) {
        if (strictContractBuilder_ == null) {
          strictContract_ = builderForValue.build();
          onChanged();
        } else {
          strictContractBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder mergeStrictContract(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto value) {
        if (strictContractBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              strictContract_ != null &&
              strictContract_ != org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance()) {
            strictContract_ =
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.newBuilder(strictContract_).mergeFrom(value).buildPartial();
          } else {
            strictContract_ = value;
          }
          onChanged();
        } else {
          strictContractBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public Builder clearStrictContract() {
        if (strictContractBuilder_ == null) {
          strictContract_ = null;
          onChanged();
        } else {
          strictContractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder getStrictContractBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getStrictContractFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder getStrictContractOrBuilder() {
        if (strictContractBuilder_ != null) {
          return strictContractBuilder_.getMessageOrBuilder();
        } else {
          return strictContract_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance() : strictContract_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.StrictPreemptionContractProto strictContract = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder> 
          getStrictContractFieldBuilder() {
        if (strictContractBuilder_ == null) {
          strictContractBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder>(
                  getStrictContract(),
                  getParentForChildren(),
                  isClean());
          strictContract_ = null;
        }
        return strictContractBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto contract_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder> contractBuilder_;
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public boolean hasContract() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getContract() {
        if (contractBuilder_ == null) {
          return contract_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance() : contract_;
        } else {
          return contractBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder setContract(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto value) {
        if (contractBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          contract_ = value;
          onChanged();
        } else {
          contractBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder setContract(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder builderForValue) {
        if (contractBuilder_ == null) {
          contract_ = builderForValue.build();
          onChanged();
        } else {
          contractBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder mergeContract(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto value) {
        if (contractBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              contract_ != null &&
              contract_ != org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance()) {
            contract_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.newBuilder(contract_).mergeFrom(value).buildPartial();
          } else {
            contract_ = value;
          }
          onChanged();
        } else {
          contractBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public Builder clearContract() {
        if (contractBuilder_ == null) {
          contract_ = null;
          onChanged();
        } else {
          contractBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder getContractBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getContractFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder getContractOrBuilder() {
        if (contractBuilder_ != null) {
          return contractBuilder_.getMessageOrBuilder();
        } else {
          return contract_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance() : contract_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PreemptionContractProto contract = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder> 
          getContractFieldBuilder() {
        if (contractBuilder_ == null) {
          contractBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder>(
                  getContract(),
                  getParentForChildren(),
                  isClean());
          contract_ = null;
        }
        return contractBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionMessageProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionMessageProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<PreemptionMessageProto>
        PARSER = new com.google.protobuf.AbstractParser<PreemptionMessageProto>() {
      public PreemptionMessageProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new PreemptionMessageProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PreemptionMessageProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionMessageProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionMessageProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StrictPreemptionContractProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StrictPreemptionContractProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> 
        getContainerList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    int getContainerCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.StrictPreemptionContractProto}
   */
  public  static final class StrictPreemptionContractProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StrictPreemptionContractProto)
      StrictPreemptionContractProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StrictPreemptionContractProto.newBuilder() to construct.
    private StrictPreemptionContractProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StrictPreemptionContractProto() {
      container_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StrictPreemptionContractProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              container_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          container_ = java.util.Collections.unmodifiableList(container_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder.class);
    }

    public static final int CONTAINER_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public int getContainerCount() {
      return container_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
      return container_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index) {
      return container_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < container_.size(); i++) {
        output.writeMessage(1, container_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < container_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, container_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) obj;

      boolean result = true;
      result = result && getContainerList()
          .equals(other.getContainerList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getContainerCount() > 0) {
        hash = (37 * hash) + CONTAINER_FIELD_NUMBER;
        hash = (53 * hash) + getContainerList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StrictPreemptionContractProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StrictPreemptionContractProto)
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          containerBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto(this);
        int from_bitField0_ = bitField0_;
        if (containerBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            container_ = java.util.Collections.unmodifiableList(container_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.container_ = container_;
        } else {
          result.container_ = containerBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto.getDefaultInstance()) return this;
        if (containerBuilder_ == null) {
          if (!other.container_.isEmpty()) {
            if (container_.isEmpty()) {
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureContainerIsMutable();
              container_.addAll(other.container_);
            }
            onChanged();
          }
        } else {
          if (!other.container_.isEmpty()) {
            if (containerBuilder_.isEmpty()) {
              containerBuilder_.dispose();
              containerBuilder_ = null;
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000001);
              containerBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getContainerFieldBuilder() : null;
            } else {
              containerBuilder_.addAllMessages(other.container_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_ =
        java.util.Collections.emptyList();
      private void ensureContainerIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>(container_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> containerBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
        if (containerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(container_);
        } else {
          return containerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public int getContainerCount() {
        if (containerBuilder_ == null) {
          return container_.size();
        } else {
          return containerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);
        } else {
          return containerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.set(index, value);
          onChanged();
        } else {
          containerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(value);
          onChanged();
        } else {
          containerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(index, value);
          onChanged();
        } else {
          containerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder addAllContainer(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> values) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, container_);
          onChanged();
        } else {
          containerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder clearContainer() {
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          containerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public Builder removeContainer(int index) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.remove(index);
          onChanged();
        } else {
          containerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder getContainerBuilder(
          int index) {
        return getContainerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
          int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);  } else {
          return containerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
           getContainerOrBuilderList() {
        if (containerBuilder_ != null) {
          return containerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(container_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder() {
        return getContainerFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder(
          int index) {
        return getContainerFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder> 
           getContainerBuilderList() {
        return getContainerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
          getContainerFieldBuilder() {
        if (containerBuilder_ == null) {
          containerBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder>(
                  container_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          container_ = null;
        }
        return containerBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StrictPreemptionContractProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StrictPreemptionContractProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StrictPreemptionContractProto>
        PARSER = new com.google.protobuf.AbstractParser<StrictPreemptionContractProto>() {
      public StrictPreemptionContractProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StrictPreemptionContractProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StrictPreemptionContractProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StrictPreemptionContractProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.StrictPreemptionContractProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PreemptionContractProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.PreemptionContractProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> 
        getResourceList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    int getResourceCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
        getResourceOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> 
        getContainerList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index);
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    int getContainerCount();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionContractProto}
   */
  public  static final class PreemptionContractProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.PreemptionContractProto)
      PreemptionContractProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PreemptionContractProto.newBuilder() to construct.
    private PreemptionContractProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PreemptionContractProto() {
      resource_ = java.util.Collections.emptyList();
      container_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionContractProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                resource_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              resource_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>();
                mutable_bitField0_ |= 0x00000002;
              }
              container_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          resource_ = java.util.Collections.unmodifiableList(resource_);
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          container_ = java.util.Collections.unmodifiableList(container_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder.class);
    }

    public static final int RESOURCE_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> resource_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> getResourceList() {
      return resource_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
        getResourceOrBuilderList() {
      return resource_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public int getResourceCount() {
      return resource_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index) {
      return resource_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
        int index) {
      return resource_.get(index);
    }

    public static final int CONTAINER_FIELD_NUMBER = 2;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_;
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
        getContainerOrBuilderList() {
      return container_;
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public int getContainerCount() {
      return container_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
      return container_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
        int index) {
      return container_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < resource_.size(); i++) {
        output.writeMessage(1, resource_.get(i));
      }
      for (int i = 0; i < container_.size(); i++) {
        output.writeMessage(2, container_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < resource_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, resource_.get(i));
      }
      for (int i = 0; i < container_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, container_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) obj;

      boolean result = true;
      result = result && getResourceList()
          .equals(other.getResourceList());
      result = result && getContainerList()
          .equals(other.getContainerList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getResourceCount() > 0) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResourceList().hashCode();
      }
      if (getContainerCount() > 0) {
        hash = (37 * hash) + CONTAINER_FIELD_NUMBER;
        hash = (53 * hash) + getContainerList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionContractProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.PreemptionContractProto)
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
          getContainerFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          resourceBuilder_.clear();
        }
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
        } else {
          containerBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto(this);
        int from_bitField0_ = bitField0_;
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            resource_ = java.util.Collections.unmodifiableList(resource_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (containerBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002)) {
            container_ = java.util.Collections.unmodifiableList(container_);
            bitField0_ = (bitField0_ & ~0x00000002);
          }
          result.container_ = container_;
        } else {
          result.container_ = containerBuilder_.build();
        }
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto.getDefaultInstance()) return this;
        if (resourceBuilder_ == null) {
          if (!other.resource_.isEmpty()) {
            if (resource_.isEmpty()) {
              resource_ = other.resource_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureResourceIsMutable();
              resource_.addAll(other.resource_);
            }
            onChanged();
          }
        } else {
          if (!other.resource_.isEmpty()) {
            if (resourceBuilder_.isEmpty()) {
              resourceBuilder_.dispose();
              resourceBuilder_ = null;
              resource_ = other.resource_;
              bitField0_ = (bitField0_ & ~0x00000001);
              resourceBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getResourceFieldBuilder() : null;
            } else {
              resourceBuilder_.addAllMessages(other.resource_);
            }
          }
        }
        if (containerBuilder_ == null) {
          if (!other.container_.isEmpty()) {
            if (container_.isEmpty()) {
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000002);
            } else {
              ensureContainerIsMutable();
              container_.addAll(other.container_);
            }
            onChanged();
          }
        } else {
          if (!other.container_.isEmpty()) {
            if (containerBuilder_.isEmpty()) {
              containerBuilder_.dispose();
              containerBuilder_ = null;
              container_ = other.container_;
              bitField0_ = (bitField0_ & ~0x00000002);
              containerBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getContainerFieldBuilder() : null;
            } else {
              containerBuilder_.addAllMessages(other.container_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> resource_ =
        java.util.Collections.emptyList();
      private void ensureResourceIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          resource_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto>(resource_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> resourceBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> getResourceList() {
        if (resourceBuilder_ == null) {
          return java.util.Collections.unmodifiableList(resource_);
        } else {
          return resourceBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public int getResourceCount() {
        if (resourceBuilder_ == null) {
          return resource_.size();
        } else {
          return resourceBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getResource(int index) {
        if (resourceBuilder_ == null) {
          return resource_.get(index);
        } else {
          return resourceBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.set(index, value);
          onChanged();
        } else {
          resourceBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.set(index, builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.add(value);
          onChanged();
        } else {
          resourceBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureResourceIsMutable();
          resource_.add(index, value);
          onChanged();
        } else {
          resourceBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.add(builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addResource(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.add(index, builderForValue.build());
          onChanged();
        } else {
          resourceBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder addAllResource(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto> values) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, resource_);
          onChanged();
        } else {
          resourceBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public Builder removeResource(int index) {
        if (resourceBuilder_ == null) {
          ensureResourceIsMutable();
          resource_.remove(index);
          onChanged();
        } else {
          resourceBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder getResourceBuilder(
          int index) {
        return getResourceFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder getResourceOrBuilder(
          int index) {
        if (resourceBuilder_ == null) {
          return resource_.get(index);  } else {
          return resourceBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
           getResourceOrBuilderList() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(resource_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder addResourceBuilder() {
        return getResourceFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder addResourceBuilder(
          int index) {
        return getResourceFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionResourceRequestProto resource = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder> 
           getResourceBuilderList() {
        return getResourceFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder>(
                  resource_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> container_ =
        java.util.Collections.emptyList();
      private void ensureContainerIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          container_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto>(container_);
          bitField0_ |= 0x00000002;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> containerBuilder_;

      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> getContainerList() {
        if (containerBuilder_ == null) {
          return java.util.Collections.unmodifiableList(container_);
        } else {
          return containerBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public int getContainerCount() {
        if (containerBuilder_ == null) {
          return container_.size();
        } else {
          return containerBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getContainer(int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);
        } else {
          return containerBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.set(index, value);
          onChanged();
        } else {
          containerBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder setContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.set(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(value);
          onChanged();
        } else {
          containerBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto value) {
        if (containerBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureContainerIsMutable();
          container_.add(index, value);
          onChanged();
        } else {
          containerBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addContainer(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder builderForValue) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.add(index, builderForValue.build());
          onChanged();
        } else {
          containerBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder addAllContainer(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto> values) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, container_);
          onChanged();
        } else {
          containerBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder clearContainer() {
        if (containerBuilder_ == null) {
          container_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000002);
          onChanged();
        } else {
          containerBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public Builder removeContainer(int index) {
        if (containerBuilder_ == null) {
          ensureContainerIsMutable();
          container_.remove(index);
          onChanged();
        } else {
          containerBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder getContainerBuilder(
          int index) {
        return getContainerFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder getContainerOrBuilder(
          int index) {
        if (containerBuilder_ == null) {
          return container_.get(index);  } else {
          return containerBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
           getContainerOrBuilderList() {
        if (containerBuilder_ != null) {
          return containerBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(container_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder() {
        return getContainerFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder addContainerBuilder(
          int index) {
        return getContainerFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.PreemptionContainerProto container = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder> 
           getContainerBuilderList() {
        return getContainerFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder> 
          getContainerFieldBuilder() {
        if (containerBuilder_ == null) {
          containerBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder>(
                  container_,
                  ((bitField0_ & 0x00000002) == 0x00000002),
                  getParentForChildren(),
                  isClean());
          container_ = null;
        }
        return containerBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionContractProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContractProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<PreemptionContractProto>
        PARSER = new com.google.protobuf.AbstractParser<PreemptionContractProto>() {
      public PreemptionContractProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new PreemptionContractProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PreemptionContractProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionContractProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContractProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PreemptionContainerProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.PreemptionContainerProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionContainerProto}
   */
  public  static final class PreemptionContainerProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.PreemptionContainerProto)
      PreemptionContainerProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PreemptionContainerProto.newBuilder() to construct.
    private PreemptionContainerProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PreemptionContainerProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionContainerProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = id_.toBuilder();
              }
              id_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(id_);
                id_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder.class);
    }

    private int bitField0_;
    public static final int ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
      return id_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
      return id_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getId());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getId());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && getId()
            .equals(other.getId());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + getId().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionContainerProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.PreemptionContainerProto)
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (idBuilder_ == null) {
          id_ = null;
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (idBuilder_ == null) {
          result.id_ = id_;
        } else {
          result.id_ = idBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          mergeId(other.getId());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto id_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> idBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getId() {
        if (idBuilder_ == null) {
          return id_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
        } else {
          return idBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          id_ = value;
          onChanged();
        } else {
          idBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder setId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (idBuilder_ == null) {
          id_ = builderForValue.build();
          onChanged();
        } else {
          idBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder mergeId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (idBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              id_ != null &&
              id_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            id_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(id_).mergeFrom(value).buildPartial();
          } else {
            id_ = value;
          }
          onChanged();
        } else {
          idBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public Builder clearId() {
        if (idBuilder_ == null) {
          id_ = null;
          onChanged();
        } else {
          idBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getIdOrBuilder() {
        if (idBuilder_ != null) {
          return idBuilder_.getMessageOrBuilder();
        } else {
          return id_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : id_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getIdFieldBuilder() {
        if (idBuilder_ == null) {
          idBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getId(),
                  getParentForChildren(),
                  isClean());
          id_ = null;
        }
        return idBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionContainerProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionContainerProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<PreemptionContainerProto>
        PARSER = new com.google.protobuf.AbstractParser<PreemptionContainerProto>() {
      public PreemptionContainerProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new PreemptionContainerProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PreemptionContainerProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionContainerProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionContainerProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface PreemptionResourceRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.PreemptionResourceRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.PreemptionResourceRequestProto}
   */
  public  static final class PreemptionResourceRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.PreemptionResourceRequestProto)
      PreemptionResourceRequestProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use PreemptionResourceRequestProto.newBuilder() to construct.
    private PreemptionResourceRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private PreemptionResourceRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private PreemptionResourceRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESOURCE_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : resource_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getResource());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getResource());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) obj;

      boolean result = true;
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.PreemptionResourceRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.PreemptionResourceRequestProto)
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getResourceFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (resourceBuilder_ == null) {
          resource_ = null;
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto.getDefaultInstance()) return this;
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto resource_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              resource_ != null &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = null;
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto resource = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder>(
                  getResource(),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.PreemptionResourceRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.PreemptionResourceRequestProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<PreemptionResourceRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<PreemptionResourceRequestProto>() {
      public PreemptionResourceRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new PreemptionResourceRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<PreemptionResourceRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<PreemptionResourceRequestProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.PreemptionResourceRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ResourceBlacklistRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ResourceBlacklistRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    java.util.List<java.lang.String>
        getBlacklistAdditionsList();
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    int getBlacklistAdditionsCount();
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    java.lang.String getBlacklistAdditions(int index);
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    com.google.protobuf.ByteString
        getBlacklistAdditionsBytes(int index);

    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    java.util.List<java.lang.String>
        getBlacklistRemovalsList();
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    int getBlacklistRemovalsCount();
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    java.lang.String getBlacklistRemovals(int index);
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    com.google.protobuf.ByteString
        getBlacklistRemovalsBytes(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ResourceBlacklistRequestProto}
   */
  public  static final class ResourceBlacklistRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ResourceBlacklistRequestProto)
      ResourceBlacklistRequestProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ResourceBlacklistRequestProto.newBuilder() to construct.
    private ResourceBlacklistRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ResourceBlacklistRequestProto() {
      blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ResourceBlacklistRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                blacklistAdditions_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000001;
              }
              blacklistAdditions_.add(bs);
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                blacklistRemovals_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000002;
              }
              blacklistRemovals_.add(bs);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = blacklistAdditions_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = blacklistRemovals_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder.class);
    }

    public static final int BLACKLIST_ADDITIONS_FIELD_NUMBER = 1;
    private com.google.protobuf.LazyStringList blacklistAdditions_;
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getBlacklistAdditionsList() {
      return blacklistAdditions_;
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public int getBlacklistAdditionsCount() {
      return blacklistAdditions_.size();
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public java.lang.String getBlacklistAdditions(int index) {
      return blacklistAdditions_.get(index);
    }
    /**
     * <code>repeated string blacklist_additions = 1;</code>
     */
    public com.google.protobuf.ByteString
        getBlacklistAdditionsBytes(int index) {
      return blacklistAdditions_.getByteString(index);
    }

    public static final int BLACKLIST_REMOVALS_FIELD_NUMBER = 2;
    private com.google.protobuf.LazyStringList blacklistRemovals_;
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getBlacklistRemovalsList() {
      return blacklistRemovals_;
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public int getBlacklistRemovalsCount() {
      return blacklistRemovals_.size();
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public java.lang.String getBlacklistRemovals(int index) {
      return blacklistRemovals_.get(index);
    }
    /**
     * <code>repeated string blacklist_removals = 2;</code>
     */
    public com.google.protobuf.ByteString
        getBlacklistRemovalsBytes(int index) {
      return blacklistRemovals_.getByteString(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < blacklistAdditions_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, blacklistAdditions_.getRaw(i));
      }
      for (int i = 0; i < blacklistRemovals_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, blacklistRemovals_.getRaw(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      {
        int dataSize = 0;
        for (int i = 0; i < blacklistAdditions_.size(); i++) {
          dataSize += computeStringSizeNoTag(blacklistAdditions_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getBlacklistAdditionsList().size();
      }
      {
        int dataSize = 0;
        for (int i = 0; i < blacklistRemovals_.size(); i++) {
          dataSize += computeStringSizeNoTag(blacklistRemovals_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getBlacklistRemovalsList().size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) obj;

      boolean result = true;
      result = result && getBlacklistAdditionsList()
          .equals(other.getBlacklistAdditionsList());
      result = result && getBlacklistRemovalsList()
          .equals(other.getBlacklistRemovalsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getBlacklistAdditionsCount() > 0) {
        hash = (37 * hash) + BLACKLIST_ADDITIONS_FIELD_NUMBER;
        hash = (53 * hash) + getBlacklistAdditionsList().hashCode();
      }
      if (getBlacklistRemovalsCount() > 0) {
        hash = (37 * hash) + BLACKLIST_REMOVALS_FIELD_NUMBER;
        hash = (53 * hash) + getBlacklistRemovalsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ResourceBlacklistRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ResourceBlacklistRequestProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto(this);
        int from_bitField0_ = bitField0_;
        if (((bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = blacklistAdditions_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000001);
        }
        result.blacklistAdditions_ = blacklistAdditions_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = blacklistRemovals_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.blacklistRemovals_ = blacklistRemovals_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto.getDefaultInstance()) return this;
        if (!other.blacklistAdditions_.isEmpty()) {
          if (blacklistAdditions_.isEmpty()) {
            blacklistAdditions_ = other.blacklistAdditions_;
            bitField0_ = (bitField0_ & ~0x00000001);
          } else {
            ensureBlacklistAdditionsIsMutable();
            blacklistAdditions_.addAll(other.blacklistAdditions_);
          }
          onChanged();
        }
        if (!other.blacklistRemovals_.isEmpty()) {
          if (blacklistRemovals_.isEmpty()) {
            blacklistRemovals_ = other.blacklistRemovals_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureBlacklistRemovalsIsMutable();
            blacklistRemovals_.addAll(other.blacklistRemovals_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private com.google.protobuf.LazyStringList blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureBlacklistAdditionsIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          blacklistAdditions_ = new com.google.protobuf.LazyStringArrayList(blacklistAdditions_);
          bitField0_ |= 0x00000001;
         }
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getBlacklistAdditionsList() {
        return blacklistAdditions_.getUnmodifiableView();
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public int getBlacklistAdditionsCount() {
        return blacklistAdditions_.size();
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public java.lang.String getBlacklistAdditions(int index) {
        return blacklistAdditions_.get(index);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public com.google.protobuf.ByteString
          getBlacklistAdditionsBytes(int index) {
        return blacklistAdditions_.getByteString(index);
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder setBlacklistAdditions(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addBlacklistAdditions(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addAllBlacklistAdditions(
          java.lang.Iterable<java.lang.String> values) {
        ensureBlacklistAdditionsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, blacklistAdditions_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder clearBlacklistAdditions() {
        blacklistAdditions_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000001);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_additions = 1;</code>
       */
      public Builder addBlacklistAdditionsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistAdditionsIsMutable();
        blacklistAdditions_.add(value);
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureBlacklistRemovalsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          blacklistRemovals_ = new com.google.protobuf.LazyStringArrayList(blacklistRemovals_);
          bitField0_ |= 0x00000002;
         }
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getBlacklistRemovalsList() {
        return blacklistRemovals_.getUnmodifiableView();
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public int getBlacklistRemovalsCount() {
        return blacklistRemovals_.size();
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public java.lang.String getBlacklistRemovals(int index) {
        return blacklistRemovals_.get(index);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public com.google.protobuf.ByteString
          getBlacklistRemovalsBytes(int index) {
        return blacklistRemovals_.getByteString(index);
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder setBlacklistRemovals(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addBlacklistRemovals(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addAllBlacklistRemovals(
          java.lang.Iterable<java.lang.String> values) {
        ensureBlacklistRemovalsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, blacklistRemovals_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder clearBlacklistRemovals() {
        blacklistRemovals_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string blacklist_removals = 2;</code>
       */
      public Builder addBlacklistRemovalsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureBlacklistRemovalsIsMutable();
        blacklistRemovals_.add(value);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ResourceBlacklistRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ResourceBlacklistRequestProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ResourceBlacklistRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ResourceBlacklistRequestProto>() {
      public ResourceBlacklistRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ResourceBlacklistRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ResourceBlacklistRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ResourceBlacklistRequestProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceBlacklistRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationSubmissionContextProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ApplicationSubmissionContextProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    boolean hasApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId();
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder();

    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    boolean hasApplicationName();
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    java.lang.String getApplicationName();
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getApplicationNameBytes();

    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    boolean hasQueue();
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    java.lang.String getQueue();
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    com.google.protobuf.ByteString
        getQueueBytes();

    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    boolean hasPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority();
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    boolean hasAmContainerSpec();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec();
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder();

    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    boolean hasCancelTokensWhenComplete();
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    boolean getCancelTokensWhenComplete();

    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    boolean hasUnmanagedAm();
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    boolean getUnmanagedAm();

    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    boolean hasMaxAppAttempts();
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    int getMaxAppAttempts();

    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    boolean hasResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource();
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder();

    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    boolean hasApplicationType();
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    java.lang.String getApplicationType();
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    com.google.protobuf.ByteString
        getApplicationTypeBytes();

    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    boolean hasKeepContainersAcrossApplicationAttempts();
    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    boolean getKeepContainersAcrossApplicationAttempts();

    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    java.util.List<java.lang.String>
        getApplicationTagsList();
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    int getApplicationTagsCount();
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    java.lang.String getApplicationTags(int index);
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    com.google.protobuf.ByteString
        getApplicationTagsBytes(int index);

    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    boolean hasAttemptFailuresValidityInterval();
    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    long getAttemptFailuresValidityInterval();

    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    boolean hasLogAggregationContext();
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getLogAggregationContext();
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder getLogAggregationContextOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    boolean hasReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId();
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder();

    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    boolean hasNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    java.lang.String getNodeLabelExpression();
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    com.google.protobuf.ByteString
        getNodeLabelExpressionBytes();

    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    boolean hasAmContainerResourceRequest();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAmContainerResourceRequest();
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAmContainerResourceRequestOrBuilder();
  }
  /**
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From client_RM_Protocol /////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   *
   * Protobuf type {@code hadoop.yarn.ApplicationSubmissionContextProto}
   */
  public  static final class ApplicationSubmissionContextProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ApplicationSubmissionContextProto)
      ApplicationSubmissionContextProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationSubmissionContextProto.newBuilder() to construct.
    private ApplicationSubmissionContextProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationSubmissionContextProto() {
      applicationName_ = "N/A";
      queue_ = "default";
      cancelTokensWhenComplete_ = true;
      unmanagedAm_ = false;
      maxAppAttempts_ = 0;
      applicationType_ = "YARN";
      keepContainersAcrossApplicationAttempts_ = false;
      applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      attemptFailuresValidityInterval_ = -1L;
      nodeLabelExpression_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationSubmissionContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = applicationId_.toBuilder();
              }
              applicationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(applicationId_);
                applicationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              applicationName_ = bs;
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              queue_ = bs;
              break;
            }
            case 34: {
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000008) == 0x00000008)) {
                subBuilder = priority_.toBuilder();
              }
              priority_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(priority_);
                priority_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000008;
              break;
            }
            case 42: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000010) == 0x00000010)) {
                subBuilder = amContainerSpec_.toBuilder();
              }
              amContainerSpec_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amContainerSpec_);
                amContainerSpec_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000010;
              break;
            }
            case 48: {
              bitField0_ |= 0x00000020;
              cancelTokensWhenComplete_ = input.readBool();
              break;
            }
            case 56: {
              bitField0_ |= 0x00000040;
              unmanagedAm_ = input.readBool();
              break;
            }
            case 64: {
              bitField0_ |= 0x00000080;
              maxAppAttempts_ = input.readInt32();
              break;
            }
            case 74: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000100) == 0x00000100)) {
                subBuilder = resource_.toBuilder();
              }
              resource_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(resource_);
                resource_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000100;
              break;
            }
            case 82: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000200;
              applicationType_ = bs;
              break;
            }
            case 88: {
              bitField0_ |= 0x00000400;
              keepContainersAcrossApplicationAttempts_ = input.readBool();
              break;
            }
            case 98: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
                applicationTags_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000800;
              }
              applicationTags_.add(bs);
              break;
            }
            case 104: {
              bitField0_ |= 0x00000800;
              attemptFailuresValidityInterval_ = input.readInt64();
              break;
            }
            case 114: {
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00001000) == 0x00001000)) {
                subBuilder = logAggregationContext_.toBuilder();
              }
              logAggregationContext_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(logAggregationContext_);
                logAggregationContext_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00001000;
              break;
            }
            case 122: {
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00002000) == 0x00002000)) {
                subBuilder = reservationId_.toBuilder();
              }
              reservationId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationId_);
                reservationId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00002000;
              break;
            }
            case 130: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00004000;
              nodeLabelExpression_ = bs;
              break;
            }
            case 138: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00008000) == 0x00008000)) {
                subBuilder = amContainerResourceRequest_.toBuilder();
              }
              amContainerResourceRequest_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(amContainerResourceRequest_);
                amContainerResourceRequest_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00008000;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000800) == 0x00000800)) {
          applicationTags_ = applicationTags_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder.class);
    }

    private int bitField0_;
    public static final int APPLICATION_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_;
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public boolean hasApplicationId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
      return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
      return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
    }

    public static final int APPLICATION_NAME_FIELD_NUMBER = 2;
    private volatile java.lang.Object applicationName_;
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public boolean hasApplicationName() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public java.lang.String getApplicationName() {
      java.lang.Object ref = applicationName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string application_name = 2 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getApplicationNameBytes() {
      java.lang.Object ref = applicationName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int QUEUE_FIELD_NUMBER = 3;
    private volatile java.lang.Object queue_;
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public boolean hasQueue() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public java.lang.String getQueue() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queue_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queue = 3 [default = "default"];</code>
     */
    public com.google.protobuf.ByteString
        getQueueBytes() {
      java.lang.Object ref = queue_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queue_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int PRIORITY_FIELD_NUMBER = 4;
    private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_;
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public boolean hasPriority() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }
    /**
     * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
      return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
    }

    public static final int AM_CONTAINER_SPEC_FIELD_NUMBER = 5;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto amContainerSpec_;
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public boolean hasAmContainerSpec() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec() {
      return amContainerSpec_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : amContainerSpec_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder() {
      return amContainerSpec_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : amContainerSpec_;
    }

    public static final int CANCEL_TOKENS_WHEN_COMPLETE_FIELD_NUMBER = 6;
    private boolean cancelTokensWhenComplete_;
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    public boolean hasCancelTokensWhenComplete() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
     */
    public boolean getCancelTokensWhenComplete() {
      return cancelTokensWhenComplete_;
    }

    public static final int UNMANAGED_AM_FIELD_NUMBER = 7;
    private boolean unmanagedAm_;
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    public boolean hasUnmanagedAm() {
      return ((bitField0_ & 0x00000040) == 0x00000040);
    }
    /**
     * <code>optional bool unmanaged_am = 7 [default = false];</code>
     */
    public boolean getUnmanagedAm() {
      return unmanagedAm_;
    }

    public static final int MAXAPPATTEMPTS_FIELD_NUMBER = 8;
    private int maxAppAttempts_;
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    public boolean hasMaxAppAttempts() {
      return ((bitField0_ & 0x00000080) == 0x00000080);
    }
    /**
     * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
     */
    public int getMaxAppAttempts() {
      return maxAppAttempts_;
    }

    public static final int RESOURCE_FIELD_NUMBER = 9;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public boolean hasResource() {
      return ((bitField0_ & 0x00000100) == 0x00000100);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
      return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
    }

    public static final int APPLICATIONTYPE_FIELD_NUMBER = 10;
    private volatile java.lang.Object applicationType_;
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public boolean hasApplicationType() {
      return ((bitField0_ & 0x00000200) == 0x00000200);
    }
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public java.lang.String getApplicationType() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          applicationType_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string applicationType = 10 [default = "YARN"];</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTypeBytes() {
      java.lang.Object ref = applicationType_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        applicationType_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int KEEP_CONTAINERS_ACROSS_APPLICATION_ATTEMPTS_FIELD_NUMBER = 11;
    private boolean keepContainersAcrossApplicationAttempts_;
    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    public boolean hasKeepContainersAcrossApplicationAttempts() {
      return ((bitField0_ & 0x00000400) == 0x00000400);
    }
    /**
     * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
     */
    public boolean getKeepContainersAcrossApplicationAttempts() {
      return keepContainersAcrossApplicationAttempts_;
    }

    public static final int APPLICATIONTAGS_FIELD_NUMBER = 12;
    private com.google.protobuf.LazyStringList applicationTags_;
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getApplicationTagsList() {
      return applicationTags_;
    }
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public int getApplicationTagsCount() {
      return applicationTags_.size();
    }
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public java.lang.String getApplicationTags(int index) {
      return applicationTags_.get(index);
    }
    /**
     * <code>repeated string applicationTags = 12;</code>
     */
    public com.google.protobuf.ByteString
        getApplicationTagsBytes(int index) {
      return applicationTags_.getByteString(index);
    }

    public static final int ATTEMPT_FAILURES_VALIDITY_INTERVAL_FIELD_NUMBER = 13;
    private long attemptFailuresValidityInterval_;
    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    public boolean hasAttemptFailuresValidityInterval() {
      return ((bitField0_ & 0x00000800) == 0x00000800);
    }
    /**
     * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
     */
    public long getAttemptFailuresValidityInterval() {
      return attemptFailuresValidityInterval_;
    }

    public static final int LOG_AGGREGATION_CONTEXT_FIELD_NUMBER = 14;
    private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto logAggregationContext_;
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    public boolean hasLogAggregationContext() {
      return ((bitField0_ & 0x00001000) == 0x00001000);
    }
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getLogAggregationContext() {
      return logAggregationContext_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance() : logAggregationContext_;
    }
    /**
     * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder getLogAggregationContextOrBuilder() {
      return logAggregationContext_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance() : logAggregationContext_;
    }

    public static final int RESERVATION_ID_FIELD_NUMBER = 15;
    private org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_;
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    public boolean hasReservationId() {
      return ((bitField0_ & 0x00002000) == 0x00002000);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
      return reservationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
      return reservationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
    }

    public static final int NODE_LABEL_EXPRESSION_FIELD_NUMBER = 16;
    private volatile java.lang.Object nodeLabelExpression_;
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    public boolean hasNodeLabelExpression() {
      return ((bitField0_ & 0x00004000) == 0x00004000);
    }
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    public java.lang.String getNodeLabelExpression() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          nodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string node_label_expression = 16;</code>
     */
    public com.google.protobuf.ByteString
        getNodeLabelExpressionBytes() {
      java.lang.Object ref = nodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        nodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int AM_CONTAINER_RESOURCE_REQUEST_FIELD_NUMBER = 17;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto amContainerResourceRequest_;
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public boolean hasAmContainerResourceRequest() {
      return ((bitField0_ & 0x00008000) == 0x00008000);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAmContainerResourceRequest() {
      return amContainerResourceRequest_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : amContainerResourceRequest_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAmContainerResourceRequestOrBuilder() {
      return amContainerResourceRequest_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : amContainerResourceRequest_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, applicationName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, queue_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeMessage(4, getPriority());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeMessage(5, getAmContainerSpec());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        output.writeBool(6, cancelTokensWhenComplete_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        output.writeBool(7, unmanagedAm_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        output.writeInt32(8, maxAppAttempts_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        output.writeMessage(9, getResource());
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 10, applicationType_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        output.writeBool(11, keepContainersAcrossApplicationAttempts_);
      }
      for (int i = 0; i < applicationTags_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 12, applicationTags_.getRaw(i));
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        output.writeInt64(13, attemptFailuresValidityInterval_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        output.writeMessage(14, getLogAggregationContext());
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        output.writeMessage(15, getReservationId());
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 16, nodeLabelExpression_);
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        output.writeMessage(17, getAmContainerResourceRequest());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getApplicationId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, applicationName_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, queue_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, getPriority());
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(5, getAmContainerSpec());
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(6, cancelTokensWhenComplete_);
      }
      if (((bitField0_ & 0x00000040) == 0x00000040)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(7, unmanagedAm_);
      }
      if (((bitField0_ & 0x00000080) == 0x00000080)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(8, maxAppAttempts_);
      }
      if (((bitField0_ & 0x00000100) == 0x00000100)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(9, getResource());
      }
      if (((bitField0_ & 0x00000200) == 0x00000200)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(10, applicationType_);
      }
      if (((bitField0_ & 0x00000400) == 0x00000400)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBoolSize(11, keepContainersAcrossApplicationAttempts_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < applicationTags_.size(); i++) {
          dataSize += computeStringSizeNoTag(applicationTags_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getApplicationTagsList().size();
      }
      if (((bitField0_ & 0x00000800) == 0x00000800)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(13, attemptFailuresValidityInterval_);
      }
      if (((bitField0_ & 0x00001000) == 0x00001000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(14, getLogAggregationContext());
      }
      if (((bitField0_ & 0x00002000) == 0x00002000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(15, getReservationId());
      }
      if (((bitField0_ & 0x00004000) == 0x00004000)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(16, nodeLabelExpression_);
      }
      if (((bitField0_ & 0x00008000) == 0x00008000)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(17, getAmContainerResourceRequest());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) obj;

      boolean result = true;
      result = result && (hasApplicationId() == other.hasApplicationId());
      if (hasApplicationId()) {
        result = result && getApplicationId()
            .equals(other.getApplicationId());
      }
      result = result && (hasApplicationName() == other.hasApplicationName());
      if (hasApplicationName()) {
        result = result && getApplicationName()
            .equals(other.getApplicationName());
      }
      result = result && (hasQueue() == other.hasQueue());
      if (hasQueue()) {
        result = result && getQueue()
            .equals(other.getQueue());
      }
      result = result && (hasPriority() == other.hasPriority());
      if (hasPriority()) {
        result = result && getPriority()
            .equals(other.getPriority());
      }
      result = result && (hasAmContainerSpec() == other.hasAmContainerSpec());
      if (hasAmContainerSpec()) {
        result = result && getAmContainerSpec()
            .equals(other.getAmContainerSpec());
      }
      result = result && (hasCancelTokensWhenComplete() == other.hasCancelTokensWhenComplete());
      if (hasCancelTokensWhenComplete()) {
        result = result && (getCancelTokensWhenComplete()
            == other.getCancelTokensWhenComplete());
      }
      result = result && (hasUnmanagedAm() == other.hasUnmanagedAm());
      if (hasUnmanagedAm()) {
        result = result && (getUnmanagedAm()
            == other.getUnmanagedAm());
      }
      result = result && (hasMaxAppAttempts() == other.hasMaxAppAttempts());
      if (hasMaxAppAttempts()) {
        result = result && (getMaxAppAttempts()
            == other.getMaxAppAttempts());
      }
      result = result && (hasResource() == other.hasResource());
      if (hasResource()) {
        result = result && getResource()
            .equals(other.getResource());
      }
      result = result && (hasApplicationType() == other.hasApplicationType());
      if (hasApplicationType()) {
        result = result && getApplicationType()
            .equals(other.getApplicationType());
      }
      result = result && (hasKeepContainersAcrossApplicationAttempts() == other.hasKeepContainersAcrossApplicationAttempts());
      if (hasKeepContainersAcrossApplicationAttempts()) {
        result = result && (getKeepContainersAcrossApplicationAttempts()
            == other.getKeepContainersAcrossApplicationAttempts());
      }
      result = result && getApplicationTagsList()
          .equals(other.getApplicationTagsList());
      result = result && (hasAttemptFailuresValidityInterval() == other.hasAttemptFailuresValidityInterval());
      if (hasAttemptFailuresValidityInterval()) {
        result = result && (getAttemptFailuresValidityInterval()
            == other.getAttemptFailuresValidityInterval());
      }
      result = result && (hasLogAggregationContext() == other.hasLogAggregationContext());
      if (hasLogAggregationContext()) {
        result = result && getLogAggregationContext()
            .equals(other.getLogAggregationContext());
      }
      result = result && (hasReservationId() == other.hasReservationId());
      if (hasReservationId()) {
        result = result && getReservationId()
            .equals(other.getReservationId());
      }
      result = result && (hasNodeLabelExpression() == other.hasNodeLabelExpression());
      if (hasNodeLabelExpression()) {
        result = result && getNodeLabelExpression()
            .equals(other.getNodeLabelExpression());
      }
      result = result && (hasAmContainerResourceRequest() == other.hasAmContainerResourceRequest());
      if (hasAmContainerResourceRequest()) {
        result = result && getAmContainerResourceRequest()
            .equals(other.getAmContainerResourceRequest());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasApplicationId()) {
        hash = (37 * hash) + APPLICATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationId().hashCode();
      }
      if (hasApplicationName()) {
        hash = (37 * hash) + APPLICATION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationName().hashCode();
      }
      if (hasQueue()) {
        hash = (37 * hash) + QUEUE_FIELD_NUMBER;
        hash = (53 * hash) + getQueue().hashCode();
      }
      if (hasPriority()) {
        hash = (37 * hash) + PRIORITY_FIELD_NUMBER;
        hash = (53 * hash) + getPriority().hashCode();
      }
      if (hasAmContainerSpec()) {
        hash = (37 * hash) + AM_CONTAINER_SPEC_FIELD_NUMBER;
        hash = (53 * hash) + getAmContainerSpec().hashCode();
      }
      if (hasCancelTokensWhenComplete()) {
        hash = (37 * hash) + CANCEL_TOKENS_WHEN_COMPLETE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getCancelTokensWhenComplete());
      }
      if (hasUnmanagedAm()) {
        hash = (37 * hash) + UNMANAGED_AM_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getUnmanagedAm());
      }
      if (hasMaxAppAttempts()) {
        hash = (37 * hash) + MAXAPPATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + getMaxAppAttempts();
      }
      if (hasResource()) {
        hash = (37 * hash) + RESOURCE_FIELD_NUMBER;
        hash = (53 * hash) + getResource().hashCode();
      }
      if (hasApplicationType()) {
        hash = (37 * hash) + APPLICATIONTYPE_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationType().hashCode();
      }
      if (hasKeepContainersAcrossApplicationAttempts()) {
        hash = (37 * hash) + KEEP_CONTAINERS_ACROSS_APPLICATION_ATTEMPTS_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashBoolean(
            getKeepContainersAcrossApplicationAttempts());
      }
      if (getApplicationTagsCount() > 0) {
        hash = (37 * hash) + APPLICATIONTAGS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationTagsList().hashCode();
      }
      if (hasAttemptFailuresValidityInterval()) {
        hash = (37 * hash) + ATTEMPT_FAILURES_VALIDITY_INTERVAL_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getAttemptFailuresValidityInterval());
      }
      if (hasLogAggregationContext()) {
        hash = (37 * hash) + LOG_AGGREGATION_CONTEXT_FIELD_NUMBER;
        hash = (53 * hash) + getLogAggregationContext().hashCode();
      }
      if (hasReservationId()) {
        hash = (37 * hash) + RESERVATION_ID_FIELD_NUMBER;
        hash = (53 * hash) + getReservationId().hashCode();
      }
      if (hasNodeLabelExpression()) {
        hash = (37 * hash) + NODE_LABEL_EXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getNodeLabelExpression().hashCode();
      }
      if (hasAmContainerResourceRequest()) {
        hash = (37 * hash) + AM_CONTAINER_RESOURCE_REQUEST_FIELD_NUMBER;
        hash = (53 * hash) + getAmContainerResourceRequest().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From client_RM_Protocol /////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     *
     * Protobuf type {@code hadoop.yarn.ApplicationSubmissionContextProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ApplicationSubmissionContextProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getApplicationIdFieldBuilder();
          getPriorityFieldBuilder();
          getAmContainerSpecFieldBuilder();
          getResourceFieldBuilder();
          getLogAggregationContextFieldBuilder();
          getReservationIdFieldBuilder();
          getAmContainerResourceRequestFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        applicationName_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000002);
        queue_ = "default";
        bitField0_ = (bitField0_ & ~0x00000004);
        if (priorityBuilder_ == null) {
          priority_ = null;
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = null;
        } else {
          amContainerSpecBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        cancelTokensWhenComplete_ = true;
        bitField0_ = (bitField0_ & ~0x00000020);
        unmanagedAm_ = false;
        bitField0_ = (bitField0_ & ~0x00000040);
        maxAppAttempts_ = 0;
        bitField0_ = (bitField0_ & ~0x00000080);
        if (resourceBuilder_ == null) {
          resource_ = null;
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        applicationType_ = "YARN";
        bitField0_ = (bitField0_ & ~0x00000200);
        keepContainersAcrossApplicationAttempts_ = false;
        bitField0_ = (bitField0_ & ~0x00000400);
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000800);
        attemptFailuresValidityInterval_ = -1L;
        bitField0_ = (bitField0_ & ~0x00001000);
        if (logAggregationContextBuilder_ == null) {
          logAggregationContext_ = null;
        } else {
          logAggregationContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        nodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00008000);
        if (amContainerResourceRequestBuilder_ == null) {
          amContainerResourceRequest_ = null;
        } else {
          amContainerResourceRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00010000);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (applicationIdBuilder_ == null) {
          result.applicationId_ = applicationId_;
        } else {
          result.applicationId_ = applicationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.applicationName_ = applicationName_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.queue_ = queue_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        if (priorityBuilder_ == null) {
          result.priority_ = priority_;
        } else {
          result.priority_ = priorityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        if (amContainerSpecBuilder_ == null) {
          result.amContainerSpec_ = amContainerSpec_;
        } else {
          result.amContainerSpec_ = amContainerSpecBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000020) == 0x00000020)) {
          to_bitField0_ |= 0x00000020;
        }
        result.cancelTokensWhenComplete_ = cancelTokensWhenComplete_;
        if (((from_bitField0_ & 0x00000040) == 0x00000040)) {
          to_bitField0_ |= 0x00000040;
        }
        result.unmanagedAm_ = unmanagedAm_;
        if (((from_bitField0_ & 0x00000080) == 0x00000080)) {
          to_bitField0_ |= 0x00000080;
        }
        result.maxAppAttempts_ = maxAppAttempts_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000100;
        }
        if (resourceBuilder_ == null) {
          result.resource_ = resource_;
        } else {
          result.resource_ = resourceBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000200) == 0x00000200)) {
          to_bitField0_ |= 0x00000200;
        }
        result.applicationType_ = applicationType_;
        if (((from_bitField0_ & 0x00000400) == 0x00000400)) {
          to_bitField0_ |= 0x00000400;
        }
        result.keepContainersAcrossApplicationAttempts_ = keepContainersAcrossApplicationAttempts_;
        if (((bitField0_ & 0x00000800) == 0x00000800)) {
          applicationTags_ = applicationTags_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000800);
        }
        result.applicationTags_ = applicationTags_;
        if (((from_bitField0_ & 0x00001000) == 0x00001000)) {
          to_bitField0_ |= 0x00000800;
        }
        result.attemptFailuresValidityInterval_ = attemptFailuresValidityInterval_;
        if (((from_bitField0_ & 0x00002000) == 0x00002000)) {
          to_bitField0_ |= 0x00001000;
        }
        if (logAggregationContextBuilder_ == null) {
          result.logAggregationContext_ = logAggregationContext_;
        } else {
          result.logAggregationContext_ = logAggregationContextBuilder_.build();
        }
        if (((from_bitField0_ & 0x00004000) == 0x00004000)) {
          to_bitField0_ |= 0x00002000;
        }
        if (reservationIdBuilder_ == null) {
          result.reservationId_ = reservationId_;
        } else {
          result.reservationId_ = reservationIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00008000) == 0x00008000)) {
          to_bitField0_ |= 0x00004000;
        }
        result.nodeLabelExpression_ = nodeLabelExpression_;
        if (((from_bitField0_ & 0x00010000) == 0x00010000)) {
          to_bitField0_ |= 0x00008000;
        }
        if (amContainerResourceRequestBuilder_ == null) {
          result.amContainerResourceRequest_ = amContainerResourceRequest_;
        } else {
          result.amContainerResourceRequest_ = amContainerResourceRequestBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto.getDefaultInstance()) return this;
        if (other.hasApplicationId()) {
          mergeApplicationId(other.getApplicationId());
        }
        if (other.hasApplicationName()) {
          bitField0_ |= 0x00000002;
          applicationName_ = other.applicationName_;
          onChanged();
        }
        if (other.hasQueue()) {
          bitField0_ |= 0x00000004;
          queue_ = other.queue_;
          onChanged();
        }
        if (other.hasPriority()) {
          mergePriority(other.getPriority());
        }
        if (other.hasAmContainerSpec()) {
          mergeAmContainerSpec(other.getAmContainerSpec());
        }
        if (other.hasCancelTokensWhenComplete()) {
          setCancelTokensWhenComplete(other.getCancelTokensWhenComplete());
        }
        if (other.hasUnmanagedAm()) {
          setUnmanagedAm(other.getUnmanagedAm());
        }
        if (other.hasMaxAppAttempts()) {
          setMaxAppAttempts(other.getMaxAppAttempts());
        }
        if (other.hasResource()) {
          mergeResource(other.getResource());
        }
        if (other.hasApplicationType()) {
          bitField0_ |= 0x00000200;
          applicationType_ = other.applicationType_;
          onChanged();
        }
        if (other.hasKeepContainersAcrossApplicationAttempts()) {
          setKeepContainersAcrossApplicationAttempts(other.getKeepContainersAcrossApplicationAttempts());
        }
        if (!other.applicationTags_.isEmpty()) {
          if (applicationTags_.isEmpty()) {
            applicationTags_ = other.applicationTags_;
            bitField0_ = (bitField0_ & ~0x00000800);
          } else {
            ensureApplicationTagsIsMutable();
            applicationTags_.addAll(other.applicationTags_);
          }
          onChanged();
        }
        if (other.hasAttemptFailuresValidityInterval()) {
          setAttemptFailuresValidityInterval(other.getAttemptFailuresValidityInterval());
        }
        if (other.hasLogAggregationContext()) {
          mergeLogAggregationContext(other.getLogAggregationContext());
        }
        if (other.hasReservationId()) {
          mergeReservationId(other.getReservationId());
        }
        if (other.hasNodeLabelExpression()) {
          bitField0_ |= 0x00008000;
          nodeLabelExpression_ = other.nodeLabelExpression_;
          onChanged();
        }
        if (other.hasAmContainerResourceRequest()) {
          mergeAmContainerResourceRequest(other.getAmContainerResourceRequest());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto applicationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> applicationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public boolean hasApplicationId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto getApplicationId() {
        if (applicationIdBuilder_ == null) {
          return applicationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        } else {
          return applicationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          applicationId_ = value;
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder setApplicationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder builderForValue) {
        if (applicationIdBuilder_ == null) {
          applicationId_ = builderForValue.build();
          onChanged();
        } else {
          applicationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder mergeApplicationId(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto value) {
        if (applicationIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              applicationId_ != null &&
              applicationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance()) {
            applicationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.newBuilder(applicationId_).mergeFrom(value).buildPartial();
          } else {
            applicationId_ = value;
          }
          onChanged();
        } else {
          applicationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public Builder clearApplicationId() {
        if (applicationIdBuilder_ == null) {
          applicationId_ = null;
          onChanged();
        } else {
          applicationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder getApplicationIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getApplicationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder getApplicationIdOrBuilder() {
        if (applicationIdBuilder_ != null) {
          return applicationIdBuilder_.getMessageOrBuilder();
        } else {
          return applicationId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.getDefaultInstance() : applicationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationIdProto application_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder> 
          getApplicationIdFieldBuilder() {
        if (applicationIdBuilder_ == null) {
          applicationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationIdProtoOrBuilder>(
                  getApplicationId(),
                  getParentForChildren(),
                  isClean());
          applicationId_ = null;
        }
        return applicationIdBuilder_;
      }

      private java.lang.Object applicationName_ = "N/A";
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public boolean hasApplicationName() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public java.lang.String getApplicationName() {
        java.lang.Object ref = applicationName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            applicationName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getApplicationNameBytes() {
        java.lang.Object ref = applicationName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder setApplicationName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        applicationName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder clearApplicationName() {
        bitField0_ = (bitField0_ & ~0x00000002);
        applicationName_ = getDefaultInstance().getApplicationName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string application_name = 2 [default = "N/A"];</code>
       */
      public Builder setApplicationNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        applicationName_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object queue_ = "default";
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public boolean hasQueue() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public java.lang.String getQueue() {
        java.lang.Object ref = queue_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queue_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public com.google.protobuf.ByteString
          getQueueBytes() {
        java.lang.Object ref = queue_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queue_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder setQueue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder clearQueue() {
        bitField0_ = (bitField0_ & ~0x00000004);
        queue_ = getDefaultInstance().getQueue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queue = 3 [default = "default"];</code>
       */
      public Builder setQueueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        queue_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto priority_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> priorityBuilder_;
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public boolean hasPriority() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto getPriority() {
        if (priorityBuilder_ == null) {
          return priority_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        } else {
          return priorityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          priority_ = value;
          onChanged();
        } else {
          priorityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder setPriority(
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder builderForValue) {
        if (priorityBuilder_ == null) {
          priority_ = builderForValue.build();
          onChanged();
        } else {
          priorityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder mergePriority(org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto value) {
        if (priorityBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008) &&
              priority_ != null &&
              priority_ != org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance()) {
            priority_ =
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.newBuilder(priority_).mergeFrom(value).buildPartial();
          } else {
            priority_ = value;
          }
          onChanged();
        } else {
          priorityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000008;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public Builder clearPriority() {
        if (priorityBuilder_ == null) {
          priority_ = null;
          onChanged();
        } else {
          priorityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder getPriorityBuilder() {
        bitField0_ |= 0x00000008;
        onChanged();
        return getPriorityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder getPriorityOrBuilder() {
        if (priorityBuilder_ != null) {
          return priorityBuilder_.getMessageOrBuilder();
        } else {
          return priority_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.getDefaultInstance() : priority_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.PriorityProto priority = 4;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder> 
          getPriorityFieldBuilder() {
        if (priorityBuilder_ == null) {
          priorityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.PriorityProtoOrBuilder>(
                  getPriority(),
                  getParentForChildren(),
                  isClean());
          priority_ = null;
        }
        return priorityBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto amContainerSpec_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> amContainerSpecBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public boolean hasAmContainerSpec() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getAmContainerSpec() {
        if (amContainerSpecBuilder_ == null) {
          return amContainerSpec_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : amContainerSpec_;
        } else {
          return amContainerSpecBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder setAmContainerSpec(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (amContainerSpecBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amContainerSpec_ = value;
          onChanged();
        } else {
          amContainerSpecBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder setAmContainerSpec(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder builderForValue) {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = builderForValue.build();
          onChanged();
        } else {
          amContainerSpecBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder mergeAmContainerSpec(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto value) {
        if (amContainerSpecBuilder_ == null) {
          if (((bitField0_ & 0x00000010) == 0x00000010) &&
              amContainerSpec_ != null &&
              amContainerSpec_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) {
            amContainerSpec_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder(amContainerSpec_).mergeFrom(value).buildPartial();
          } else {
            amContainerSpec_ = value;
          }
          onChanged();
        } else {
          amContainerSpecBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000010;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public Builder clearAmContainerSpec() {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpec_ = null;
          onChanged();
        } else {
          amContainerSpecBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000010);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder getAmContainerSpecBuilder() {
        bitField0_ |= 0x00000010;
        onChanged();
        return getAmContainerSpecFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder getAmContainerSpecOrBuilder() {
        if (amContainerSpecBuilder_ != null) {
          return amContainerSpecBuilder_.getMessageOrBuilder();
        } else {
          return amContainerSpec_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance() : amContainerSpec_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerLaunchContextProto am_container_spec = 5;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder> 
          getAmContainerSpecFieldBuilder() {
        if (amContainerSpecBuilder_ == null) {
          amContainerSpecBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder>(
                  getAmContainerSpec(),
                  getParentForChildren(),
                  isClean());
          amContainerSpec_ = null;
        }
        return amContainerSpecBuilder_;
      }

      private boolean cancelTokensWhenComplete_ = true;
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public boolean hasCancelTokensWhenComplete() {
        return ((bitField0_ & 0x00000020) == 0x00000020);
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public boolean getCancelTokensWhenComplete() {
        return cancelTokensWhenComplete_;
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public Builder setCancelTokensWhenComplete(boolean value) {
        bitField0_ |= 0x00000020;
        cancelTokensWhenComplete_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool cancel_tokens_when_complete = 6 [default = true];</code>
       */
      public Builder clearCancelTokensWhenComplete() {
        bitField0_ = (bitField0_ & ~0x00000020);
        cancelTokensWhenComplete_ = true;
        onChanged();
        return this;
      }

      private boolean unmanagedAm_ ;
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public boolean hasUnmanagedAm() {
        return ((bitField0_ & 0x00000040) == 0x00000040);
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public boolean getUnmanagedAm() {
        return unmanagedAm_;
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public Builder setUnmanagedAm(boolean value) {
        bitField0_ |= 0x00000040;
        unmanagedAm_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool unmanaged_am = 7 [default = false];</code>
       */
      public Builder clearUnmanagedAm() {
        bitField0_ = (bitField0_ & ~0x00000040);
        unmanagedAm_ = false;
        onChanged();
        return this;
      }

      private int maxAppAttempts_ ;
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public boolean hasMaxAppAttempts() {
        return ((bitField0_ & 0x00000080) == 0x00000080);
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public int getMaxAppAttempts() {
        return maxAppAttempts_;
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public Builder setMaxAppAttempts(int value) {
        bitField0_ |= 0x00000080;
        maxAppAttempts_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 maxAppAttempts = 8 [default = 0];</code>
       */
      public Builder clearMaxAppAttempts() {
        bitField0_ = (bitField0_ & ~0x00000080);
        maxAppAttempts_ = 0;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto resource_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> resourceBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public boolean hasResource() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getResource() {
        if (resourceBuilder_ == null) {
          return resource_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        } else {
          return resourceBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder setResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          resource_ = value;
          onChanged();
        } else {
          resourceBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder setResource(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (resourceBuilder_ == null) {
          resource_ = builderForValue.build();
          onChanged();
        } else {
          resourceBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder mergeResource(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (resourceBuilder_ == null) {
          if (((bitField0_ & 0x00000100) == 0x00000100) &&
              resource_ != null &&
              resource_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            resource_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(resource_).mergeFrom(value).buildPartial();
          } else {
            resource_ = value;
          }
          onChanged();
        } else {
          resourceBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000100;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public Builder clearResource() {
        if (resourceBuilder_ == null) {
          resource_ = null;
          onChanged();
        } else {
          resourceBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getResourceBuilder() {
        bitField0_ |= 0x00000100;
        onChanged();
        return getResourceFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getResourceOrBuilder() {
        if (resourceBuilder_ != null) {
          return resourceBuilder_.getMessageOrBuilder();
        } else {
          return resource_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : resource_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto resource = 9;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getResourceFieldBuilder() {
        if (resourceBuilder_ == null) {
          resourceBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getResource(),
                  getParentForChildren(),
                  isClean());
          resource_ = null;
        }
        return resourceBuilder_;
      }

      private java.lang.Object applicationType_ = "YARN";
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public boolean hasApplicationType() {
        return ((bitField0_ & 0x00000200) == 0x00000200);
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public java.lang.String getApplicationType() {
        java.lang.Object ref = applicationType_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            applicationType_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTypeBytes() {
        java.lang.Object ref = applicationType_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          applicationType_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder setApplicationType(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        applicationType_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder clearApplicationType() {
        bitField0_ = (bitField0_ & ~0x00000200);
        applicationType_ = getDefaultInstance().getApplicationType();
        onChanged();
        return this;
      }
      /**
       * <code>optional string applicationType = 10 [default = "YARN"];</code>
       */
      public Builder setApplicationTypeBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000200;
        applicationType_ = value;
        onChanged();
        return this;
      }

      private boolean keepContainersAcrossApplicationAttempts_ ;
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public boolean hasKeepContainersAcrossApplicationAttempts() {
        return ((bitField0_ & 0x00000400) == 0x00000400);
      }
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public boolean getKeepContainersAcrossApplicationAttempts() {
        return keepContainersAcrossApplicationAttempts_;
      }
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public Builder setKeepContainersAcrossApplicationAttempts(boolean value) {
        bitField0_ |= 0x00000400;
        keepContainersAcrossApplicationAttempts_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bool keep_containers_across_application_attempts = 11 [default = false];</code>
       */
      public Builder clearKeepContainersAcrossApplicationAttempts() {
        bitField0_ = (bitField0_ & ~0x00000400);
        keepContainersAcrossApplicationAttempts_ = false;
        onChanged();
        return this;
      }

      private com.google.protobuf.LazyStringList applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureApplicationTagsIsMutable() {
        if (!((bitField0_ & 0x00000800) == 0x00000800)) {
          applicationTags_ = new com.google.protobuf.LazyStringArrayList(applicationTags_);
          bitField0_ |= 0x00000800;
         }
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getApplicationTagsList() {
        return applicationTags_.getUnmodifiableView();
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public int getApplicationTagsCount() {
        return applicationTags_.size();
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public java.lang.String getApplicationTags(int index) {
        return applicationTags_.get(index);
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public com.google.protobuf.ByteString
          getApplicationTagsBytes(int index) {
        return applicationTags_.getByteString(index);
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder setApplicationTags(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder addApplicationTags(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder addAllApplicationTags(
          java.lang.Iterable<java.lang.String> values) {
        ensureApplicationTagsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, applicationTags_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder clearApplicationTags() {
        applicationTags_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000800);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string applicationTags = 12;</code>
       */
      public Builder addApplicationTagsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureApplicationTagsIsMutable();
        applicationTags_.add(value);
        onChanged();
        return this;
      }

      private long attemptFailuresValidityInterval_ = -1L;
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public boolean hasAttemptFailuresValidityInterval() {
        return ((bitField0_ & 0x00001000) == 0x00001000);
      }
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public long getAttemptFailuresValidityInterval() {
        return attemptFailuresValidityInterval_;
      }
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public Builder setAttemptFailuresValidityInterval(long value) {
        bitField0_ |= 0x00001000;
        attemptFailuresValidityInterval_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 attempt_failures_validity_interval = 13 [default = -1];</code>
       */
      public Builder clearAttemptFailuresValidityInterval() {
        bitField0_ = (bitField0_ & ~0x00001000);
        attemptFailuresValidityInterval_ = -1L;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto logAggregationContext_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder> logAggregationContextBuilder_;
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public boolean hasLogAggregationContext() {
        return ((bitField0_ & 0x00002000) == 0x00002000);
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getLogAggregationContext() {
        if (logAggregationContextBuilder_ == null) {
          return logAggregationContext_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance() : logAggregationContext_;
        } else {
          return logAggregationContextBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder setLogAggregationContext(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto value) {
        if (logAggregationContextBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          logAggregationContext_ = value;
          onChanged();
        } else {
          logAggregationContextBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder setLogAggregationContext(
          org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder builderForValue) {
        if (logAggregationContextBuilder_ == null) {
          logAggregationContext_ = builderForValue.build();
          onChanged();
        } else {
          logAggregationContextBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder mergeLogAggregationContext(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto value) {
        if (logAggregationContextBuilder_ == null) {
          if (((bitField0_ & 0x00002000) == 0x00002000) &&
              logAggregationContext_ != null &&
              logAggregationContext_ != org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance()) {
            logAggregationContext_ =
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.newBuilder(logAggregationContext_).mergeFrom(value).buildPartial();
          } else {
            logAggregationContext_ = value;
          }
          onChanged();
        } else {
          logAggregationContextBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00002000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public Builder clearLogAggregationContext() {
        if (logAggregationContextBuilder_ == null) {
          logAggregationContext_ = null;
          onChanged();
        } else {
          logAggregationContextBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00002000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder getLogAggregationContextBuilder() {
        bitField0_ |= 0x00002000;
        onChanged();
        return getLogAggregationContextFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder getLogAggregationContextOrBuilder() {
        if (logAggregationContextBuilder_ != null) {
          return logAggregationContextBuilder_.getMessageOrBuilder();
        } else {
          return logAggregationContext_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance() : logAggregationContext_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.LogAggregationContextProto log_aggregation_context = 14;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder> 
          getLogAggregationContextFieldBuilder() {
        if (logAggregationContextBuilder_ == null) {
          logAggregationContextBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder>(
                  getLogAggregationContext(),
                  getParentForChildren(),
                  isClean());
          logAggregationContext_ = null;
        }
        return logAggregationContextBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto reservationId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> reservationIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public boolean hasReservationId() {
        return ((bitField0_ & 0x00004000) == 0x00004000);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getReservationId() {
        if (reservationIdBuilder_ == null) {
          return reservationId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        } else {
          return reservationIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder setReservationId(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationId_ = value;
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder setReservationId(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder builderForValue) {
        if (reservationIdBuilder_ == null) {
          reservationId_ = builderForValue.build();
          onChanged();
        } else {
          reservationIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder mergeReservationId(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto value) {
        if (reservationIdBuilder_ == null) {
          if (((bitField0_ & 0x00004000) == 0x00004000) &&
              reservationId_ != null &&
              reservationId_ != org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) {
            reservationId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder(reservationId_).mergeFrom(value).buildPartial();
          } else {
            reservationId_ = value;
          }
          onChanged();
        } else {
          reservationIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00004000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public Builder clearReservationId() {
        if (reservationIdBuilder_ == null) {
          reservationId_ = null;
          onChanged();
        } else {
          reservationIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00004000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder getReservationIdBuilder() {
        bitField0_ |= 0x00004000;
        onChanged();
        return getReservationIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder getReservationIdOrBuilder() {
        if (reservationIdBuilder_ != null) {
          return reservationIdBuilder_.getMessageOrBuilder();
        } else {
          return reservationId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance() : reservationId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationIdProto reservation_id = 15;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder> 
          getReservationIdFieldBuilder() {
        if (reservationIdBuilder_ == null) {
          reservationIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder>(
                  getReservationId(),
                  getParentForChildren(),
                  isClean());
          reservationId_ = null;
        }
        return reservationIdBuilder_;
      }

      private java.lang.Object nodeLabelExpression_ = "";
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public boolean hasNodeLabelExpression() {
        return ((bitField0_ & 0x00008000) == 0x00008000);
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public java.lang.String getNodeLabelExpression() {
        java.lang.Object ref = nodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            nodeLabelExpression_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public com.google.protobuf.ByteString
          getNodeLabelExpressionBytes() {
        java.lang.Object ref = nodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          nodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public Builder setNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00008000;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public Builder clearNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00008000);
        nodeLabelExpression_ = getDefaultInstance().getNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string node_label_expression = 16;</code>
       */
      public Builder setNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00008000;
        nodeLabelExpression_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto amContainerResourceRequest_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> amContainerResourceRequestBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public boolean hasAmContainerResourceRequest() {
        return ((bitField0_ & 0x00010000) == 0x00010000);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto getAmContainerResourceRequest() {
        if (amContainerResourceRequestBuilder_ == null) {
          return amContainerResourceRequest_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : amContainerResourceRequest_;
        } else {
          return amContainerResourceRequestBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder setAmContainerResourceRequest(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (amContainerResourceRequestBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          amContainerResourceRequest_ = value;
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00010000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder setAmContainerResourceRequest(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder builderForValue) {
        if (amContainerResourceRequestBuilder_ == null) {
          amContainerResourceRequest_ = builderForValue.build();
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00010000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder mergeAmContainerResourceRequest(org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto value) {
        if (amContainerResourceRequestBuilder_ == null) {
          if (((bitField0_ & 0x00010000) == 0x00010000) &&
              amContainerResourceRequest_ != null &&
              amContainerResourceRequest_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance()) {
            amContainerResourceRequest_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.newBuilder(amContainerResourceRequest_).mergeFrom(value).buildPartial();
          } else {
            amContainerResourceRequest_ = value;
          }
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00010000;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public Builder clearAmContainerResourceRequest() {
        if (amContainerResourceRequestBuilder_ == null) {
          amContainerResourceRequest_ = null;
          onChanged();
        } else {
          amContainerResourceRequestBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00010000);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder getAmContainerResourceRequestBuilder() {
        bitField0_ |= 0x00010000;
        onChanged();
        return getAmContainerResourceRequestFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder getAmContainerResourceRequestOrBuilder() {
        if (amContainerResourceRequestBuilder_ != null) {
          return amContainerResourceRequestBuilder_.getMessageOrBuilder();
        } else {
          return amContainerResourceRequest_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.getDefaultInstance() : amContainerResourceRequest_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceRequestProto am_container_resource_request = 17;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder> 
          getAmContainerResourceRequestFieldBuilder() {
        if (amContainerResourceRequestBuilder_ == null) {
          amContainerResourceRequestBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceRequestProtoOrBuilder>(
                  getAmContainerResourceRequest(),
                  getParentForChildren(),
                  isClean());
          amContainerResourceRequest_ = null;
        }
        return amContainerResourceRequestBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationSubmissionContextProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationSubmissionContextProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApplicationSubmissionContextProto>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationSubmissionContextProto>() {
      public ApplicationSubmissionContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ApplicationSubmissionContextProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationSubmissionContextProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationSubmissionContextProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationSubmissionContextProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface LogAggregationContextProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.LogAggregationContextProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    boolean hasIncludePattern();
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    java.lang.String getIncludePattern();
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    com.google.protobuf.ByteString
        getIncludePatternBytes();

    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    boolean hasExcludePattern();
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    java.lang.String getExcludePattern();
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    com.google.protobuf.ByteString
        getExcludePatternBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.LogAggregationContextProto}
   */
  public  static final class LogAggregationContextProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.LogAggregationContextProto)
      LogAggregationContextProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use LogAggregationContextProto.newBuilder() to construct.
    private LogAggregationContextProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private LogAggregationContextProto() {
      includePattern_ = ".*";
      excludePattern_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private LogAggregationContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              includePattern_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              excludePattern_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder.class);
    }

    private int bitField0_;
    public static final int INCLUDE_PATTERN_FIELD_NUMBER = 1;
    private volatile java.lang.Object includePattern_;
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    public boolean hasIncludePattern() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    public java.lang.String getIncludePattern() {
      java.lang.Object ref = includePattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          includePattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string include_pattern = 1 [default = ".*"];</code>
     */
    public com.google.protobuf.ByteString
        getIncludePatternBytes() {
      java.lang.Object ref = includePattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        includePattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int EXCLUDE_PATTERN_FIELD_NUMBER = 2;
    private volatile java.lang.Object excludePattern_;
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    public boolean hasExcludePattern() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    public java.lang.String getExcludePattern() {
      java.lang.Object ref = excludePattern_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          excludePattern_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string exclude_pattern = 2 [default = ""];</code>
     */
    public com.google.protobuf.ByteString
        getExcludePatternBytes() {
      java.lang.Object ref = excludePattern_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        excludePattern_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, includePattern_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, excludePattern_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, includePattern_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, excludePattern_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto) obj;

      boolean result = true;
      result = result && (hasIncludePattern() == other.hasIncludePattern());
      if (hasIncludePattern()) {
        result = result && getIncludePattern()
            .equals(other.getIncludePattern());
      }
      result = result && (hasExcludePattern() == other.hasExcludePattern());
      if (hasExcludePattern()) {
        result = result && getExcludePattern()
            .equals(other.getExcludePattern());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasIncludePattern()) {
        hash = (37 * hash) + INCLUDE_PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getIncludePattern().hashCode();
      }
      if (hasExcludePattern()) {
        hash = (37 * hash) + EXCLUDE_PATTERN_FIELD_NUMBER;
        hash = (53 * hash) + getExcludePattern().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.LogAggregationContextProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.LogAggregationContextProto)
        org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        includePattern_ = ".*";
        bitField0_ = (bitField0_ & ~0x00000001);
        excludePattern_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.includePattern_ = includePattern_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.excludePattern_ = excludePattern_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto.getDefaultInstance()) return this;
        if (other.hasIncludePattern()) {
          bitField0_ |= 0x00000001;
          includePattern_ = other.includePattern_;
          onChanged();
        }
        if (other.hasExcludePattern()) {
          bitField0_ |= 0x00000002;
          excludePattern_ = other.excludePattern_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object includePattern_ = ".*";
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public boolean hasIncludePattern() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public java.lang.String getIncludePattern() {
        java.lang.Object ref = includePattern_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            includePattern_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public com.google.protobuf.ByteString
          getIncludePatternBytes() {
        java.lang.Object ref = includePattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          includePattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public Builder setIncludePattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        includePattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public Builder clearIncludePattern() {
        bitField0_ = (bitField0_ & ~0x00000001);
        includePattern_ = getDefaultInstance().getIncludePattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string include_pattern = 1 [default = ".*"];</code>
       */
      public Builder setIncludePatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        includePattern_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object excludePattern_ = "";
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public boolean hasExcludePattern() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public java.lang.String getExcludePattern() {
        java.lang.Object ref = excludePattern_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            excludePattern_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public com.google.protobuf.ByteString
          getExcludePatternBytes() {
        java.lang.Object ref = excludePattern_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          excludePattern_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public Builder setExcludePattern(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        excludePattern_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public Builder clearExcludePattern() {
        bitField0_ = (bitField0_ & ~0x00000002);
        excludePattern_ = getDefaultInstance().getExcludePattern();
        onChanged();
        return this;
      }
      /**
       * <code>optional string exclude_pattern = 2 [default = ""];</code>
       */
      public Builder setExcludePatternBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        excludePattern_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.LogAggregationContextProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.LogAggregationContextProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<LogAggregationContextProto>
        PARSER = new com.google.protobuf.AbstractParser<LogAggregationContextProto>() {
      public LogAggregationContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new LogAggregationContextProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<LogAggregationContextProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<LogAggregationContextProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.LogAggregationContextProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ApplicationACLMapProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ApplicationACLMapProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    boolean hasAccessType();
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType();

    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    boolean hasAcl();
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    java.lang.String getAcl();
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    com.google.protobuf.ByteString
        getAclBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ApplicationACLMapProto}
   */
  public  static final class ApplicationACLMapProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ApplicationACLMapProto)
      ApplicationACLMapProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ApplicationACLMapProto.newBuilder() to construct.
    private ApplicationACLMapProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ApplicationACLMapProto() {
      accessType_ = 1;
      acl_ = " ";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ApplicationACLMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto value = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(1, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                accessType_ = rawValue;
              }
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              acl_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder.class);
    }

    private int bitField0_;
    public static final int ACCESSTYPE_FIELD_NUMBER = 1;
    private int accessType_;
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    public boolean hasAccessType() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType() {
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto result = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.valueOf(accessType_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP : result;
    }

    public static final int ACL_FIELD_NUMBER = 2;
    private volatile java.lang.Object acl_;
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public boolean hasAcl() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public java.lang.String getAcl() {
      java.lang.Object ref = acl_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          acl_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string acl = 2 [default = " "];</code>
     */
    public com.google.protobuf.ByteString
        getAclBytes() {
      java.lang.Object ref = acl_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        acl_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(1, accessType_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, acl_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(1, accessType_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, acl_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) obj;

      boolean result = true;
      result = result && (hasAccessType() == other.hasAccessType());
      if (hasAccessType()) {
        result = result && accessType_ == other.accessType_;
      }
      result = result && (hasAcl() == other.hasAcl());
      if (hasAcl()) {
        result = result && getAcl()
            .equals(other.getAcl());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasAccessType()) {
        hash = (37 * hash) + ACCESSTYPE_FIELD_NUMBER;
        hash = (53 * hash) + accessType_;
      }
      if (hasAcl()) {
        hash = (37 * hash) + ACL_FIELD_NUMBER;
        hash = (53 * hash) + getAcl().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ApplicationACLMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ApplicationACLMapProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        accessType_ = 1;
        bitField0_ = (bitField0_ & ~0x00000001);
        acl_ = " ";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.accessType_ = accessType_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.acl_ = acl_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance()) return this;
        if (other.hasAccessType()) {
          setAccessType(other.getAccessType());
        }
        if (other.hasAcl()) {
          bitField0_ |= 0x00000002;
          acl_ = other.acl_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int accessType_ = 1;
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public boolean hasAccessType() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto getAccessType() {
        org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto result = org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.valueOf(accessType_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto.APPACCESS_VIEW_APP : result;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public Builder setAccessType(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationAccessTypeProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000001;
        accessType_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ApplicationAccessTypeProto accessType = 1;</code>
       */
      public Builder clearAccessType() {
        bitField0_ = (bitField0_ & ~0x00000001);
        accessType_ = 1;
        onChanged();
        return this;
      }

      private java.lang.Object acl_ = " ";
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public boolean hasAcl() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public java.lang.String getAcl() {
        java.lang.Object ref = acl_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            acl_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public com.google.protobuf.ByteString
          getAclBytes() {
        java.lang.Object ref = acl_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          acl_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder setAcl(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        acl_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder clearAcl() {
        bitField0_ = (bitField0_ & ~0x00000002);
        acl_ = getDefaultInstance().getAcl();
        onChanged();
        return this;
      }
      /**
       * <code>optional string acl = 2 [default = " "];</code>
       */
      public Builder setAclBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        acl_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ApplicationACLMapProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ApplicationACLMapProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ApplicationACLMapProto>
        PARSER = new com.google.protobuf.AbstractParser<ApplicationACLMapProto>() {
      public ApplicationACLMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ApplicationACLMapProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ApplicationACLMapProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ApplicationACLMapProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface YarnClusterMetricsProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.YarnClusterMetricsProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    boolean hasNumNodeManagers();
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    int getNumNodeManagers();
  }
  /**
   * Protobuf type {@code hadoop.yarn.YarnClusterMetricsProto}
   */
  public  static final class YarnClusterMetricsProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.YarnClusterMetricsProto)
      YarnClusterMetricsProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use YarnClusterMetricsProto.newBuilder() to construct.
    private YarnClusterMetricsProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private YarnClusterMetricsProto() {
      numNodeManagers_ = 0;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private YarnClusterMetricsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              numNodeManagers_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder.class);
    }

    private int bitField0_;
    public static final int NUM_NODE_MANAGERS_FIELD_NUMBER = 1;
    private int numNodeManagers_;
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    public boolean hasNumNodeManagers() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int32 num_node_managers = 1;</code>
     */
    public int getNumNodeManagers() {
      return numNodeManagers_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt32(1, numNodeManagers_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(1, numNodeManagers_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) obj;

      boolean result = true;
      result = result && (hasNumNodeManagers() == other.hasNumNodeManagers());
      if (hasNumNodeManagers()) {
        result = result && (getNumNodeManagers()
            == other.getNumNodeManagers());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasNumNodeManagers()) {
        hash = (37 * hash) + NUM_NODE_MANAGERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumNodeManagers();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.YarnClusterMetricsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.YarnClusterMetricsProto)
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        numNodeManagers_ = 0;
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.numNodeManagers_ = numNodeManagers_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto.getDefaultInstance()) return this;
        if (other.hasNumNodeManagers()) {
          setNumNodeManagers(other.getNumNodeManagers());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private int numNodeManagers_ ;
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public boolean hasNumNodeManagers() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public int getNumNodeManagers() {
        return numNodeManagers_;
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public Builder setNumNodeManagers(int value) {
        bitField0_ |= 0x00000001;
        numNodeManagers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_node_managers = 1;</code>
       */
      public Builder clearNumNodeManagers() {
        bitField0_ = (bitField0_ & ~0x00000001);
        numNodeManagers_ = 0;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.YarnClusterMetricsProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.YarnClusterMetricsProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<YarnClusterMetricsProto>
        PARSER = new com.google.protobuf.AbstractParser<YarnClusterMetricsProto>() {
      public YarnClusterMetricsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new YarnClusterMetricsProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<YarnClusterMetricsProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<YarnClusterMetricsProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.YarnClusterMetricsProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface QueueInfoProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.QueueInfoProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string queueName = 1;</code>
     */
    boolean hasQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    java.lang.String getQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueNameBytes();

    /**
     * <code>optional float capacity = 2;</code>
     */
    boolean hasCapacity();
    /**
     * <code>optional float capacity = 2;</code>
     */
    float getCapacity();

    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    boolean hasMaximumCapacity();
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    float getMaximumCapacity();

    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    boolean hasCurrentCapacity();
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    float getCurrentCapacity();

    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    boolean hasState();
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState();

    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> 
        getChildQueuesList();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index);
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    int getChildQueuesCount();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
        getChildQueuesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> 
        getApplicationsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    int getApplicationsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index);

    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    java.util.List<java.lang.String>
        getAccessibleNodeLabelsList();
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    int getAccessibleNodeLabelsCount();
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    java.lang.String getAccessibleNodeLabels(int index);
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    com.google.protobuf.ByteString
        getAccessibleNodeLabelsBytes(int index);

    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    boolean hasDefaultNodeLabelExpression();
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    java.lang.String getDefaultNodeLabelExpression();
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    com.google.protobuf.ByteString
        getDefaultNodeLabelExpressionBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueInfoProto}
   */
  public  static final class QueueInfoProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.QueueInfoProto)
      QueueInfoProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use QueueInfoProto.newBuilder() to construct.
    private QueueInfoProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private QueueInfoProto() {
      queueName_ = "";
      capacity_ = 0F;
      maximumCapacity_ = 0F;
      currentCapacity_ = 0F;
      state_ = 1;
      childQueues_ = java.util.Collections.emptyList();
      applications_ = java.util.Collections.emptyList();
      accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      defaultNodeLabelExpression_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private QueueInfoProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              queueName_ = bs;
              break;
            }
            case 21: {
              bitField0_ |= 0x00000002;
              capacity_ = input.readFloat();
              break;
            }
            case 29: {
              bitField0_ |= 0x00000004;
              maximumCapacity_ = input.readFloat();
              break;
            }
            case 37: {
              bitField0_ |= 0x00000008;
              currentCapacity_ = input.readFloat();
              break;
            }
            case 40: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(5, rawValue);
              } else {
                bitField0_ |= 0x00000010;
                state_ = rawValue;
              }
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                childQueues_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              childQueues_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.PARSER, extensionRegistry));
              break;
            }
            case 58: {
              if (!((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
                applications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>();
                mutable_bitField0_ |= 0x00000040;
              }
              applications_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.PARSER, extensionRegistry));
              break;
            }
            case 66: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
                accessibleNodeLabels_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000080;
              }
              accessibleNodeLabels_.add(bs);
              break;
            }
            case 74: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000020;
              defaultNodeLabelExpression_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          childQueues_ = java.util.Collections.unmodifiableList(childQueues_);
        }
        if (((mutable_bitField0_ & 0x00000040) == 0x00000040)) {
          applications_ = java.util.Collections.unmodifiableList(applications_);
        }
        if (((mutable_bitField0_ & 0x00000080) == 0x00000080)) {
          accessibleNodeLabels_ = accessibleNodeLabels_.getUnmodifiableView();
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder.class);
    }

    private int bitField0_;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object queueName_;
    /**
     * <code>optional string queueName = 1;</code>
     */
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public java.lang.String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queueName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int CAPACITY_FIELD_NUMBER = 2;
    private float capacity_;
    /**
     * <code>optional float capacity = 2;</code>
     */
    public boolean hasCapacity() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional float capacity = 2;</code>
     */
    public float getCapacity() {
      return capacity_;
    }

    public static final int MAXIMUMCAPACITY_FIELD_NUMBER = 3;
    private float maximumCapacity_;
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    public boolean hasMaximumCapacity() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional float maximumCapacity = 3;</code>
     */
    public float getMaximumCapacity() {
      return maximumCapacity_;
    }

    public static final int CURRENTCAPACITY_FIELD_NUMBER = 4;
    private float currentCapacity_;
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    public boolean hasCurrentCapacity() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional float currentCapacity = 4;</code>
     */
    public float getCurrentCapacity() {
      return currentCapacity_;
    }

    public static final int STATE_FIELD_NUMBER = 5;
    private int state_;
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    public boolean hasState() {
      return ((bitField0_ & 0x00000010) == 0x00000010);
    }
    /**
     * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState() {
      org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.valueOf(state_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED : result;
    }

    public static final int CHILDQUEUES_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> childQueues_;
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> getChildQueuesList() {
      return childQueues_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
        getChildQueuesOrBuilderList() {
      return childQueues_;
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public int getChildQueuesCount() {
      return childQueues_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index) {
      return childQueues_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
        int index) {
      return childQueues_.get(index);
    }

    public static final int APPLICATIONS_FIELD_NUMBER = 7;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
        getApplicationsOrBuilderList() {
      return applications_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public int getApplicationsCount() {
      return applications_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
      return applications_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
        int index) {
      return applications_.get(index);
    }

    public static final int ACCESSIBLENODELABELS_FIELD_NUMBER = 8;
    private com.google.protobuf.LazyStringList accessibleNodeLabels_;
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getAccessibleNodeLabelsList() {
      return accessibleNodeLabels_;
    }
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public int getAccessibleNodeLabelsCount() {
      return accessibleNodeLabels_.size();
    }
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public java.lang.String getAccessibleNodeLabels(int index) {
      return accessibleNodeLabels_.get(index);
    }
    /**
     * <code>repeated string accessibleNodeLabels = 8;</code>
     */
    public com.google.protobuf.ByteString
        getAccessibleNodeLabelsBytes(int index) {
      return accessibleNodeLabels_.getByteString(index);
    }

    public static final int DEFAULTNODELABELEXPRESSION_FIELD_NUMBER = 9;
    private volatile java.lang.Object defaultNodeLabelExpression_;
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    public boolean hasDefaultNodeLabelExpression() {
      return ((bitField0_ & 0x00000020) == 0x00000020);
    }
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    public java.lang.String getDefaultNodeLabelExpression() {
      java.lang.Object ref = defaultNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          defaultNodeLabelExpression_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string defaultNodeLabelExpression = 9;</code>
     */
    public com.google.protobuf.ByteString
        getDefaultNodeLabelExpressionBytes() {
      java.lang.Object ref = defaultNodeLabelExpression_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        defaultNodeLabelExpression_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      for (int i = 0; i < getChildQueuesCount(); i++) {
        if (!getChildQueues(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      for (int i = 0; i < getApplicationsCount(); i++) {
        if (!getApplications(i).isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, queueName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeFloat(2, capacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeFloat(3, maximumCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeFloat(4, currentCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        output.writeEnum(5, state_);
      }
      for (int i = 0; i < childQueues_.size(); i++) {
        output.writeMessage(6, childQueues_.get(i));
      }
      for (int i = 0; i < applications_.size(); i++) {
        output.writeMessage(7, applications_.get(i));
      }
      for (int i = 0; i < accessibleNodeLabels_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 8, accessibleNodeLabels_.getRaw(i));
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 9, defaultNodeLabelExpression_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, queueName_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(2, capacity_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(3, maximumCapacity_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeFloatSize(4, currentCapacity_);
      }
      if (((bitField0_ & 0x00000010) == 0x00000010)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(5, state_);
      }
      for (int i = 0; i < childQueues_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, childQueues_.get(i));
      }
      for (int i = 0; i < applications_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(7, applications_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < accessibleNodeLabels_.size(); i++) {
          dataSize += computeStringSizeNoTag(accessibleNodeLabels_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getAccessibleNodeLabelsList().size();
      }
      if (((bitField0_ & 0x00000020) == 0x00000020)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(9, defaultNodeLabelExpression_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) obj;

      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && (hasCapacity() == other.hasCapacity());
      if (hasCapacity()) {
        result = result && (
            java.lang.Float.floatToIntBits(getCapacity())
            == java.lang.Float.floatToIntBits(
                other.getCapacity()));
      }
      result = result && (hasMaximumCapacity() == other.hasMaximumCapacity());
      if (hasMaximumCapacity()) {
        result = result && (
            java.lang.Float.floatToIntBits(getMaximumCapacity())
            == java.lang.Float.floatToIntBits(
                other.getMaximumCapacity()));
      }
      result = result && (hasCurrentCapacity() == other.hasCurrentCapacity());
      if (hasCurrentCapacity()) {
        result = result && (
            java.lang.Float.floatToIntBits(getCurrentCapacity())
            == java.lang.Float.floatToIntBits(
                other.getCurrentCapacity()));
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result && state_ == other.state_;
      }
      result = result && getChildQueuesList()
          .equals(other.getChildQueuesList());
      result = result && getApplicationsList()
          .equals(other.getApplicationsList());
      result = result && getAccessibleNodeLabelsList()
          .equals(other.getAccessibleNodeLabelsList());
      result = result && (hasDefaultNodeLabelExpression() == other.hasDefaultNodeLabelExpression());
      if (hasDefaultNodeLabelExpression()) {
        result = result && getDefaultNodeLabelExpression()
            .equals(other.getDefaultNodeLabelExpression());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (hasCapacity()) {
        hash = (37 * hash) + CAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + java.lang.Float.floatToIntBits(
            getCapacity());
      }
      if (hasMaximumCapacity()) {
        hash = (37 * hash) + MAXIMUMCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + java.lang.Float.floatToIntBits(
            getMaximumCapacity());
      }
      if (hasCurrentCapacity()) {
        hash = (37 * hash) + CURRENTCAPACITY_FIELD_NUMBER;
        hash = (53 * hash) + java.lang.Float.floatToIntBits(
            getCurrentCapacity());
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (getChildQueuesCount() > 0) {
        hash = (37 * hash) + CHILDQUEUES_FIELD_NUMBER;
        hash = (53 * hash) + getChildQueuesList().hashCode();
      }
      if (getApplicationsCount() > 0) {
        hash = (37 * hash) + APPLICATIONS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationsList().hashCode();
      }
      if (getAccessibleNodeLabelsCount() > 0) {
        hash = (37 * hash) + ACCESSIBLENODELABELS_FIELD_NUMBER;
        hash = (53 * hash) + getAccessibleNodeLabelsList().hashCode();
      }
      if (hasDefaultNodeLabelExpression()) {
        hash = (37 * hash) + DEFAULTNODELABELEXPRESSION_FIELD_NUMBER;
        hash = (53 * hash) + getDefaultNodeLabelExpression().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueInfoProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.QueueInfoProto)
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getChildQueuesFieldBuilder();
          getApplicationsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        capacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000002);
        maximumCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000004);
        currentCapacity_ = 0F;
        bitField0_ = (bitField0_ & ~0x00000008);
        state_ = 1;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (childQueuesBuilder_ == null) {
          childQueues_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          childQueuesBuilder_.clear();
        }
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
        } else {
          applicationsBuilder_.clear();
        }
        accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        defaultNodeLabelExpression_ = "";
        bitField0_ = (bitField0_ & ~0x00000100);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueInfoProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.capacity_ = capacity_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.maximumCapacity_ = maximumCapacity_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.currentCapacity_ = currentCapacity_;
        if (((from_bitField0_ & 0x00000010) == 0x00000010)) {
          to_bitField0_ |= 0x00000010;
        }
        result.state_ = state_;
        if (childQueuesBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            childQueues_ = java.util.Collections.unmodifiableList(childQueues_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.childQueues_ = childQueues_;
        } else {
          result.childQueues_ = childQueuesBuilder_.build();
        }
        if (applicationsBuilder_ == null) {
          if (((bitField0_ & 0x00000040) == 0x00000040)) {
            applications_ = java.util.Collections.unmodifiableList(applications_);
            bitField0_ = (bitField0_ & ~0x00000040);
          }
          result.applications_ = applications_;
        } else {
          result.applications_ = applicationsBuilder_.build();
        }
        if (((bitField0_ & 0x00000080) == 0x00000080)) {
          accessibleNodeLabels_ = accessibleNodeLabels_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000080);
        }
        result.accessibleNodeLabels_ = accessibleNodeLabels_;
        if (((from_bitField0_ & 0x00000100) == 0x00000100)) {
          to_bitField0_ |= 0x00000020;
        }
        result.defaultNodeLabelExpression_ = defaultNodeLabelExpression_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          bitField0_ |= 0x00000001;
          queueName_ = other.queueName_;
          onChanged();
        }
        if (other.hasCapacity()) {
          setCapacity(other.getCapacity());
        }
        if (other.hasMaximumCapacity()) {
          setMaximumCapacity(other.getMaximumCapacity());
        }
        if (other.hasCurrentCapacity()) {
          setCurrentCapacity(other.getCurrentCapacity());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (childQueuesBuilder_ == null) {
          if (!other.childQueues_.isEmpty()) {
            if (childQueues_.isEmpty()) {
              childQueues_ = other.childQueues_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureChildQueuesIsMutable();
              childQueues_.addAll(other.childQueues_);
            }
            onChanged();
          }
        } else {
          if (!other.childQueues_.isEmpty()) {
            if (childQueuesBuilder_.isEmpty()) {
              childQueuesBuilder_.dispose();
              childQueuesBuilder_ = null;
              childQueues_ = other.childQueues_;
              bitField0_ = (bitField0_ & ~0x00000020);
              childQueuesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getChildQueuesFieldBuilder() : null;
            } else {
              childQueuesBuilder_.addAllMessages(other.childQueues_);
            }
          }
        }
        if (applicationsBuilder_ == null) {
          if (!other.applications_.isEmpty()) {
            if (applications_.isEmpty()) {
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000040);
            } else {
              ensureApplicationsIsMutable();
              applications_.addAll(other.applications_);
            }
            onChanged();
          }
        } else {
          if (!other.applications_.isEmpty()) {
            if (applicationsBuilder_.isEmpty()) {
              applicationsBuilder_.dispose();
              applicationsBuilder_ = null;
              applications_ = other.applications_;
              bitField0_ = (bitField0_ & ~0x00000040);
              applicationsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getApplicationsFieldBuilder() : null;
            } else {
              applicationsBuilder_.addAllMessages(other.applications_);
            }
          }
        }
        if (!other.accessibleNodeLabels_.isEmpty()) {
          if (accessibleNodeLabels_.isEmpty()) {
            accessibleNodeLabels_ = other.accessibleNodeLabels_;
            bitField0_ = (bitField0_ & ~0x00000080);
          } else {
            ensureAccessibleNodeLabelsIsMutable();
            accessibleNodeLabels_.addAll(other.accessibleNodeLabels_);
          }
          onChanged();
        }
        if (other.hasDefaultNodeLabelExpression()) {
          bitField0_ |= 0x00000100;
          defaultNodeLabelExpression_ = other.defaultNodeLabelExpression_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        for (int i = 0; i < getChildQueuesCount(); i++) {
          if (!getChildQueues(i).isInitialized()) {
            return false;
          }
        }
        for (int i = 0; i < getApplicationsCount(); i++) {
          if (!getApplications(i).isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object queueName_ = "";
      /**
       * <code>optional string queueName = 1;</code>
       */
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public java.lang.String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queueName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueNameBytes() {
        java.lang.Object ref = queueName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queueName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }

      private float capacity_ ;
      /**
       * <code>optional float capacity = 2;</code>
       */
      public boolean hasCapacity() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public float getCapacity() {
        return capacity_;
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public Builder setCapacity(float value) {
        bitField0_ |= 0x00000002;
        capacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float capacity = 2;</code>
       */
      public Builder clearCapacity() {
        bitField0_ = (bitField0_ & ~0x00000002);
        capacity_ = 0F;
        onChanged();
        return this;
      }

      private float maximumCapacity_ ;
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public boolean hasMaximumCapacity() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public float getMaximumCapacity() {
        return maximumCapacity_;
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public Builder setMaximumCapacity(float value) {
        bitField0_ |= 0x00000004;
        maximumCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float maximumCapacity = 3;</code>
       */
      public Builder clearMaximumCapacity() {
        bitField0_ = (bitField0_ & ~0x00000004);
        maximumCapacity_ = 0F;
        onChanged();
        return this;
      }

      private float currentCapacity_ ;
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public boolean hasCurrentCapacity() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public float getCurrentCapacity() {
        return currentCapacity_;
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public Builder setCurrentCapacity(float value) {
        bitField0_ |= 0x00000008;
        currentCapacity_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional float currentCapacity = 4;</code>
       */
      public Builder clearCurrentCapacity() {
        bitField0_ = (bitField0_ & ~0x00000008);
        currentCapacity_ = 0F;
        onChanged();
        return this;
      }

      private int state_ = 1;
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public boolean hasState() {
        return ((bitField0_ & 0x00000010) == 0x00000010);
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto getState() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.valueOf(state_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto.Q_STOPPED : result;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public Builder setState(org.apache.hadoop.yarn.proto.YarnProtos.QueueStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000010;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.QueueStateProto state = 5;</code>
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000010);
        state_ = 1;
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> childQueues_ =
        java.util.Collections.emptyList();
      private void ensureChildQueuesIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          childQueues_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto>(childQueues_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> childQueuesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> getChildQueuesList() {
        if (childQueuesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(childQueues_);
        } else {
          return childQueuesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public int getChildQueuesCount() {
        if (childQueuesBuilder_ == null) {
          return childQueues_.size();
        } else {
          return childQueuesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getChildQueues(int index) {
        if (childQueuesBuilder_ == null) {
          return childQueues_.get(index);
        } else {
          return childQueuesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder setChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.set(index, value);
          onChanged();
        } else {
          childQueuesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder setChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.set(index, builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.add(value);
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto value) {
        if (childQueuesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureChildQueuesIsMutable();
          childQueues_.add(index, value);
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.add(builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addChildQueues(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder builderForValue) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.add(index, builderForValue.build());
          onChanged();
        } else {
          childQueuesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder addAllChildQueues(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto> values) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, childQueues_);
          onChanged();
        } else {
          childQueuesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder clearChildQueues() {
        if (childQueuesBuilder_ == null) {
          childQueues_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          childQueuesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public Builder removeChildQueues(int index) {
        if (childQueuesBuilder_ == null) {
          ensureChildQueuesIsMutable();
          childQueues_.remove(index);
          onChanged();
        } else {
          childQueuesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder getChildQueuesBuilder(
          int index) {
        return getChildQueuesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder getChildQueuesOrBuilder(
          int index) {
        if (childQueuesBuilder_ == null) {
          return childQueues_.get(index);  } else {
          return childQueuesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
           getChildQueuesOrBuilderList() {
        if (childQueuesBuilder_ != null) {
          return childQueuesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(childQueues_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder addChildQueuesBuilder() {
        return getChildQueuesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder addChildQueuesBuilder(
          int index) {
        return getChildQueuesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.QueueInfoProto childQueues = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder> 
           getChildQueuesBuilderList() {
        return getChildQueuesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder> 
          getChildQueuesFieldBuilder() {
        if (childQueuesBuilder_ == null) {
          childQueuesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProtoOrBuilder>(
                  childQueues_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          childQueues_ = null;
        }
        return childQueuesBuilder_;
      }

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> applications_ =
        java.util.Collections.emptyList();
      private void ensureApplicationsIsMutable() {
        if (!((bitField0_ & 0x00000040) == 0x00000040)) {
          applications_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto>(applications_);
          bitField0_ |= 0x00000040;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> applicationsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> getApplicationsList() {
        if (applicationsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applications_);
        } else {
          return applicationsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public int getApplicationsCount() {
        if (applicationsBuilder_ == null) {
          return applications_.size();
        } else {
          return applicationsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto getApplications(int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);
        } else {
          return applicationsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.set(index, value);
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder setApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto value) {
        if (applicationsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationsIsMutable();
          applications_.add(index, value);
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addApplications(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder builderForValue) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder addAllApplications(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto> values) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, applications_);
          onChanged();
        } else {
          applicationsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder clearApplications() {
        if (applicationsBuilder_ == null) {
          applications_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000040);
          onChanged();
        } else {
          applicationsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public Builder removeApplications(int index) {
        if (applicationsBuilder_ == null) {
          ensureApplicationsIsMutable();
          applications_.remove(index);
          onChanged();
        } else {
          applicationsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder getApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder getApplicationsOrBuilder(
          int index) {
        if (applicationsBuilder_ == null) {
          return applications_.get(index);  } else {
          return applicationsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
           getApplicationsOrBuilderList() {
        if (applicationsBuilder_ != null) {
          return applicationsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applications_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder() {
        return getApplicationsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder addApplicationsBuilder(
          int index) {
        return getApplicationsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationReportProto applications = 7;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder> 
           getApplicationsBuilderList() {
        return getApplicationsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder> 
          getApplicationsFieldBuilder() {
        if (applicationsBuilder_ == null) {
          applicationsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationReportProtoOrBuilder>(
                  applications_,
                  ((bitField0_ & 0x00000040) == 0x00000040),
                  getParentForChildren(),
                  isClean());
          applications_ = null;
        }
        return applicationsBuilder_;
      }

      private com.google.protobuf.LazyStringList accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureAccessibleNodeLabelsIsMutable() {
        if (!((bitField0_ & 0x00000080) == 0x00000080)) {
          accessibleNodeLabels_ = new com.google.protobuf.LazyStringArrayList(accessibleNodeLabels_);
          bitField0_ |= 0x00000080;
         }
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getAccessibleNodeLabelsList() {
        return accessibleNodeLabels_.getUnmodifiableView();
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public int getAccessibleNodeLabelsCount() {
        return accessibleNodeLabels_.size();
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public java.lang.String getAccessibleNodeLabels(int index) {
        return accessibleNodeLabels_.get(index);
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public com.google.protobuf.ByteString
          getAccessibleNodeLabelsBytes(int index) {
        return accessibleNodeLabels_.getByteString(index);
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder setAccessibleNodeLabels(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureAccessibleNodeLabelsIsMutable();
        accessibleNodeLabels_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder addAccessibleNodeLabels(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureAccessibleNodeLabelsIsMutable();
        accessibleNodeLabels_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder addAllAccessibleNodeLabels(
          java.lang.Iterable<java.lang.String> values) {
        ensureAccessibleNodeLabelsIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, accessibleNodeLabels_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder clearAccessibleNodeLabels() {
        accessibleNodeLabels_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000080);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string accessibleNodeLabels = 8;</code>
       */
      public Builder addAccessibleNodeLabelsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureAccessibleNodeLabelsIsMutable();
        accessibleNodeLabels_.add(value);
        onChanged();
        return this;
      }

      private java.lang.Object defaultNodeLabelExpression_ = "";
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public boolean hasDefaultNodeLabelExpression() {
        return ((bitField0_ & 0x00000100) == 0x00000100);
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public java.lang.String getDefaultNodeLabelExpression() {
        java.lang.Object ref = defaultNodeLabelExpression_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            defaultNodeLabelExpression_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public com.google.protobuf.ByteString
          getDefaultNodeLabelExpressionBytes() {
        java.lang.Object ref = defaultNodeLabelExpression_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          defaultNodeLabelExpression_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public Builder setDefaultNodeLabelExpression(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        defaultNodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public Builder clearDefaultNodeLabelExpression() {
        bitField0_ = (bitField0_ & ~0x00000100);
        defaultNodeLabelExpression_ = getDefaultInstance().getDefaultNodeLabelExpression();
        onChanged();
        return this;
      }
      /**
       * <code>optional string defaultNodeLabelExpression = 9;</code>
       */
      public Builder setDefaultNodeLabelExpressionBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000100;
        defaultNodeLabelExpression_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueInfoProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueInfoProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<QueueInfoProto>
        PARSER = new com.google.protobuf.AbstractParser<QueueInfoProto>() {
      public QueueInfoProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new QueueInfoProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<QueueInfoProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<QueueInfoProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.QueueInfoProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface QueueUserACLInfoProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.QueueUserACLInfoProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string queueName = 1;</code>
     */
    boolean hasQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    java.lang.String getQueueName();
    /**
     * <code>optional string queueName = 1;</code>
     */
    com.google.protobuf.ByteString
        getQueueNameBytes();

    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList();
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    int getUserAclsCount();
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.QueueUserACLInfoProto}
   */
  public  static final class QueueUserACLInfoProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.QueueUserACLInfoProto)
      QueueUserACLInfoProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use QueueUserACLInfoProto.newBuilder() to construct.
    private QueueUserACLInfoProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private QueueUserACLInfoProto() {
      queueName_ = "";
      userAcls_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private QueueUserACLInfoProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              queueName_ = bs;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                  userAcls_ = new java.util.ArrayList<java.lang.Integer>();
                  mutable_bitField0_ |= 0x00000002;
                }
                userAcls_.add(rawValue);
              }
              break;
            }
            case 18: {
              int length = input.readRawVarint32();
              int oldLimit = input.pushLimit(length);
              while(input.getBytesUntilLimit() > 0) {
                int rawValue = input.readEnum();
                org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value = org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.valueOf(rawValue);
                if (value == null) {
                  unknownFields.mergeVarintField(2, rawValue);
                } else {
                  if (!((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
                    userAcls_ = new java.util.ArrayList<java.lang.Integer>();
                    mutable_bitField0_ |= 0x00000002;
                  }
                  userAcls_.add(rawValue);
                }
              }
              input.popLimit(oldLimit);
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = java.util.Collections.unmodifiableList(userAcls_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder.class);
    }

    private int bitField0_;
    public static final int QUEUENAME_FIELD_NUMBER = 1;
    private volatile java.lang.Object queueName_;
    /**
     * <code>optional string queueName = 1;</code>
     */
    public boolean hasQueueName() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public java.lang.String getQueueName() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          queueName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string queueName = 1;</code>
     */
    public com.google.protobuf.ByteString
        getQueueNameBytes() {
      java.lang.Object ref = queueName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        queueName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int USERACLS_FIELD_NUMBER = 2;
    private java.util.List<java.lang.Integer> userAcls_;
    private static final com.google.protobuf.Internal.ListAdapter.Converter<
        java.lang.Integer, org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> userAcls_converter_ =
            new com.google.protobuf.Internal.ListAdapter.Converter<
                java.lang.Integer, org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>() {
              public org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto convert(java.lang.Integer from) {
                org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto result = org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.valueOf(from);
                return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto.QACL_SUBMIT_APPLICATIONS : result;
              }
            };
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList() {
      return new com.google.protobuf.Internal.ListAdapter<
          java.lang.Integer, org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>(userAcls_, userAcls_converter_);
    }
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public int getUserAclsCount() {
      return userAcls_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index) {
      return userAcls_converter_.convert(userAcls_.get(index));
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, queueName_);
      }
      for (int i = 0; i < userAcls_.size(); i++) {
        output.writeEnum(2, userAcls_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, queueName_);
      }
      {
        int dataSize = 0;
        for (int i = 0; i < userAcls_.size(); i++) {
          dataSize += com.google.protobuf.CodedOutputStream
            .computeEnumSizeNoTag(userAcls_.get(i));
        }
        size += dataSize;
        size += 1 * userAcls_.size();
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto other = (org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) obj;

      boolean result = true;
      result = result && (hasQueueName() == other.hasQueueName());
      if (hasQueueName()) {
        result = result && getQueueName()
            .equals(other.getQueueName());
      }
      result = result && userAcls_.equals(other.userAcls_);
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasQueueName()) {
        hash = (37 * hash) + QUEUENAME_FIELD_NUMBER;
        hash = (53 * hash) + getQueueName().hashCode();
      }
      if (getUserAclsCount() > 0) {
        hash = (37 * hash) + USERACLS_FIELD_NUMBER;
        hash = (53 * hash) + userAcls_.hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.QueueUserACLInfoProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.QueueUserACLInfoProto)
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.class, org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        queueName_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        userAcls_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto result = new org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.queueName_ = queueName_;
        if (((bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = java.util.Collections.unmodifiableList(userAcls_);
          bitField0_ = (bitField0_ & ~0x00000002);
        }
        result.userAcls_ = userAcls_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto.getDefaultInstance()) return this;
        if (other.hasQueueName()) {
          bitField0_ |= 0x00000001;
          queueName_ = other.queueName_;
          onChanged();
        }
        if (!other.userAcls_.isEmpty()) {
          if (userAcls_.isEmpty()) {
            userAcls_ = other.userAcls_;
            bitField0_ = (bitField0_ & ~0x00000002);
          } else {
            ensureUserAclsIsMutable();
            userAcls_.addAll(other.userAcls_);
          }
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object queueName_ = "";
      /**
       * <code>optional string queueName = 1;</code>
       */
      public boolean hasQueueName() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public java.lang.String getQueueName() {
        java.lang.Object ref = queueName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            queueName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public com.google.protobuf.ByteString
          getQueueNameBytes() {
        java.lang.Object ref = queueName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          queueName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder clearQueueName() {
        bitField0_ = (bitField0_ & ~0x00000001);
        queueName_ = getDefaultInstance().getQueueName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string queueName = 1;</code>
       */
      public Builder setQueueNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        queueName_ = value;
        onChanged();
        return this;
      }

      private java.util.List<java.lang.Integer> userAcls_ =
        java.util.Collections.emptyList();
      private void ensureUserAclsIsMutable() {
        if (!((bitField0_ & 0x00000002) == 0x00000002)) {
          userAcls_ = new java.util.ArrayList<java.lang.Integer>(userAcls_);
          bitField0_ |= 0x00000002;
        }
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> getUserAclsList() {
        return new com.google.protobuf.Internal.ListAdapter<
            java.lang.Integer, org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto>(userAcls_, userAcls_converter_);
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public int getUserAclsCount() {
        return userAcls_.size();
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto getUserAcls(int index) {
        return userAcls_converter_.convert(userAcls_.get(index));
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder setUserAcls(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureUserAclsIsMutable();
        userAcls_.set(index, value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder addUserAcls(org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        ensureUserAclsIsMutable();
        userAcls_.add(value.getNumber());
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder addAllUserAcls(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto> values) {
        ensureUserAclsIsMutable();
        for (org.apache.hadoop.yarn.proto.YarnProtos.QueueACLProto value : values) {
          userAcls_.add(value.getNumber());
        }
        onChanged();
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.QueueACLProto userAcls = 2;</code>
       */
      public Builder clearUserAcls() {
        userAcls_ = java.util.Collections.emptyList();
        bitField0_ = (bitField0_ & ~0x00000002);
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.QueueUserACLInfoProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.QueueUserACLInfoProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<QueueUserACLInfoProto>
        PARSER = new com.google.protobuf.AbstractParser<QueueUserACLInfoProto>() {
      public QueueUserACLInfoProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new QueueUserACLInfoProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<QueueUserACLInfoProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<QueueUserACLInfoProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.QueueUserACLInfoProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationIdProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationIdProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional int64 id = 1;</code>
     */
    boolean hasId();
    /**
     * <code>optional int64 id = 1;</code>
     */
    long getId();

    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    boolean hasClusterTimestamp();
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    long getClusterTimestamp();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationIdProto}
   */
  public  static final class ReservationIdProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationIdProto)
      ReservationIdProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReservationIdProto.newBuilder() to construct.
    private ReservationIdProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationIdProto() {
      id_ = 0L;
      clusterTimestamp_ = 0L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationIdProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 8: {
              bitField0_ |= 0x00000001;
              id_ = input.readInt64();
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              clusterTimestamp_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder.class);
    }

    private int bitField0_;
    public static final int ID_FIELD_NUMBER = 1;
    private long id_;
    /**
     * <code>optional int64 id = 1;</code>
     */
    public boolean hasId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional int64 id = 1;</code>
     */
    public long getId() {
      return id_;
    }

    public static final int CLUSTER_TIMESTAMP_FIELD_NUMBER = 2;
    private long clusterTimestamp_;
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public boolean hasClusterTimestamp() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 cluster_timestamp = 2;</code>
     */
    public long getClusterTimestamp() {
      return clusterTimestamp_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeInt64(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, clusterTimestamp_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(1, id_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, clusterTimestamp_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto) obj;

      boolean result = true;
      result = result && (hasId() == other.hasId());
      if (hasId()) {
        result = result && (getId()
            == other.getId());
      }
      result = result && (hasClusterTimestamp() == other.hasClusterTimestamp());
      if (hasClusterTimestamp()) {
        result = result && (getClusterTimestamp()
            == other.getClusterTimestamp());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasId()) {
        hash = (37 * hash) + ID_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getId());
      }
      if (hasClusterTimestamp()) {
        hash = (37 * hash) + CLUSTER_TIMESTAMP_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getClusterTimestamp());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationIdProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationIdProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        id_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000001);
        clusterTimestamp_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationIdProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.id_ = id_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.clusterTimestamp_ = clusterTimestamp_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto.getDefaultInstance()) return this;
        if (other.hasId()) {
          setId(other.getId());
        }
        if (other.hasClusterTimestamp()) {
          setClusterTimestamp(other.getClusterTimestamp());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private long id_ ;
      /**
       * <code>optional int64 id = 1;</code>
       */
      public boolean hasId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional int64 id = 1;</code>
       */
      public long getId() {
        return id_;
      }
      /**
       * <code>optional int64 id = 1;</code>
       */
      public Builder setId(long value) {
        bitField0_ |= 0x00000001;
        id_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 id = 1;</code>
       */
      public Builder clearId() {
        bitField0_ = (bitField0_ & ~0x00000001);
        id_ = 0L;
        onChanged();
        return this;
      }

      private long clusterTimestamp_ ;
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public boolean hasClusterTimestamp() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public long getClusterTimestamp() {
        return clusterTimestamp_;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder setClusterTimestamp(long value) {
        bitField0_ |= 0x00000002;
        clusterTimestamp_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 cluster_timestamp = 2;</code>
       */
      public Builder clearClusterTimestamp() {
        bitField0_ = (bitField0_ & ~0x00000002);
        clusterTimestamp_ = 0L;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationIdProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationIdProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationIdProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationIdProto>() {
      public ReservationIdProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationIdProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationIdProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationIdProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationIdProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    boolean hasNumContainers();
    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    int getNumContainers();

    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    boolean hasConcurrency();
    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    int getConcurrency();

    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    boolean hasDuration();
    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    long getDuration();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationRequestProto}
   */
  public  static final class ReservationRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationRequestProto)
      ReservationRequestProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReservationRequestProto.newBuilder() to construct.
    private ReservationRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationRequestProto() {
      numContainers_ = 1;
      concurrency_ = 1;
      duration_ = -1L;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              numContainers_ = input.readInt32();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              concurrency_ = input.readInt32();
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              duration_ = input.readInt64();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int CAPABILITY_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }

    public static final int NUM_CONTAINERS_FIELD_NUMBER = 2;
    private int numContainers_;
    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    public boolean hasNumContainers() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int32 num_containers = 2 [default = 1];</code>
     */
    public int getNumContainers() {
      return numContainers_;
    }

    public static final int CONCURRENCY_FIELD_NUMBER = 3;
    private int concurrency_;
    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    public boolean hasConcurrency() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int32 concurrency = 3 [default = 1];</code>
     */
    public int getConcurrency() {
      return concurrency_;
    }

    public static final int DURATION_FIELD_NUMBER = 4;
    private long duration_;
    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    public boolean hasDuration() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int64 duration = 4 [default = -1];</code>
     */
    public long getDuration() {
      return duration_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getCapability());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt32(2, numContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt32(3, concurrency_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt64(4, duration_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getCapability());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(2, numContainers_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(3, concurrency_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(4, duration_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto) obj;

      boolean result = true;
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasNumContainers() == other.hasNumContainers());
      if (hasNumContainers()) {
        result = result && (getNumContainers()
            == other.getNumContainers());
      }
      result = result && (hasConcurrency() == other.hasConcurrency());
      if (hasConcurrency()) {
        result = result && (getConcurrency()
            == other.getConcurrency());
      }
      result = result && (hasDuration() == other.hasDuration());
      if (hasDuration()) {
        result = result && (getDuration()
            == other.getDuration());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasNumContainers()) {
        hash = (37 * hash) + NUM_CONTAINERS_FIELD_NUMBER;
        hash = (53 * hash) + getNumContainers();
      }
      if (hasConcurrency()) {
        hash = (37 * hash) + CONCURRENCY_FIELD_NUMBER;
        hash = (53 * hash) + getConcurrency();
      }
      if (hasDuration()) {
        hash = (37 * hash) + DURATION_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getDuration());
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationRequestProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getCapabilityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (capabilityBuilder_ == null) {
          capability_ = null;
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        numContainers_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        concurrency_ = 1;
        bitField0_ = (bitField0_ & ~0x00000004);
        duration_ = -1L;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.numContainers_ = numContainers_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.concurrency_ = concurrency_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.duration_ = duration_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance()) return this;
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasNumContainers()) {
          setNumContainers(other.getNumContainers());
        }
        if (other.hasConcurrency()) {
          setConcurrency(other.getConcurrency());
        }
        if (other.hasDuration()) {
          setDuration(other.getDuration());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              capability_ != null &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = null;
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getCapability(),
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      private int numContainers_ = 1;
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public boolean hasNumContainers() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public int getNumContainers() {
        return numContainers_;
      }
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public Builder setNumContainers(int value) {
        bitField0_ |= 0x00000002;
        numContainers_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 num_containers = 2 [default = 1];</code>
       */
      public Builder clearNumContainers() {
        bitField0_ = (bitField0_ & ~0x00000002);
        numContainers_ = 1;
        onChanged();
        return this;
      }

      private int concurrency_ = 1;
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public boolean hasConcurrency() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public int getConcurrency() {
        return concurrency_;
      }
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public Builder setConcurrency(int value) {
        bitField0_ |= 0x00000004;
        concurrency_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 concurrency = 3 [default = 1];</code>
       */
      public Builder clearConcurrency() {
        bitField0_ = (bitField0_ & ~0x00000004);
        concurrency_ = 1;
        onChanged();
        return this;
      }

      private long duration_ = -1L;
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public boolean hasDuration() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public long getDuration() {
        return duration_;
      }
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public Builder setDuration(long value) {
        bitField0_ |= 0x00000008;
        duration_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 duration = 4 [default = -1];</code>
       */
      public Builder clearDuration() {
        bitField0_ = (bitField0_ & ~0x00000008);
        duration_ = -1L;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationRequestProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationRequestProto>() {
      public ReservationRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationRequestProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationRequestsProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationRequestsProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> 
        getReservationResourcesList();
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getReservationResources(int index);
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    int getReservationResourcesCount();
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
        getReservationResourcesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder getReservationResourcesOrBuilder(
        int index);

    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    boolean hasInterpreter();
    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto getInterpreter();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationRequestsProto}
   */
  public  static final class ReservationRequestsProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationRequestsProto)
      ReservationRequestsProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReservationRequestsProto.newBuilder() to construct.
    private ReservationRequestsProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationRequestsProto() {
      reservationResources_ = java.util.Collections.emptyList();
      interpreter_ = 1;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationRequestsProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                reservationResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              reservationResources_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.PARSER, extensionRegistry));
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto value = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000001;
                interpreter_ = rawValue;
              }
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          reservationResources_ = java.util.Collections.unmodifiableList(reservationResources_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESERVATION_RESOURCES_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> reservationResources_;
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> getReservationResourcesList() {
      return reservationResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
        getReservationResourcesOrBuilderList() {
      return reservationResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public int getReservationResourcesCount() {
      return reservationResources_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getReservationResources(int index) {
      return reservationResources_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder getReservationResourcesOrBuilder(
        int index) {
      return reservationResources_.get(index);
    }

    public static final int INTERPRETER_FIELD_NUMBER = 2;
    private int interpreter_;
    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    public boolean hasInterpreter() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto getInterpreter() {
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto result = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.valueOf(interpreter_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.R_ALL : result;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < reservationResources_.size(); i++) {
        output.writeMessage(1, reservationResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeEnum(2, interpreter_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < reservationResources_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, reservationResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, interpreter_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto) obj;

      boolean result = true;
      result = result && getReservationResourcesList()
          .equals(other.getReservationResourcesList());
      result = result && (hasInterpreter() == other.hasInterpreter());
      if (hasInterpreter()) {
        result = result && interpreter_ == other.interpreter_;
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getReservationResourcesCount() > 0) {
        hash = (37 * hash) + RESERVATION_RESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getReservationResourcesList().hashCode();
      }
      if (hasInterpreter()) {
        hash = (37 * hash) + INTERPRETER_FIELD_NUMBER;
        hash = (53 * hash) + interpreter_;
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationRequestsProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationRequestsProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReservationResourcesFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (reservationResourcesBuilder_ == null) {
          reservationResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          reservationResourcesBuilder_.clear();
        }
        interpreter_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (reservationResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            reservationResources_ = java.util.Collections.unmodifiableList(reservationResources_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.reservationResources_ = reservationResources_;
        } else {
          result.reservationResources_ = reservationResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.interpreter_ = interpreter_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance()) return this;
        if (reservationResourcesBuilder_ == null) {
          if (!other.reservationResources_.isEmpty()) {
            if (reservationResources_.isEmpty()) {
              reservationResources_ = other.reservationResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureReservationResourcesIsMutable();
              reservationResources_.addAll(other.reservationResources_);
            }
            onChanged();
          }
        } else {
          if (!other.reservationResources_.isEmpty()) {
            if (reservationResourcesBuilder_.isEmpty()) {
              reservationResourcesBuilder_.dispose();
              reservationResourcesBuilder_ = null;
              reservationResources_ = other.reservationResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
              reservationResourcesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getReservationResourcesFieldBuilder() : null;
            } else {
              reservationResourcesBuilder_.addAllMessages(other.reservationResources_);
            }
          }
        }
        if (other.hasInterpreter()) {
          setInterpreter(other.getInterpreter());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> reservationResources_ =
        java.util.Collections.emptyList();
      private void ensureReservationResourcesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          reservationResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto>(reservationResources_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> reservationResourcesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> getReservationResourcesList() {
        if (reservationResourcesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(reservationResources_);
        } else {
          return reservationResourcesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public int getReservationResourcesCount() {
        if (reservationResourcesBuilder_ == null) {
          return reservationResources_.size();
        } else {
          return reservationResourcesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto getReservationResources(int index) {
        if (reservationResourcesBuilder_ == null) {
          return reservationResources_.get(index);
        } else {
          return reservationResourcesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder setReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto value) {
        if (reservationResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationResourcesIsMutable();
          reservationResources_.set(index, value);
          onChanged();
        } else {
          reservationResourcesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder setReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder builderForValue) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.set(index, builderForValue.build());
          onChanged();
        } else {
          reservationResourcesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto value) {
        if (reservationResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationResourcesIsMutable();
          reservationResources_.add(value);
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto value) {
        if (reservationResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureReservationResourcesIsMutable();
          reservationResources_.add(index, value);
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder builderForValue) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.add(builderForValue.build());
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addReservationResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder builderForValue) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.add(index, builderForValue.build());
          onChanged();
        } else {
          reservationResourcesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder addAllReservationResources(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto> values) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, reservationResources_);
          onChanged();
        } else {
          reservationResourcesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder clearReservationResources() {
        if (reservationResourcesBuilder_ == null) {
          reservationResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          reservationResourcesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public Builder removeReservationResources(int index) {
        if (reservationResourcesBuilder_ == null) {
          ensureReservationResourcesIsMutable();
          reservationResources_.remove(index);
          onChanged();
        } else {
          reservationResourcesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder getReservationResourcesBuilder(
          int index) {
        return getReservationResourcesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder getReservationResourcesOrBuilder(
          int index) {
        if (reservationResourcesBuilder_ == null) {
          return reservationResources_.get(index);  } else {
          return reservationResourcesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
           getReservationResourcesOrBuilderList() {
        if (reservationResourcesBuilder_ != null) {
          return reservationResourcesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(reservationResources_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder addReservationResourcesBuilder() {
        return getReservationResourcesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder addReservationResourcesBuilder(
          int index) {
        return getReservationResourcesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ReservationRequestProto reservation_resources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder> 
           getReservationResourcesBuilderList() {
        return getReservationResourcesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder> 
          getReservationResourcesFieldBuilder() {
        if (reservationResourcesBuilder_ == null) {
          reservationResourcesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestProtoOrBuilder>(
                  reservationResources_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          reservationResources_ = null;
        }
        return reservationResourcesBuilder_;
      }

      private int interpreter_ = 1;
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public boolean hasInterpreter() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto getInterpreter() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto result = org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.valueOf(interpreter_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto.R_ALL : result;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public Builder setInterpreter(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestInterpreterProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        interpreter_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestInterpreterProto interpreter = 2 [default = R_ALL];</code>
       */
      public Builder clearInterpreter() {
        bitField0_ = (bitField0_ & ~0x00000002);
        interpreter_ = 1;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationRequestsProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationRequestsProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationRequestsProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationRequestsProto>() {
      public ReservationRequestsProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationRequestsProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationRequestsProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationRequestsProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ReservationDefinitionProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ReservationDefinitionProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    boolean hasReservationRequests();
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getReservationRequests();
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder getReservationRequestsOrBuilder();

    /**
     * <code>optional int64 arrival = 2;</code>
     */
    boolean hasArrival();
    /**
     * <code>optional int64 arrival = 2;</code>
     */
    long getArrival();

    /**
     * <code>optional int64 deadline = 3;</code>
     */
    boolean hasDeadline();
    /**
     * <code>optional int64 deadline = 3;</code>
     */
    long getDeadline();

    /**
     * <code>optional string reservation_name = 4;</code>
     */
    boolean hasReservationName();
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    java.lang.String getReservationName();
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    com.google.protobuf.ByteString
        getReservationNameBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ReservationDefinitionProto}
   */
  public  static final class ReservationDefinitionProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ReservationDefinitionProto)
      ReservationDefinitionProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ReservationDefinitionProto.newBuilder() to construct.
    private ReservationDefinitionProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ReservationDefinitionProto() {
      arrival_ = 0L;
      deadline_ = 0L;
      reservationName_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ReservationDefinitionProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = reservationRequests_.toBuilder();
              }
              reservationRequests_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(reservationRequests_);
                reservationRequests_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              bitField0_ |= 0x00000002;
              arrival_ = input.readInt64();
              break;
            }
            case 24: {
              bitField0_ |= 0x00000004;
              deadline_ = input.readInt64();
              break;
            }
            case 34: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000008;
              reservationName_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder.class);
    }

    private int bitField0_;
    public static final int RESERVATION_REQUESTS_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto reservationRequests_;
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    public boolean hasReservationRequests() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getReservationRequests() {
      return reservationRequests_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance() : reservationRequests_;
    }
    /**
     * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder getReservationRequestsOrBuilder() {
      return reservationRequests_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance() : reservationRequests_;
    }

    public static final int ARRIVAL_FIELD_NUMBER = 2;
    private long arrival_;
    /**
     * <code>optional int64 arrival = 2;</code>
     */
    public boolean hasArrival() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional int64 arrival = 2;</code>
     */
    public long getArrival() {
      return arrival_;
    }

    public static final int DEADLINE_FIELD_NUMBER = 3;
    private long deadline_;
    /**
     * <code>optional int64 deadline = 3;</code>
     */
    public boolean hasDeadline() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional int64 deadline = 3;</code>
     */
    public long getDeadline() {
      return deadline_;
    }

    public static final int RESERVATION_NAME_FIELD_NUMBER = 4;
    private volatile java.lang.Object reservationName_;
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    public boolean hasReservationName() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    public java.lang.String getReservationName() {
      java.lang.Object ref = reservationName_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          reservationName_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string reservation_name = 4;</code>
     */
    public com.google.protobuf.ByteString
        getReservationNameBytes() {
      java.lang.Object ref = reservationName_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        reservationName_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getReservationRequests());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeInt64(2, arrival_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeInt64(3, deadline_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 4, reservationName_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getReservationRequests());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(2, arrival_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt64Size(3, deadline_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(4, reservationName_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto) obj;

      boolean result = true;
      result = result && (hasReservationRequests() == other.hasReservationRequests());
      if (hasReservationRequests()) {
        result = result && getReservationRequests()
            .equals(other.getReservationRequests());
      }
      result = result && (hasArrival() == other.hasArrival());
      if (hasArrival()) {
        result = result && (getArrival()
            == other.getArrival());
      }
      result = result && (hasDeadline() == other.hasDeadline());
      if (hasDeadline()) {
        result = result && (getDeadline()
            == other.getDeadline());
      }
      result = result && (hasReservationName() == other.hasReservationName());
      if (hasReservationName()) {
        result = result && getReservationName()
            .equals(other.getReservationName());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasReservationRequests()) {
        hash = (37 * hash) + RESERVATION_REQUESTS_FIELD_NUMBER;
        hash = (53 * hash) + getReservationRequests().hashCode();
      }
      if (hasArrival()) {
        hash = (37 * hash) + ARRIVAL_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getArrival());
      }
      if (hasDeadline()) {
        hash = (37 * hash) + DEADLINE_FIELD_NUMBER;
        hash = (53 * hash) + com.google.protobuf.Internal.hashLong(
            getDeadline());
      }
      if (hasReservationName()) {
        hash = (37 * hash) + RESERVATION_NAME_FIELD_NUMBER;
        hash = (53 * hash) + getReservationName().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ReservationDefinitionProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ReservationDefinitionProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getReservationRequestsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (reservationRequestsBuilder_ == null) {
          reservationRequests_ = null;
        } else {
          reservationRequestsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        arrival_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000002);
        deadline_ = 0L;
        bitField0_ = (bitField0_ & ~0x00000004);
        reservationName_ = "";
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (reservationRequestsBuilder_ == null) {
          result.reservationRequests_ = reservationRequests_;
        } else {
          result.reservationRequests_ = reservationRequestsBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.arrival_ = arrival_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.deadline_ = deadline_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.reservationName_ = reservationName_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto.getDefaultInstance()) return this;
        if (other.hasReservationRequests()) {
          mergeReservationRequests(other.getReservationRequests());
        }
        if (other.hasArrival()) {
          setArrival(other.getArrival());
        }
        if (other.hasDeadline()) {
          setDeadline(other.getDeadline());
        }
        if (other.hasReservationName()) {
          bitField0_ |= 0x00000008;
          reservationName_ = other.reservationName_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto reservationRequests_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder> reservationRequestsBuilder_;
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public boolean hasReservationRequests() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto getReservationRequests() {
        if (reservationRequestsBuilder_ == null) {
          return reservationRequests_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance() : reservationRequests_;
        } else {
          return reservationRequestsBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder setReservationRequests(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto value) {
        if (reservationRequestsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          reservationRequests_ = value;
          onChanged();
        } else {
          reservationRequestsBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder setReservationRequests(
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder builderForValue) {
        if (reservationRequestsBuilder_ == null) {
          reservationRequests_ = builderForValue.build();
          onChanged();
        } else {
          reservationRequestsBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder mergeReservationRequests(org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto value) {
        if (reservationRequestsBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              reservationRequests_ != null &&
              reservationRequests_ != org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance()) {
            reservationRequests_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.newBuilder(reservationRequests_).mergeFrom(value).buildPartial();
          } else {
            reservationRequests_ = value;
          }
          onChanged();
        } else {
          reservationRequestsBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public Builder clearReservationRequests() {
        if (reservationRequestsBuilder_ == null) {
          reservationRequests_ = null;
          onChanged();
        } else {
          reservationRequestsBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder getReservationRequestsBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getReservationRequestsFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder getReservationRequestsOrBuilder() {
        if (reservationRequestsBuilder_ != null) {
          return reservationRequestsBuilder_.getMessageOrBuilder();
        } else {
          return reservationRequests_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.getDefaultInstance() : reservationRequests_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ReservationRequestsProto reservation_requests = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder> 
          getReservationRequestsFieldBuilder() {
        if (reservationRequestsBuilder_ == null) {
          reservationRequestsBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ReservationRequestsProtoOrBuilder>(
                  getReservationRequests(),
                  getParentForChildren(),
                  isClean());
          reservationRequests_ = null;
        }
        return reservationRequestsBuilder_;
      }

      private long arrival_ ;
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public boolean hasArrival() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public long getArrival() {
        return arrival_;
      }
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public Builder setArrival(long value) {
        bitField0_ |= 0x00000002;
        arrival_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 arrival = 2;</code>
       */
      public Builder clearArrival() {
        bitField0_ = (bitField0_ & ~0x00000002);
        arrival_ = 0L;
        onChanged();
        return this;
      }

      private long deadline_ ;
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public boolean hasDeadline() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public long getDeadline() {
        return deadline_;
      }
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public Builder setDeadline(long value) {
        bitField0_ |= 0x00000004;
        deadline_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int64 deadline = 3;</code>
       */
      public Builder clearDeadline() {
        bitField0_ = (bitField0_ & ~0x00000004);
        deadline_ = 0L;
        onChanged();
        return this;
      }

      private java.lang.Object reservationName_ = "";
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public boolean hasReservationName() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public java.lang.String getReservationName() {
        java.lang.Object ref = reservationName_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            reservationName_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public com.google.protobuf.ByteString
          getReservationNameBytes() {
        java.lang.Object ref = reservationName_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          reservationName_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public Builder setReservationName(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        reservationName_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public Builder clearReservationName() {
        bitField0_ = (bitField0_ & ~0x00000008);
        reservationName_ = getDefaultInstance().getReservationName();
        onChanged();
        return this;
      }
      /**
       * <code>optional string reservation_name = 4;</code>
       */
      public Builder setReservationNameBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000008;
        reservationName_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ReservationDefinitionProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ReservationDefinitionProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ReservationDefinitionProto>
        PARSER = new com.google.protobuf.AbstractParser<ReservationDefinitionProto>() {
      public ReservationDefinitionProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ReservationDefinitionProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ReservationDefinitionProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ReservationDefinitionProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ReservationDefinitionProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerLaunchContextProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerLaunchContextProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> 
        getLocalResourcesList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index);
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    int getLocalResourcesCount();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index);

    /**
     * <code>optional bytes tokens = 2;</code>
     */
    boolean hasTokens();
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    com.google.protobuf.ByteString getTokens();

    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> 
        getServiceDataList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index);
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    int getServiceDataCount();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceDataOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
        int index);

    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> 
        getEnvironmentList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index);
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    int getEnvironmentCount();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getEnvironmentOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
        int index);

    /**
     * <code>repeated string command = 5;</code>
     */
    java.util.List<java.lang.String>
        getCommandList();
    /**
     * <code>repeated string command = 5;</code>
     */
    int getCommandCount();
    /**
     * <code>repeated string command = 5;</code>
     */
    java.lang.String getCommand(int index);
    /**
     * <code>repeated string command = 5;</code>
     */
    com.google.protobuf.ByteString
        getCommandBytes(int index);

    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> 
        getApplicationACLsList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index);
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    int getApplicationACLsCount();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList();
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index);
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerLaunchContextProto}
   */
  public  static final class ContainerLaunchContextProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerLaunchContextProto)
      ContainerLaunchContextProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerLaunchContextProto.newBuilder() to construct.
    private ContainerLaunchContextProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerLaunchContextProto() {
      localResources_ = java.util.Collections.emptyList();
      tokens_ = com.google.protobuf.ByteString.EMPTY;
      serviceData_ = java.util.Collections.emptyList();
      environment_ = java.util.Collections.emptyList();
      command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      applicationACLs_ = java.util.Collections.emptyList();
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerLaunchContextProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              if (!((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
                localResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>();
                mutable_bitField0_ |= 0x00000001;
              }
              localResources_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.PARSER, extensionRegistry));
              break;
            }
            case 18: {
              bitField0_ |= 0x00000001;
              tokens_ = input.readBytes();
              break;
            }
            case 26: {
              if (!((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
                serviceData_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>();
                mutable_bitField0_ |= 0x00000004;
              }
              serviceData_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.PARSER, extensionRegistry));
              break;
            }
            case 34: {
              if (!((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
                environment_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>();
                mutable_bitField0_ |= 0x00000008;
              }
              environment_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.PARSER, extensionRegistry));
              break;
            }
            case 42: {
              com.google.protobuf.ByteString bs = input.readBytes();
              if (!((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
                command_ = new com.google.protobuf.LazyStringArrayList();
                mutable_bitField0_ |= 0x00000010;
              }
              command_.add(bs);
              break;
            }
            case 50: {
              if (!((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
                applicationACLs_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>();
                mutable_bitField0_ |= 0x00000020;
              }
              applicationACLs_.add(
                  input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.PARSER, extensionRegistry));
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        if (((mutable_bitField0_ & 0x00000001) == 0x00000001)) {
          localResources_ = java.util.Collections.unmodifiableList(localResources_);
        }
        if (((mutable_bitField0_ & 0x00000004) == 0x00000004)) {
          serviceData_ = java.util.Collections.unmodifiableList(serviceData_);
        }
        if (((mutable_bitField0_ & 0x00000008) == 0x00000008)) {
          environment_ = java.util.Collections.unmodifiableList(environment_);
        }
        if (((mutable_bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = command_.getUnmodifiableView();
        }
        if (((mutable_bitField0_ & 0x00000020) == 0x00000020)) {
          applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
        }
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder.class);
    }

    private int bitField0_;
    public static final int LOCALRESOURCES_FIELD_NUMBER = 1;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_;
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
        getLocalResourcesOrBuilderList() {
      return localResources_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public int getLocalResourcesCount() {
      return localResources_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
      return localResources_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
        int index) {
      return localResources_.get(index);
    }

    public static final int TOKENS_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString tokens_;
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    public boolean hasTokens() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional bytes tokens = 2;</code>
     */
    public com.google.protobuf.ByteString getTokens() {
      return tokens_;
    }

    public static final int SERVICE_DATA_FIELD_NUMBER = 3;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceData_;
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceDataList() {
      return serviceData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
        getServiceDataOrBuilderList() {
      return serviceData_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public int getServiceDataCount() {
      return serviceData_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index) {
      return serviceData_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
        int index) {
      return serviceData_.get(index);
    }

    public static final int ENVIRONMENT_FIELD_NUMBER = 4;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> environment_;
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getEnvironmentList() {
      return environment_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
        getEnvironmentOrBuilderList() {
      return environment_;
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public int getEnvironmentCount() {
      return environment_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index) {
      return environment_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
        int index) {
      return environment_.get(index);
    }

    public static final int COMMAND_FIELD_NUMBER = 5;
    private com.google.protobuf.LazyStringList command_;
    /**
     * <code>repeated string command = 5;</code>
     */
    public com.google.protobuf.ProtocolStringList
        getCommandList() {
      return command_;
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public int getCommandCount() {
      return command_.size();
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public java.lang.String getCommand(int index) {
      return command_.get(index);
    }
    /**
     * <code>repeated string command = 5;</code>
     */
    public com.google.protobuf.ByteString
        getCommandBytes(int index) {
      return command_.getByteString(index);
    }

    public static final int APPLICATION_ACLS_FIELD_NUMBER = 6;
    private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_;
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
        getApplicationACLsOrBuilderList() {
      return applicationACLs_;
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public int getApplicationACLsCount() {
      return applicationACLs_.size();
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
      return applicationACLs_.get(index);
    }
    /**
     * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
        int index) {
      return applicationACLs_.get(index);
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      for (int i = 0; i < localResources_.size(); i++) {
        output.writeMessage(1, localResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeBytes(2, tokens_);
      }
      for (int i = 0; i < serviceData_.size(); i++) {
        output.writeMessage(3, serviceData_.get(i));
      }
      for (int i = 0; i < environment_.size(); i++) {
        output.writeMessage(4, environment_.get(i));
      }
      for (int i = 0; i < command_.size(); i++) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 5, command_.getRaw(i));
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        output.writeMessage(6, applicationACLs_.get(i));
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      for (int i = 0; i < localResources_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, localResources_.get(i));
      }
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, tokens_);
      }
      for (int i = 0; i < serviceData_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, serviceData_.get(i));
      }
      for (int i = 0; i < environment_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(4, environment_.get(i));
      }
      {
        int dataSize = 0;
        for (int i = 0; i < command_.size(); i++) {
          dataSize += computeStringSizeNoTag(command_.getRaw(i));
        }
        size += dataSize;
        size += 1 * getCommandList().size();
      }
      for (int i = 0; i < applicationACLs_.size(); i++) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(6, applicationACLs_.get(i));
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) obj;

      boolean result = true;
      result = result && getLocalResourcesList()
          .equals(other.getLocalResourcesList());
      result = result && (hasTokens() == other.hasTokens());
      if (hasTokens()) {
        result = result && getTokens()
            .equals(other.getTokens());
      }
      result = result && getServiceDataList()
          .equals(other.getServiceDataList());
      result = result && getEnvironmentList()
          .equals(other.getEnvironmentList());
      result = result && getCommandList()
          .equals(other.getCommandList());
      result = result && getApplicationACLsList()
          .equals(other.getApplicationACLsList());
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (getLocalResourcesCount() > 0) {
        hash = (37 * hash) + LOCALRESOURCES_FIELD_NUMBER;
        hash = (53 * hash) + getLocalResourcesList().hashCode();
      }
      if (hasTokens()) {
        hash = (37 * hash) + TOKENS_FIELD_NUMBER;
        hash = (53 * hash) + getTokens().hashCode();
      }
      if (getServiceDataCount() > 0) {
        hash = (37 * hash) + SERVICE_DATA_FIELD_NUMBER;
        hash = (53 * hash) + getServiceDataList().hashCode();
      }
      if (getEnvironmentCount() > 0) {
        hash = (37 * hash) + ENVIRONMENT_FIELD_NUMBER;
        hash = (53 * hash) + getEnvironmentList().hashCode();
      }
      if (getCommandCount() > 0) {
        hash = (37 * hash) + COMMAND_FIELD_NUMBER;
        hash = (53 * hash) + getCommandList().hashCode();
      }
      if (getApplicationACLsCount() > 0) {
        hash = (37 * hash) + APPLICATION_ACLS_FIELD_NUMBER;
        hash = (53 * hash) + getApplicationACLsList().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerLaunchContextProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerLaunchContextProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getLocalResourcesFieldBuilder();
          getServiceDataFieldBuilder();
          getEnvironmentFieldBuilder();
          getApplicationACLsFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
        } else {
          localResourcesBuilder_.clear();
        }
        tokens_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        if (serviceDataBuilder_ == null) {
          serviceData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
        } else {
          serviceDataBuilder_.clear();
        }
        if (environmentBuilder_ == null) {
          environment_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
        } else {
          environmentBuilder_.clear();
        }
        command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (localResourcesBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001)) {
            localResources_ = java.util.Collections.unmodifiableList(localResources_);
            bitField0_ = (bitField0_ & ~0x00000001);
          }
          result.localResources_ = localResources_;
        } else {
          result.localResources_ = localResourcesBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000001;
        }
        result.tokens_ = tokens_;
        if (serviceDataBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004)) {
            serviceData_ = java.util.Collections.unmodifiableList(serviceData_);
            bitField0_ = (bitField0_ & ~0x00000004);
          }
          result.serviceData_ = serviceData_;
        } else {
          result.serviceData_ = serviceDataBuilder_.build();
        }
        if (environmentBuilder_ == null) {
          if (((bitField0_ & 0x00000008) == 0x00000008)) {
            environment_ = java.util.Collections.unmodifiableList(environment_);
            bitField0_ = (bitField0_ & ~0x00000008);
          }
          result.environment_ = environment_;
        } else {
          result.environment_ = environmentBuilder_.build();
        }
        if (((bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = command_.getUnmodifiableView();
          bitField0_ = (bitField0_ & ~0x00000010);
        }
        result.command_ = command_;
        if (applicationACLsBuilder_ == null) {
          if (((bitField0_ & 0x00000020) == 0x00000020)) {
            applicationACLs_ = java.util.Collections.unmodifiableList(applicationACLs_);
            bitField0_ = (bitField0_ & ~0x00000020);
          }
          result.applicationACLs_ = applicationACLs_;
        } else {
          result.applicationACLs_ = applicationACLsBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto.getDefaultInstance()) return this;
        if (localResourcesBuilder_ == null) {
          if (!other.localResources_.isEmpty()) {
            if (localResources_.isEmpty()) {
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
            } else {
              ensureLocalResourcesIsMutable();
              localResources_.addAll(other.localResources_);
            }
            onChanged();
          }
        } else {
          if (!other.localResources_.isEmpty()) {
            if (localResourcesBuilder_.isEmpty()) {
              localResourcesBuilder_.dispose();
              localResourcesBuilder_ = null;
              localResources_ = other.localResources_;
              bitField0_ = (bitField0_ & ~0x00000001);
              localResourcesBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getLocalResourcesFieldBuilder() : null;
            } else {
              localResourcesBuilder_.addAllMessages(other.localResources_);
            }
          }
        }
        if (other.hasTokens()) {
          setTokens(other.getTokens());
        }
        if (serviceDataBuilder_ == null) {
          if (!other.serviceData_.isEmpty()) {
            if (serviceData_.isEmpty()) {
              serviceData_ = other.serviceData_;
              bitField0_ = (bitField0_ & ~0x00000004);
            } else {
              ensureServiceDataIsMutable();
              serviceData_.addAll(other.serviceData_);
            }
            onChanged();
          }
        } else {
          if (!other.serviceData_.isEmpty()) {
            if (serviceDataBuilder_.isEmpty()) {
              serviceDataBuilder_.dispose();
              serviceDataBuilder_ = null;
              serviceData_ = other.serviceData_;
              bitField0_ = (bitField0_ & ~0x00000004);
              serviceDataBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getServiceDataFieldBuilder() : null;
            } else {
              serviceDataBuilder_.addAllMessages(other.serviceData_);
            }
          }
        }
        if (environmentBuilder_ == null) {
          if (!other.environment_.isEmpty()) {
            if (environment_.isEmpty()) {
              environment_ = other.environment_;
              bitField0_ = (bitField0_ & ~0x00000008);
            } else {
              ensureEnvironmentIsMutable();
              environment_.addAll(other.environment_);
            }
            onChanged();
          }
        } else {
          if (!other.environment_.isEmpty()) {
            if (environmentBuilder_.isEmpty()) {
              environmentBuilder_.dispose();
              environmentBuilder_ = null;
              environment_ = other.environment_;
              bitField0_ = (bitField0_ & ~0x00000008);
              environmentBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getEnvironmentFieldBuilder() : null;
            } else {
              environmentBuilder_.addAllMessages(other.environment_);
            }
          }
        }
        if (!other.command_.isEmpty()) {
          if (command_.isEmpty()) {
            command_ = other.command_;
            bitField0_ = (bitField0_ & ~0x00000010);
          } else {
            ensureCommandIsMutable();
            command_.addAll(other.command_);
          }
          onChanged();
        }
        if (applicationACLsBuilder_ == null) {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLs_.isEmpty()) {
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000020);
            } else {
              ensureApplicationACLsIsMutable();
              applicationACLs_.addAll(other.applicationACLs_);
            }
            onChanged();
          }
        } else {
          if (!other.applicationACLs_.isEmpty()) {
            if (applicationACLsBuilder_.isEmpty()) {
              applicationACLsBuilder_.dispose();
              applicationACLsBuilder_ = null;
              applicationACLs_ = other.applicationACLs_;
              bitField0_ = (bitField0_ & ~0x00000020);
              applicationACLsBuilder_ = 
                com.google.protobuf.GeneratedMessageV3.alwaysUseFieldBuilders ?
                   getApplicationACLsFieldBuilder() : null;
            } else {
              applicationACLsBuilder_.addAllMessages(other.applicationACLs_);
            }
          }
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> localResources_ =
        java.util.Collections.emptyList();
      private void ensureLocalResourcesIsMutable() {
        if (!((bitField0_ & 0x00000001) == 0x00000001)) {
          localResources_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto>(localResources_);
          bitField0_ |= 0x00000001;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> localResourcesBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> getLocalResourcesList() {
        if (localResourcesBuilder_ == null) {
          return java.util.Collections.unmodifiableList(localResources_);
        } else {
          return localResourcesBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public int getLocalResourcesCount() {
        if (localResourcesBuilder_ == null) {
          return localResources_.size();
        } else {
          return localResourcesBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);
        } else {
          return localResourcesBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder setLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.set(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder setLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.set(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto value) {
        if (localResourcesBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureLocalResourcesIsMutable();
          localResources_.add(index, value);
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addLocalResources(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder builderForValue) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.add(index, builderForValue.build());
          onChanged();
        } else {
          localResourcesBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder addAllLocalResources(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto> values) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, localResources_);
          onChanged();
        } else {
          localResourcesBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder clearLocalResources() {
        if (localResourcesBuilder_ == null) {
          localResources_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000001);
          onChanged();
        } else {
          localResourcesBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public Builder removeLocalResources(int index) {
        if (localResourcesBuilder_ == null) {
          ensureLocalResourcesIsMutable();
          localResources_.remove(index);
          onChanged();
        } else {
          localResourcesBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder getLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder getLocalResourcesOrBuilder(
          int index) {
        if (localResourcesBuilder_ == null) {
          return localResources_.get(index);  } else {
          return localResourcesBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
           getLocalResourcesOrBuilderList() {
        if (localResourcesBuilder_ != null) {
          return localResourcesBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(localResources_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder() {
        return getLocalResourcesFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder addLocalResourcesBuilder(
          int index) {
        return getLocalResourcesFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringLocalResourceMapProto localResources = 1;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder> 
           getLocalResourcesBuilderList() {
        return getLocalResourcesFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder> 
          getLocalResourcesFieldBuilder() {
        if (localResourcesBuilder_ == null) {
          localResourcesBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder>(
                  localResources_,
                  ((bitField0_ & 0x00000001) == 0x00000001),
                  getParentForChildren(),
                  isClean());
          localResources_ = null;
        }
        return localResourcesBuilder_;
      }

      private com.google.protobuf.ByteString tokens_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public boolean hasTokens() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public com.google.protobuf.ByteString getTokens() {
        return tokens_;
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public Builder setTokens(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        tokens_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes tokens = 2;</code>
       */
      public Builder clearTokens() {
        bitField0_ = (bitField0_ & ~0x00000002);
        tokens_ = getDefaultInstance().getTokens();
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> serviceData_ =
        java.util.Collections.emptyList();
      private void ensureServiceDataIsMutable() {
        if (!((bitField0_ & 0x00000004) == 0x00000004)) {
          serviceData_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto>(serviceData_);
          bitField0_ |= 0x00000004;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> serviceDataBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> getServiceDataList() {
        if (serviceDataBuilder_ == null) {
          return java.util.Collections.unmodifiableList(serviceData_);
        } else {
          return serviceDataBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public int getServiceDataCount() {
        if (serviceDataBuilder_ == null) {
          return serviceData_.size();
        } else {
          return serviceDataBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getServiceData(int index) {
        if (serviceDataBuilder_ == null) {
          return serviceData_.get(index);
        } else {
          return serviceDataBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder setServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.set(index, value);
          onChanged();
        } else {
          serviceDataBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder setServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.set(index, builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.add(value);
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto value) {
        if (serviceDataBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureServiceDataIsMutable();
          serviceData_.add(index, value);
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.add(builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addServiceData(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder builderForValue) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.add(index, builderForValue.build());
          onChanged();
        } else {
          serviceDataBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder addAllServiceData(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto> values) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, serviceData_);
          onChanged();
        } else {
          serviceDataBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder clearServiceData() {
        if (serviceDataBuilder_ == null) {
          serviceData_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000004);
          onChanged();
        } else {
          serviceDataBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public Builder removeServiceData(int index) {
        if (serviceDataBuilder_ == null) {
          ensureServiceDataIsMutable();
          serviceData_.remove(index);
          onChanged();
        } else {
          serviceDataBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder getServiceDataBuilder(
          int index) {
        return getServiceDataFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder getServiceDataOrBuilder(
          int index) {
        if (serviceDataBuilder_ == null) {
          return serviceData_.get(index);  } else {
          return serviceDataBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
           getServiceDataOrBuilderList() {
        if (serviceDataBuilder_ != null) {
          return serviceDataBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(serviceData_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceDataBuilder() {
        return getServiceDataFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder addServiceDataBuilder(
          int index) {
        return getServiceDataFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringBytesMapProto service_data = 3;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder> 
           getServiceDataBuilderList() {
        return getServiceDataFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder> 
          getServiceDataFieldBuilder() {
        if (serviceDataBuilder_ == null) {
          serviceDataBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder>(
                  serviceData_,
                  ((bitField0_ & 0x00000004) == 0x00000004),
                  getParentForChildren(),
                  isClean());
          serviceData_ = null;
        }
        return serviceDataBuilder_;
      }

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> environment_ =
        java.util.Collections.emptyList();
      private void ensureEnvironmentIsMutable() {
        if (!((bitField0_ & 0x00000008) == 0x00000008)) {
          environment_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto>(environment_);
          bitField0_ |= 0x00000008;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> environmentBuilder_;

      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> getEnvironmentList() {
        if (environmentBuilder_ == null) {
          return java.util.Collections.unmodifiableList(environment_);
        } else {
          return environmentBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public int getEnvironmentCount() {
        if (environmentBuilder_ == null) {
          return environment_.size();
        } else {
          return environmentBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getEnvironment(int index) {
        if (environmentBuilder_ == null) {
          return environment_.get(index);
        } else {
          return environmentBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder setEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.set(index, value);
          onChanged();
        } else {
          environmentBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder setEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.set(index, builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.add(value);
          onChanged();
        } else {
          environmentBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto value) {
        if (environmentBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureEnvironmentIsMutable();
          environment_.add(index, value);
          onChanged();
        } else {
          environmentBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.add(builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addEnvironment(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder builderForValue) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.add(index, builderForValue.build());
          onChanged();
        } else {
          environmentBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder addAllEnvironment(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto> values) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, environment_);
          onChanged();
        } else {
          environmentBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder clearEnvironment() {
        if (environmentBuilder_ == null) {
          environment_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000008);
          onChanged();
        } else {
          environmentBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public Builder removeEnvironment(int index) {
        if (environmentBuilder_ == null) {
          ensureEnvironmentIsMutable();
          environment_.remove(index);
          onChanged();
        } else {
          environmentBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder getEnvironmentBuilder(
          int index) {
        return getEnvironmentFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder getEnvironmentOrBuilder(
          int index) {
        if (environmentBuilder_ == null) {
          return environment_.get(index);  } else {
          return environmentBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
           getEnvironmentOrBuilderList() {
        if (environmentBuilder_ != null) {
          return environmentBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(environment_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addEnvironmentBuilder() {
        return getEnvironmentFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder addEnvironmentBuilder(
          int index) {
        return getEnvironmentFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.StringStringMapProto environment = 4;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder> 
           getEnvironmentBuilderList() {
        return getEnvironmentFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder> 
          getEnvironmentFieldBuilder() {
        if (environmentBuilder_ == null) {
          environmentBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder>(
                  environment_,
                  ((bitField0_ & 0x00000008) == 0x00000008),
                  getParentForChildren(),
                  isClean());
          environment_ = null;
        }
        return environmentBuilder_;
      }

      private com.google.protobuf.LazyStringList command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
      private void ensureCommandIsMutable() {
        if (!((bitField0_ & 0x00000010) == 0x00000010)) {
          command_ = new com.google.protobuf.LazyStringArrayList(command_);
          bitField0_ |= 0x00000010;
         }
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public com.google.protobuf.ProtocolStringList
          getCommandList() {
        return command_.getUnmodifiableView();
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public int getCommandCount() {
        return command_.size();
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public java.lang.String getCommand(int index) {
        return command_.get(index);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public com.google.protobuf.ByteString
          getCommandBytes(int index) {
        return command_.getByteString(index);
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder setCommand(
          int index, java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.set(index, value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addCommand(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.add(value);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addAllCommand(
          java.lang.Iterable<java.lang.String> values) {
        ensureCommandIsMutable();
        com.google.protobuf.AbstractMessageLite.Builder.addAll(
            values, command_);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder clearCommand() {
        command_ = com.google.protobuf.LazyStringArrayList.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000010);
        onChanged();
        return this;
      }
      /**
       * <code>repeated string command = 5;</code>
       */
      public Builder addCommandBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  ensureCommandIsMutable();
        command_.add(value);
        onChanged();
        return this;
      }

      private java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> applicationACLs_ =
        java.util.Collections.emptyList();
      private void ensureApplicationACLsIsMutable() {
        if (!((bitField0_ & 0x00000020) == 0x00000020)) {
          applicationACLs_ = new java.util.ArrayList<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto>(applicationACLs_);
          bitField0_ |= 0x00000020;
         }
      }

      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> applicationACLsBuilder_;

      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> getApplicationACLsList() {
        if (applicationACLsBuilder_ == null) {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        } else {
          return applicationACLsBuilder_.getMessageList();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public int getApplicationACLsCount() {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.size();
        } else {
          return applicationACLsBuilder_.getCount();
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto getApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);
        } else {
          return applicationACLsBuilder_.getMessage(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder setApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.set(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.setMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto value) {
        if (applicationACLsBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, value);
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, value);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addApplicationACLs(
          int index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder builderForValue) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.add(index, builderForValue.build());
          onChanged();
        } else {
          applicationACLsBuilder_.addMessage(index, builderForValue.build());
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder addAllApplicationACLs(
          java.lang.Iterable<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto> values) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          com.google.protobuf.AbstractMessageLite.Builder.addAll(
              values, applicationACLs_);
          onChanged();
        } else {
          applicationACLsBuilder_.addAllMessages(values);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder clearApplicationACLs() {
        if (applicationACLsBuilder_ == null) {
          applicationACLs_ = java.util.Collections.emptyList();
          bitField0_ = (bitField0_ & ~0x00000020);
          onChanged();
        } else {
          applicationACLsBuilder_.clear();
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public Builder removeApplicationACLs(int index) {
        if (applicationACLsBuilder_ == null) {
          ensureApplicationACLsIsMutable();
          applicationACLs_.remove(index);
          onChanged();
        } else {
          applicationACLsBuilder_.remove(index);
        }
        return this;
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder getApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().getBuilder(index);
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder getApplicationACLsOrBuilder(
          int index) {
        if (applicationACLsBuilder_ == null) {
          return applicationACLs_.get(index);  } else {
          return applicationACLsBuilder_.getMessageOrBuilder(index);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<? extends org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
           getApplicationACLsOrBuilderList() {
        if (applicationACLsBuilder_ != null) {
          return applicationACLsBuilder_.getMessageOrBuilderList();
        } else {
          return java.util.Collections.unmodifiableList(applicationACLs_);
        }
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder() {
        return getApplicationACLsFieldBuilder().addBuilder(
            org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder addApplicationACLsBuilder(
          int index) {
        return getApplicationACLsFieldBuilder().addBuilder(
            index, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.getDefaultInstance());
      }
      /**
       * <code>repeated .hadoop.yarn.ApplicationACLMapProto application_ACLs = 6;</code>
       */
      public java.util.List<org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder> 
           getApplicationACLsBuilderList() {
        return getApplicationACLsFieldBuilder().getBuilderList();
      }
      private com.google.protobuf.RepeatedFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder> 
          getApplicationACLsFieldBuilder() {
        if (applicationACLsBuilder_ == null) {
          applicationACLsBuilder_ = new com.google.protobuf.RepeatedFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ApplicationACLMapProtoOrBuilder>(
                  applicationACLs_,
                  ((bitField0_ & 0x00000020) == 0x00000020),
                  getParentForChildren(),
                  isClean());
          applicationACLs_ = null;
        }
        return applicationACLsBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerLaunchContextProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerLaunchContextProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerLaunchContextProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerLaunchContextProto>() {
      public ContainerLaunchContextProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerLaunchContextProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerLaunchContextProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerLaunchContextProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerLaunchContextProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerStatusProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerStatusProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    boolean hasState();
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState();

    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    boolean hasDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    java.lang.String getDiagnostics();
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    com.google.protobuf.ByteString
        getDiagnosticsBytes();

    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    boolean hasExitStatus();
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    int getExitStatus();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerStatusProto}
   */
  public  static final class ContainerStatusProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerStatusProto)
      ContainerStatusProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerStatusProto.newBuilder() to construct.
    private ContainerStatusProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerStatusProto() {
      state_ = 1;
      diagnostics_ = "N/A";
      exitStatus_ = -1000;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerStatusProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 16: {
              int rawValue = input.readEnum();
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(rawValue);
              if (value == null) {
                unknownFields.mergeVarintField(2, rawValue);
              } else {
                bitField0_ |= 0x00000002;
                state_ = rawValue;
              }
              break;
            }
            case 26: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000004;
              diagnostics_ = bs;
              break;
            }
            case 32: {
              bitField0_ |= 0x00000008;
              exitStatus_ = input.readInt32();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int STATE_FIELD_NUMBER = 2;
    private int state_;
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    public boolean hasState() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState() {
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(state_);
      return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW : result;
    }

    public static final int DIAGNOSTICS_FIELD_NUMBER = 3;
    private volatile java.lang.Object diagnostics_;
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public boolean hasDiagnostics() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public java.lang.String getDiagnostics() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          diagnostics_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string diagnostics = 3 [default = "N/A"];</code>
     */
    public com.google.protobuf.ByteString
        getDiagnosticsBytes() {
      java.lang.Object ref = diagnostics_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        diagnostics_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int EXIT_STATUS_FIELD_NUMBER = 4;
    private int exitStatus_;
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    public boolean hasExitStatus() {
      return ((bitField0_ & 0x00000008) == 0x00000008);
    }
    /**
     * <code>optional int32 exit_status = 4 [default = -1000];</code>
     */
    public int getExitStatus() {
      return exitStatus_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeEnum(2, state_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 3, diagnostics_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        output.writeInt32(4, exitStatus_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeEnumSize(2, state_);
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(3, diagnostics_);
      }
      if (((bitField0_ & 0x00000008) == 0x00000008)) {
        size += com.google.protobuf.CodedOutputStream
          .computeInt32Size(4, exitStatus_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasState() == other.hasState());
      if (hasState()) {
        result = result && state_ == other.state_;
      }
      result = result && (hasDiagnostics() == other.hasDiagnostics());
      if (hasDiagnostics()) {
        result = result && getDiagnostics()
            .equals(other.getDiagnostics());
      }
      result = result && (hasExitStatus() == other.hasExitStatus());
      if (hasExitStatus()) {
        result = result && (getExitStatus()
            == other.getExitStatus());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasState()) {
        hash = (37 * hash) + STATE_FIELD_NUMBER;
        hash = (53 * hash) + state_;
      }
      if (hasDiagnostics()) {
        hash = (37 * hash) + DIAGNOSTICS_FIELD_NUMBER;
        hash = (53 * hash) + getDiagnostics().hashCode();
      }
      if (hasExitStatus()) {
        hash = (37 * hash) + EXIT_STATUS_FIELD_NUMBER;
        hash = (53 * hash) + getExitStatus();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerStatusProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerStatusProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        state_ = 1;
        bitField0_ = (bitField0_ & ~0x00000002);
        diagnostics_ = "N/A";
        bitField0_ = (bitField0_ & ~0x00000004);
        exitStatus_ = -1000;
        bitField0_ = (bitField0_ & ~0x00000008);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.state_ = state_;
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        result.diagnostics_ = diagnostics_;
        if (((from_bitField0_ & 0x00000008) == 0x00000008)) {
          to_bitField0_ |= 0x00000008;
        }
        result.exitStatus_ = exitStatus_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasState()) {
          setState(other.getState());
        }
        if (other.hasDiagnostics()) {
          bitField0_ |= 0x00000004;
          diagnostics_ = other.diagnostics_;
          onChanged();
        }
        if (other.hasExitStatus()) {
          setExitStatus(other.getExitStatus());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private int state_ = 1;
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public boolean hasState() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto getState() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto result = org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.valueOf(state_);
        return result == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto.C_NEW : result;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public Builder setState(org.apache.hadoop.yarn.proto.YarnProtos.ContainerStateProto value) {
        if (value == null) {
          throw new NullPointerException();
        }
        bitField0_ |= 0x00000002;
        state_ = value.getNumber();
        onChanged();
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerStateProto state = 2;</code>
       */
      public Builder clearState() {
        bitField0_ = (bitField0_ & ~0x00000002);
        state_ = 1;
        onChanged();
        return this;
      }

      private java.lang.Object diagnostics_ = "N/A";
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public boolean hasDiagnostics() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public java.lang.String getDiagnostics() {
        java.lang.Object ref = diagnostics_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            diagnostics_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public com.google.protobuf.ByteString
          getDiagnosticsBytes() {
        java.lang.Object ref = diagnostics_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          diagnostics_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnostics(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder clearDiagnostics() {
        bitField0_ = (bitField0_ & ~0x00000004);
        diagnostics_ = getDefaultInstance().getDiagnostics();
        onChanged();
        return this;
      }
      /**
       * <code>optional string diagnostics = 3 [default = "N/A"];</code>
       */
      public Builder setDiagnosticsBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000004;
        diagnostics_ = value;
        onChanged();
        return this;
      }

      private int exitStatus_ = -1000;
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public boolean hasExitStatus() {
        return ((bitField0_ & 0x00000008) == 0x00000008);
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public int getExitStatus() {
        return exitStatus_;
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public Builder setExitStatus(int value) {
        bitField0_ |= 0x00000008;
        exitStatus_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional int32 exit_status = 4 [default = -1000];</code>
       */
      public Builder clearExitStatus() {
        bitField0_ = (bitField0_ & ~0x00000008);
        exitStatus_ = -1000;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerStatusProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerStatusProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerStatusProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerStatusProto>() {
      public ContainerStatusProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerStatusProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerStatusProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerStatusProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerStatusProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerResourceIncreaseRequestProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerResourceIncreaseRequestProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseRequestProto}
   */
  public  static final class ContainerResourceIncreaseRequestProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerResourceIncreaseRequestProto)
      ContainerResourceIncreaseRequestProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerResourceIncreaseRequestProto.newBuilder() to construct.
    private ContainerResourceIncreaseRequestProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerResourceIncreaseRequestProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceIncreaseRequestProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getCapability());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCapability());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseRequestProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerResourceIncreaseRequestProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = null;
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != null &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = null;
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getCapability(),
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceIncreaseRequestProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseRequestProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerResourceIncreaseRequestProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerResourceIncreaseRequestProto>() {
      public ContainerResourceIncreaseRequestProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerResourceIncreaseRequestProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerResourceIncreaseRequestProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceIncreaseRequestProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseRequestProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerResourceIncreaseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerResourceIncreaseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();

    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    boolean hasContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken();
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseProto}
   */
  public  static final class ContainerResourceIncreaseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerResourceIncreaseProto)
      ContainerResourceIncreaseProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerResourceIncreaseProto.newBuilder() to construct.
    private ContainerResourceIncreaseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerResourceIncreaseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceIncreaseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
            case 26: {
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000004) == 0x00000004)) {
                subBuilder = containerToken_.toBuilder();
              }
              containerToken_ = input.readMessage(org.apache.hadoop.security.proto.SecurityProtos.TokenProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerToken_);
                containerToken_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000004;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }

    public static final int CONTAINER_TOKEN_FIELD_NUMBER = 3;
    private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_;
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public boolean hasContainerToken() {
      return ((bitField0_ & 0x00000004) == 0x00000004);
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
      return containerToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
    }
    /**
     * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
     */
    public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
      return containerToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      if (hasContainerToken()) {
        if (!getContainerToken().isInitialized()) {
          memoizedIsInitialized = 0;
          return false;
        }
      }
      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getCapability());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        output.writeMessage(3, getContainerToken());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCapability());
      }
      if (((bitField0_ & 0x00000004) == 0x00000004)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(3, getContainerToken());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && (hasContainerToken() == other.hasContainerToken());
      if (hasContainerToken()) {
        result = result && getContainerToken()
            .equals(other.getContainerToken());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      if (hasContainerToken()) {
        hash = (37 * hash) + CONTAINER_TOKEN_FIELD_NUMBER;
        hash = (53 * hash) + getContainerToken().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceIncreaseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerResourceIncreaseProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
          getContainerTokenFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = null;
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        if (containerTokenBuilder_ == null) {
          containerToken_ = null;
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000004) == 0x00000004)) {
          to_bitField0_ |= 0x00000004;
        }
        if (containerTokenBuilder_ == null) {
          result.containerToken_ = containerToken_;
        } else {
          result.containerToken_ = containerTokenBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        if (other.hasContainerToken()) {
          mergeContainerToken(other.getContainerToken());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        if (hasContainerToken()) {
          if (!getContainerToken().isInitialized()) {
            return false;
          }
        }
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != null &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = null;
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getCapability(),
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }

      private org.apache.hadoop.security.proto.SecurityProtos.TokenProto containerToken_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> containerTokenBuilder_;
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public boolean hasContainerToken() {
        return ((bitField0_ & 0x00000004) == 0x00000004);
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto getContainerToken() {
        if (containerTokenBuilder_ == null) {
          return containerToken_ == null ? org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
        } else {
          return containerTokenBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder setContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerToken_ = value;
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder setContainerToken(
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder builderForValue) {
        if (containerTokenBuilder_ == null) {
          containerToken_ = builderForValue.build();
          onChanged();
        } else {
          containerTokenBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder mergeContainerToken(org.apache.hadoop.security.proto.SecurityProtos.TokenProto value) {
        if (containerTokenBuilder_ == null) {
          if (((bitField0_ & 0x00000004) == 0x00000004) &&
              containerToken_ != null &&
              containerToken_ != org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance()) {
            containerToken_ =
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.newBuilder(containerToken_).mergeFrom(value).buildPartial();
          } else {
            containerToken_ = value;
          }
          onChanged();
        } else {
          containerTokenBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000004;
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public Builder clearContainerToken() {
        if (containerTokenBuilder_ == null) {
          containerToken_ = null;
          onChanged();
        } else {
          containerTokenBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000004);
        return this;
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder getContainerTokenBuilder() {
        bitField0_ |= 0x00000004;
        onChanged();
        return getContainerTokenFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      public org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder getContainerTokenOrBuilder() {
        if (containerTokenBuilder_ != null) {
          return containerTokenBuilder_.getMessageOrBuilder();
        } else {
          return containerToken_ == null ?
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto.getDefaultInstance() : containerToken_;
        }
      }
      /**
       * <code>optional .hadoop.common.TokenProto container_token = 3;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder> 
          getContainerTokenFieldBuilder() {
        if (containerTokenBuilder_ == null) {
          containerTokenBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.security.proto.SecurityProtos.TokenProto, org.apache.hadoop.security.proto.SecurityProtos.TokenProto.Builder, org.apache.hadoop.security.proto.SecurityProtos.TokenProtoOrBuilder>(
                  getContainerToken(),
                  getParentForChildren(),
                  isClean());
          containerToken_ = null;
        }
        return containerTokenBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceIncreaseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceIncreaseProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerResourceIncreaseProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerResourceIncreaseProto>() {
      public ContainerResourceIncreaseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerResourceIncreaseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerResourceIncreaseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceIncreaseProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceIncreaseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface ContainerResourceDecreaseProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.ContainerResourceDecreaseProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    boolean hasContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId();
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder();

    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    boolean hasCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability();
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder();
  }
  /**
   * Protobuf type {@code hadoop.yarn.ContainerResourceDecreaseProto}
   */
  public  static final class ContainerResourceDecreaseProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.ContainerResourceDecreaseProto)
      ContainerResourceDecreaseProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use ContainerResourceDecreaseProto.newBuilder() to construct.
    private ContainerResourceDecreaseProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private ContainerResourceDecreaseProto() {
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private ContainerResourceDecreaseProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000001) == 0x00000001)) {
                subBuilder = containerId_.toBuilder();
              }
              containerId_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(containerId_);
                containerId_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000001;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = capability_.toBuilder();
              }
              capability_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(capability_);
                capability_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.Builder.class);
    }

    private int bitField0_;
    public static final int CONTAINER_ID_FIELD_NUMBER = 1;
    private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_;
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public boolean hasContainerId() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }
    /**
     * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
      return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
    }

    public static final int CAPABILITY_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_;
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public boolean hasCapability() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }
    /**
     * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
      return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        output.writeMessage(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getCapability());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(1, getContainerId());
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getCapability());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto other = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) obj;

      boolean result = true;
      result = result && (hasContainerId() == other.hasContainerId());
      if (hasContainerId()) {
        result = result && getContainerId()
            .equals(other.getContainerId());
      }
      result = result && (hasCapability() == other.hasCapability());
      if (hasCapability()) {
        result = result && getCapability()
            .equals(other.getCapability());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasContainerId()) {
        hash = (37 * hash) + CONTAINER_ID_FIELD_NUMBER;
        hash = (53 * hash) + getContainerId().hashCode();
      }
      if (hasCapability()) {
        hash = (37 * hash) + CAPABILITY_FIELD_NUMBER;
        hash = (53 * hash) + getCapability().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.ContainerResourceDecreaseProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.ContainerResourceDecreaseProto)
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.class, org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getContainerIdFieldBuilder();
          getCapabilityFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        if (containerIdBuilder_ == null) {
          containerId_ = null;
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        if (capabilityBuilder_ == null) {
          capability_ = null;
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto result = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        if (containerIdBuilder_ == null) {
          result.containerId_ = containerId_;
        } else {
          result.containerId_ = containerIdBuilder_.build();
        }
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (capabilityBuilder_ == null) {
          result.capability_ = capability_;
        } else {
          result.capability_ = capabilityBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto.getDefaultInstance()) return this;
        if (other.hasContainerId()) {
          mergeContainerId(other.getContainerId());
        }
        if (other.hasCapability()) {
          mergeCapability(other.getCapability());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto containerId_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> containerIdBuilder_;
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public boolean hasContainerId() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto getContainerId() {
        if (containerIdBuilder_ == null) {
          return containerId_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        } else {
          return containerIdBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          containerId_ = value;
          onChanged();
        } else {
          containerIdBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder setContainerId(
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder builderForValue) {
        if (containerIdBuilder_ == null) {
          containerId_ = builderForValue.build();
          onChanged();
        } else {
          containerIdBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder mergeContainerId(org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto value) {
        if (containerIdBuilder_ == null) {
          if (((bitField0_ & 0x00000001) == 0x00000001) &&
              containerId_ != null &&
              containerId_ != org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance()) {
            containerId_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.newBuilder(containerId_).mergeFrom(value).buildPartial();
          } else {
            containerId_ = value;
          }
          onChanged();
        } else {
          containerIdBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000001;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public Builder clearContainerId() {
        if (containerIdBuilder_ == null) {
          containerId_ = null;
          onChanged();
        } else {
          containerIdBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000001);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder getContainerIdBuilder() {
        bitField0_ |= 0x00000001;
        onChanged();
        return getContainerIdFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder getContainerIdOrBuilder() {
        if (containerIdBuilder_ != null) {
          return containerIdBuilder_.getMessageOrBuilder();
        } else {
          return containerId_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.getDefaultInstance() : containerId_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ContainerIdProto container_id = 1;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder> 
          getContainerIdFieldBuilder() {
        if (containerIdBuilder_ == null) {
          containerIdBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ContainerIdProtoOrBuilder>(
                  getContainerId(),
                  getParentForChildren(),
                  isClean());
          containerId_ = null;
        }
        return containerIdBuilder_;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto capability_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> capabilityBuilder_;
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public boolean hasCapability() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto getCapability() {
        if (capabilityBuilder_ == null) {
          return capability_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        } else {
          return capabilityBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          capability_ = value;
          onChanged();
        } else {
          capabilityBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder setCapability(
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder builderForValue) {
        if (capabilityBuilder_ == null) {
          capability_ = builderForValue.build();
          onChanged();
        } else {
          capabilityBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder mergeCapability(org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto value) {
        if (capabilityBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              capability_ != null &&
              capability_ != org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance()) {
            capability_ =
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.newBuilder(capability_).mergeFrom(value).buildPartial();
          } else {
            capability_ = value;
          }
          onChanged();
        } else {
          capabilityBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public Builder clearCapability() {
        if (capabilityBuilder_ == null) {
          capability_ = null;
          onChanged();
        } else {
          capabilityBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder getCapabilityBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getCapabilityFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder getCapabilityOrBuilder() {
        if (capabilityBuilder_ != null) {
          return capabilityBuilder_.getMessageOrBuilder();
        } else {
          return capability_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.getDefaultInstance() : capability_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.ResourceProto capability = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder> 
          getCapabilityFieldBuilder() {
        if (capabilityBuilder_ == null) {
          capabilityBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.ResourceProtoOrBuilder>(
                  getCapability(),
                  getParentForChildren(),
                  isClean());
          capability_ = null;
        }
        return capabilityBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.ContainerResourceDecreaseProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.ContainerResourceDecreaseProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<ContainerResourceDecreaseProto>
        PARSER = new com.google.protobuf.AbstractParser<ContainerResourceDecreaseProto>() {
      public ContainerResourceDecreaseProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new ContainerResourceDecreaseProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<ContainerResourceDecreaseProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<ContainerResourceDecreaseProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.ContainerResourceDecreaseProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StringLocalResourceMapProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StringLocalResourceMapProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue();
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder();
  }
  /**
   * <pre>
   *&#47;/////////////////////////////////////////////////////////////////////
   * //// From common//////////////////////////////////////////////////////
   * //////////////////////////////////////////////////////////////////////
   * </pre>
   *
   * Protobuf type {@code hadoop.yarn.StringLocalResourceMapProto}
   */
  public  static final class StringLocalResourceMapProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StringLocalResourceMapProto)
      StringLocalResourceMapProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StringLocalResourceMapProto.newBuilder() to construct.
    private StringLocalResourceMapProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StringLocalResourceMapProto() {
      key_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StringLocalResourceMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              key_ = bs;
              break;
            }
            case 18: {
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder subBuilder = null;
              if (((bitField0_ & 0x00000002) == 0x00000002)) {
                subBuilder = value_.toBuilder();
              }
              value_ = input.readMessage(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.PARSER, extensionRegistry);
              if (subBuilder != null) {
                subBuilder.mergeFrom(value_);
                value_ = subBuilder.buildPartial();
              }
              bitField0_ |= 0x00000002;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder.class);
    }

    private int bitField0_;
    public static final int KEY_FIELD_NUMBER = 1;
    private volatile java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VALUE_FIELD_NUMBER = 2;
    private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value_;
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue() {
      return value_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance() : value_;
    }
    /**
     * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
     */
    public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder() {
      return value_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance() : value_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, key_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeMessage(2, getValue());
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, key_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeMessageSize(2, getValue());
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * <pre>
     *&#47;/////////////////////////////////////////////////////////////////////
     * //// From common//////////////////////////////////////////////////////
     * //////////////////////////////////////////////////////////////////////
     * </pre>
     *
     * Protobuf type {@code hadoop.yarn.StringLocalResourceMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StringLocalResourceMapProto)
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
          getValueFieldBuilder();
        }
      }
      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        if (valueBuilder_ == null) {
          value_ = null;
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        if (valueBuilder_ == null) {
          result.value_ = value_;
        } else {
          result.value_ = valueBuilder_.build();
        }
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          mergeValue(other.getValue());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            key_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      private org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value_ = null;
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder> valueBuilder_;
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto getValue() {
        if (valueBuilder_ == null) {
          return value_ == null ? org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance() : value_;
        } else {
          return valueBuilder_.getMessage();
        }
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder setValue(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value) {
        if (valueBuilder_ == null) {
          if (value == null) {
            throw new NullPointerException();
          }
          value_ = value;
          onChanged();
        } else {
          valueBuilder_.setMessage(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder setValue(
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder builderForValue) {
        if (valueBuilder_ == null) {
          value_ = builderForValue.build();
          onChanged();
        } else {
          valueBuilder_.setMessage(builderForValue.build());
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder mergeValue(org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto value) {
        if (valueBuilder_ == null) {
          if (((bitField0_ & 0x00000002) == 0x00000002) &&
              value_ != null &&
              value_ != org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance()) {
            value_ =
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.newBuilder(value_).mergeFrom(value).buildPartial();
          } else {
            value_ = value;
          }
          onChanged();
        } else {
          valueBuilder_.mergeFrom(value);
        }
        bitField0_ |= 0x00000002;
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public Builder clearValue() {
        if (valueBuilder_ == null) {
          value_ = null;
          onChanged();
        } else {
          valueBuilder_.clear();
        }
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder getValueBuilder() {
        bitField0_ |= 0x00000002;
        onChanged();
        return getValueFieldBuilder().getBuilder();
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      public org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder getValueOrBuilder() {
        if (valueBuilder_ != null) {
          return valueBuilder_.getMessageOrBuilder();
        } else {
          return value_ == null ?
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.getDefaultInstance() : value_;
        }
      }
      /**
       * <code>optional .hadoop.yarn.LocalResourceProto value = 2;</code>
       */
      private com.google.protobuf.SingleFieldBuilderV3<
          org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder> 
          getValueFieldBuilder() {
        if (valueBuilder_ == null) {
          valueBuilder_ = new com.google.protobuf.SingleFieldBuilderV3<
              org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProto.Builder, org.apache.hadoop.yarn.proto.YarnProtos.LocalResourceProtoOrBuilder>(
                  getValue(),
                  getParentForChildren(),
                  isClean());
          value_ = null;
        }
        return valueBuilder_;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringLocalResourceMapProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringLocalResourceMapProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StringLocalResourceMapProto>
        PARSER = new com.google.protobuf.AbstractParser<StringLocalResourceMapProto>() {
      public StringLocalResourceMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StringLocalResourceMapProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StringLocalResourceMapProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StringLocalResourceMapProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.StringLocalResourceMapProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StringStringMapProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StringStringMapProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    /**
     * <code>optional string value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional string value = 2;</code>
     */
    java.lang.String getValue();
    /**
     * <code>optional string value = 2;</code>
     */
    com.google.protobuf.ByteString
        getValueBytes();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringStringMapProto}
   */
  public  static final class StringStringMapProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StringStringMapProto)
      StringStringMapProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StringStringMapProto.newBuilder() to construct.
    private StringStringMapProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StringStringMapProto() {
      key_ = "";
      value_ = "";
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StringStringMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              key_ = bs;
              break;
            }
            case 18: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000002;
              value_ = bs;
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder.class);
    }

    private int bitField0_;
    public static final int KEY_FIELD_NUMBER = 1;
    private volatile java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VALUE_FIELD_NUMBER = 2;
    private volatile java.lang.Object value_;
    /**
     * <code>optional string value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional string value = 2;</code>
     */
    public java.lang.String getValue() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          value_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string value = 2;</code>
     */
    public com.google.protobuf.ByteString
        getValueBytes() {
      java.lang.Object ref = value_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        value_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, key_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 2, value_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, key_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(2, value_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringStringMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StringStringMapProto)
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = "";
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringStringMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          bitField0_ |= 0x00000002;
          value_ = other.value_;
          onChanged();
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            key_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      private java.lang.Object value_ = "";
      /**
       * <code>optional string value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public java.lang.String getValue() {
        java.lang.Object ref = value_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            value_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public com.google.protobuf.ByteString
          getValueBytes() {
        java.lang.Object ref = value_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          value_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder setValue(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }
      /**
       * <code>optional string value = 2;</code>
       */
      public Builder setValueBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringStringMapProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringStringMapProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StringStringMapProto>
        PARSER = new com.google.protobuf.AbstractParser<StringStringMapProto>() {
      public StringStringMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StringStringMapProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StringStringMapProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StringStringMapProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.StringStringMapProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  public interface StringBytesMapProtoOrBuilder extends
      // @@protoc_insertion_point(interface_extends:hadoop.yarn.StringBytesMapProto)
      com.google.protobuf.MessageOrBuilder {

    /**
     * <code>optional string key = 1;</code>
     */
    boolean hasKey();
    /**
     * <code>optional string key = 1;</code>
     */
    java.lang.String getKey();
    /**
     * <code>optional string key = 1;</code>
     */
    com.google.protobuf.ByteString
        getKeyBytes();

    /**
     * <code>optional bytes value = 2;</code>
     */
    boolean hasValue();
    /**
     * <code>optional bytes value = 2;</code>
     */
    com.google.protobuf.ByteString getValue();
  }
  /**
   * Protobuf type {@code hadoop.yarn.StringBytesMapProto}
   */
  public  static final class StringBytesMapProto extends
      com.google.protobuf.GeneratedMessageV3 implements
      // @@protoc_insertion_point(message_implements:hadoop.yarn.StringBytesMapProto)
      StringBytesMapProtoOrBuilder {
  private static final long serialVersionUID = 0L;
    // Use StringBytesMapProto.newBuilder() to construct.
    private StringBytesMapProto(com.google.protobuf.GeneratedMessageV3.Builder<?> builder) {
      super(builder);
    }
    private StringBytesMapProto() {
      key_ = "";
      value_ = com.google.protobuf.ByteString.EMPTY;
    }

    @java.lang.Override
    public final com.google.protobuf.UnknownFieldSet
    getUnknownFields() {
      return this.unknownFields;
    }
    private StringBytesMapProto(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      this();
      int mutable_bitField0_ = 0;
      com.google.protobuf.UnknownFieldSet.Builder unknownFields =
          com.google.protobuf.UnknownFieldSet.newBuilder();
      try {
        boolean done = false;
        while (!done) {
          int tag = input.readTag();
          switch (tag) {
            case 0:
              done = true;
              break;
            default: {
              if (!parseUnknownField(
                  input, unknownFields, extensionRegistry, tag)) {
                done = true;
              }
              break;
            }
            case 10: {
              com.google.protobuf.ByteString bs = input.readBytes();
              bitField0_ |= 0x00000001;
              key_ = bs;
              break;
            }
            case 18: {
              bitField0_ |= 0x00000002;
              value_ = input.readBytes();
              break;
            }
          }
        }
      } catch (com.google.protobuf.InvalidProtocolBufferException e) {
        throw e.setUnfinishedMessage(this);
      } catch (java.io.IOException e) {
        throw new com.google.protobuf.InvalidProtocolBufferException(
            e).setUnfinishedMessage(this);
      } finally {
        this.unknownFields = unknownFields.build();
        makeExtensionsImmutable();
      }
    }
    public static final com.google.protobuf.Descriptors.Descriptor
        getDescriptor() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
    }

    protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
        internalGetFieldAccessorTable() {
      return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable
          .ensureFieldAccessorsInitialized(
              org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder.class);
    }

    private int bitField0_;
    public static final int KEY_FIELD_NUMBER = 1;
    private volatile java.lang.Object key_;
    /**
     * <code>optional string key = 1;</code>
     */
    public boolean hasKey() {
      return ((bitField0_ & 0x00000001) == 0x00000001);
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public java.lang.String getKey() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        return (java.lang.String) ref;
      } else {
        com.google.protobuf.ByteString bs = 
            (com.google.protobuf.ByteString) ref;
        java.lang.String s = bs.toStringUtf8();
        if (bs.isValidUtf8()) {
          key_ = s;
        }
        return s;
      }
    }
    /**
     * <code>optional string key = 1;</code>
     */
    public com.google.protobuf.ByteString
        getKeyBytes() {
      java.lang.Object ref = key_;
      if (ref instanceof java.lang.String) {
        com.google.protobuf.ByteString b = 
            com.google.protobuf.ByteString.copyFromUtf8(
                (java.lang.String) ref);
        key_ = b;
        return b;
      } else {
        return (com.google.protobuf.ByteString) ref;
      }
    }

    public static final int VALUE_FIELD_NUMBER = 2;
    private com.google.protobuf.ByteString value_;
    /**
     * <code>optional bytes value = 2;</code>
     */
    public boolean hasValue() {
      return ((bitField0_ & 0x00000002) == 0x00000002);
    }
    /**
     * <code>optional bytes value = 2;</code>
     */
    public com.google.protobuf.ByteString getValue() {
      return value_;
    }

    private byte memoizedIsInitialized = -1;
    public final boolean isInitialized() {
      byte isInitialized = memoizedIsInitialized;
      if (isInitialized == 1) return true;
      if (isInitialized == 0) return false;

      memoizedIsInitialized = 1;
      return true;
    }

    public void writeTo(com.google.protobuf.CodedOutputStream output)
                        throws java.io.IOException {
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        com.google.protobuf.GeneratedMessageV3.writeString(output, 1, key_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        output.writeBytes(2, value_);
      }
      unknownFields.writeTo(output);
    }

    public int getSerializedSize() {
      int size = memoizedSize;
      if (size != -1) return size;

      size = 0;
      if (((bitField0_ & 0x00000001) == 0x00000001)) {
        size += com.google.protobuf.GeneratedMessageV3.computeStringSize(1, key_);
      }
      if (((bitField0_ & 0x00000002) == 0x00000002)) {
        size += com.google.protobuf.CodedOutputStream
          .computeBytesSize(2, value_);
      }
      size += unknownFields.getSerializedSize();
      memoizedSize = size;
      return size;
    }

    @java.lang.Override
    public boolean equals(final java.lang.Object obj) {
      if (obj == this) {
       return true;
      }
      if (!(obj instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto)) {
        return super.equals(obj);
      }
      org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto other = (org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) obj;

      boolean result = true;
      result = result && (hasKey() == other.hasKey());
      if (hasKey()) {
        result = result && getKey()
            .equals(other.getKey());
      }
      result = result && (hasValue() == other.hasValue());
      if (hasValue()) {
        result = result && getValue()
            .equals(other.getValue());
      }
      result = result && unknownFields.equals(other.unknownFields);
      return result;
    }

    @java.lang.Override
    public int hashCode() {
      if (memoizedHashCode != 0) {
        return memoizedHashCode;
      }
      int hash = 41;
      hash = (19 * hash) + getDescriptor().hashCode();
      if (hasKey()) {
        hash = (37 * hash) + KEY_FIELD_NUMBER;
        hash = (53 * hash) + getKey().hashCode();
      }
      if (hasValue()) {
        hash = (37 * hash) + VALUE_FIELD_NUMBER;
        hash = (53 * hash) + getValue().hashCode();
      }
      hash = (29 * hash) + unknownFields.hashCode();
      memoizedHashCode = hash;
      return hash;
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        java.nio.ByteBuffer data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        java.nio.ByteBuffer data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.ByteString data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.ByteString data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(byte[] data)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        byte[] data,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws com.google.protobuf.InvalidProtocolBufferException {
      return PARSER.parseFrom(data, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseDelimitedFrom(java.io.InputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseDelimitedFrom(
        java.io.InputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseDelimitedWithIOException(PARSER, input, extensionRegistry);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.CodedInputStream input)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input);
    }
    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parseFrom(
        com.google.protobuf.CodedInputStream input,
        com.google.protobuf.ExtensionRegistryLite extensionRegistry)
        throws java.io.IOException {
      return com.google.protobuf.GeneratedMessageV3
          .parseWithIOException(PARSER, input, extensionRegistry);
    }

    public Builder newBuilderForType() { return newBuilder(); }
    public static Builder newBuilder() {
      return DEFAULT_INSTANCE.toBuilder();
    }
    public static Builder newBuilder(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto prototype) {
      return DEFAULT_INSTANCE.toBuilder().mergeFrom(prototype);
    }
    public Builder toBuilder() {
      return this == DEFAULT_INSTANCE
          ? new Builder() : new Builder().mergeFrom(this);
    }

    @java.lang.Override
    protected Builder newBuilderForType(
        com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
      Builder builder = new Builder(parent);
      return builder;
    }
    /**
     * Protobuf type {@code hadoop.yarn.StringBytesMapProto}
     */
    public static final class Builder extends
        com.google.protobuf.GeneratedMessageV3.Builder<Builder> implements
        // @@protoc_insertion_point(builder_implements:hadoop.yarn.StringBytesMapProto)
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProtoOrBuilder {
      public static final com.google.protobuf.Descriptors.Descriptor
          getDescriptor() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
      }

      protected com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
          internalGetFieldAccessorTable() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable
            .ensureFieldAccessorsInitialized(
                org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.class, org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.Builder.class);
      }

      // Construct using org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.newBuilder()
      private Builder() {
        maybeForceBuilderInitialization();
      }

      private Builder(
          com.google.protobuf.GeneratedMessageV3.BuilderParent parent) {
        super(parent);
        maybeForceBuilderInitialization();
      }
      private void maybeForceBuilderInitialization() {
        if (com.google.protobuf.GeneratedMessageV3
                .alwaysUseFieldBuilders) {
        }
      }
      public Builder clear() {
        super.clear();
        key_ = "";
        bitField0_ = (bitField0_ & ~0x00000001);
        value_ = com.google.protobuf.ByteString.EMPTY;
        bitField0_ = (bitField0_ & ~0x00000002);
        return this;
      }

      public com.google.protobuf.Descriptors.Descriptor
          getDescriptorForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getDefaultInstanceForType() {
        return org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance();
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto build() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto result = buildPartial();
        if (!result.isInitialized()) {
          throw newUninitializedMessageException(result);
        }
        return result;
      }

      public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto buildPartial() {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto result = new org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto(this);
        int from_bitField0_ = bitField0_;
        int to_bitField0_ = 0;
        if (((from_bitField0_ & 0x00000001) == 0x00000001)) {
          to_bitField0_ |= 0x00000001;
        }
        result.key_ = key_;
        if (((from_bitField0_ & 0x00000002) == 0x00000002)) {
          to_bitField0_ |= 0x00000002;
        }
        result.value_ = value_;
        result.bitField0_ = to_bitField0_;
        onBuilt();
        return result;
      }

      public Builder clone() {
        return (Builder) super.clone();
      }
      public Builder setField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.setField(field, value);
      }
      public Builder clearField(
          com.google.protobuf.Descriptors.FieldDescriptor field) {
        return (Builder) super.clearField(field);
      }
      public Builder clearOneof(
          com.google.protobuf.Descriptors.OneofDescriptor oneof) {
        return (Builder) super.clearOneof(oneof);
      }
      public Builder setRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          int index, java.lang.Object value) {
        return (Builder) super.setRepeatedField(field, index, value);
      }
      public Builder addRepeatedField(
          com.google.protobuf.Descriptors.FieldDescriptor field,
          java.lang.Object value) {
        return (Builder) super.addRepeatedField(field, value);
      }
      public Builder mergeFrom(com.google.protobuf.Message other) {
        if (other instanceof org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) {
          return mergeFrom((org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto)other);
        } else {
          super.mergeFrom(other);
          return this;
        }
      }

      public Builder mergeFrom(org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto other) {
        if (other == org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto.getDefaultInstance()) return this;
        if (other.hasKey()) {
          bitField0_ |= 0x00000001;
          key_ = other.key_;
          onChanged();
        }
        if (other.hasValue()) {
          setValue(other.getValue());
        }
        this.mergeUnknownFields(other.unknownFields);
        onChanged();
        return this;
      }

      public final boolean isInitialized() {
        return true;
      }

      public Builder mergeFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws java.io.IOException {
        org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto parsedMessage = null;
        try {
          parsedMessage = PARSER.parsePartialFrom(input, extensionRegistry);
        } catch (com.google.protobuf.InvalidProtocolBufferException e) {
          parsedMessage = (org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto) e.getUnfinishedMessage();
          throw e.unwrapIOException();
        } finally {
          if (parsedMessage != null) {
            mergeFrom(parsedMessage);
          }
        }
        return this;
      }
      private int bitField0_;

      private java.lang.Object key_ = "";
      /**
       * <code>optional string key = 1;</code>
       */
      public boolean hasKey() {
        return ((bitField0_ & 0x00000001) == 0x00000001);
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public java.lang.String getKey() {
        java.lang.Object ref = key_;
        if (!(ref instanceof java.lang.String)) {
          com.google.protobuf.ByteString bs =
              (com.google.protobuf.ByteString) ref;
          java.lang.String s = bs.toStringUtf8();
          if (bs.isValidUtf8()) {
            key_ = s;
          }
          return s;
        } else {
          return (java.lang.String) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public com.google.protobuf.ByteString
          getKeyBytes() {
        java.lang.Object ref = key_;
        if (ref instanceof String) {
          com.google.protobuf.ByteString b = 
              com.google.protobuf.ByteString.copyFromUtf8(
                  (java.lang.String) ref);
          key_ = b;
          return b;
        } else {
          return (com.google.protobuf.ByteString) ref;
        }
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKey(
          java.lang.String value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder clearKey() {
        bitField0_ = (bitField0_ & ~0x00000001);
        key_ = getDefaultInstance().getKey();
        onChanged();
        return this;
      }
      /**
       * <code>optional string key = 1;</code>
       */
      public Builder setKeyBytes(
          com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000001;
        key_ = value;
        onChanged();
        return this;
      }

      private com.google.protobuf.ByteString value_ = com.google.protobuf.ByteString.EMPTY;
      /**
       * <code>optional bytes value = 2;</code>
       */
      public boolean hasValue() {
        return ((bitField0_ & 0x00000002) == 0x00000002);
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public com.google.protobuf.ByteString getValue() {
        return value_;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder setValue(com.google.protobuf.ByteString value) {
        if (value == null) {
    throw new NullPointerException();
  }
  bitField0_ |= 0x00000002;
        value_ = value;
        onChanged();
        return this;
      }
      /**
       * <code>optional bytes value = 2;</code>
       */
      public Builder clearValue() {
        bitField0_ = (bitField0_ & ~0x00000002);
        value_ = getDefaultInstance().getValue();
        onChanged();
        return this;
      }
      public final Builder setUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.setUnknownFields(unknownFields);
      }

      public final Builder mergeUnknownFields(
          final com.google.protobuf.UnknownFieldSet unknownFields) {
        return super.mergeUnknownFields(unknownFields);
      }


      // @@protoc_insertion_point(builder_scope:hadoop.yarn.StringBytesMapProto)
    }

    // @@protoc_insertion_point(class_scope:hadoop.yarn.StringBytesMapProto)
    private static final org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto DEFAULT_INSTANCE;
    static {
      DEFAULT_INSTANCE = new org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto();
    }

    public static org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getDefaultInstance() {
      return DEFAULT_INSTANCE;
    }

    @java.lang.Deprecated public static final com.google.protobuf.Parser<StringBytesMapProto>
        PARSER = new com.google.protobuf.AbstractParser<StringBytesMapProto>() {
      public StringBytesMapProto parsePartialFrom(
          com.google.protobuf.CodedInputStream input,
          com.google.protobuf.ExtensionRegistryLite extensionRegistry)
          throws com.google.protobuf.InvalidProtocolBufferException {
          return new StringBytesMapProto(input, extensionRegistry);
      }
    };

    public static com.google.protobuf.Parser<StringBytesMapProto> parser() {
      return PARSER;
    }

    @java.lang.Override
    public com.google.protobuf.Parser<StringBytesMapProto> getParserForType() {
      return PARSER;
    }

    public org.apache.hadoop.yarn.proto.YarnProtos.StringBytesMapProto getDefaultInstanceForType() {
      return DEFAULT_INSTANCE;
    }

  }

  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_SerializedExceptionProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationIdProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerIdProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceOptionProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeResourceMapProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PriorityProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerReportProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_URLProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_URLProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_LocalResourceProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationReportProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeIdProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeReportProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionMessageProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionContractProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionContainerProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_LogAggregationContextProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueInfoProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationIdProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationRequestsProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerStatusProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringStringMapProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable;
  private static final com.google.protobuf.Descriptors.Descriptor
    internal_static_hadoop_yarn_StringBytesMapProto_descriptor;
  private static final 
    com.google.protobuf.GeneratedMessageV3.FieldAccessorTable
      internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable;

  public static com.google.protobuf.Descriptors.FileDescriptor
      getDescriptor() {
    return descriptor;
  }
  private static  com.google.protobuf.Descriptors.FileDescriptor
      descriptor;
  static {
    java.lang.String[] descriptorData = {
      "\n\021yarn_protos.proto\022\013hadoop.yarn\032\016Securi" +
      "ty.proto\"\204\001\n\030SerializedExceptionProto\022\017\n" +
      "\007message\030\001 \001(\t\022\r\n\005trace\030\002 \001(\t\022\022\n\nclass_n" +
      "ame\030\003 \001(\t\0224\n\005cause\030\004 \001(\0132%.hadoop.yarn.S" +
      "erializedExceptionProto\";\n\022ApplicationId" +
      "Proto\022\n\n\002id\030\001 \001(\005\022\031\n\021cluster_timestamp\030\002" +
      " \001(\003\"g\n\031ApplicationAttemptIdProto\0227\n\016app" +
      "lication_id\030\001 \001(\0132\037.hadoop.yarn.Applicat" +
      "ionIdProto\022\021\n\tattemptId\030\002 \001(\005\"\217\001\n\020Contai" +
      "nerIdProto\022/\n\006app_id\030\001 \001(\0132\037.hadoop.yarn",
      ".ApplicationIdProto\022>\n\016app_attempt_id\030\002 " +
      "\001(\0132&.hadoop.yarn.ApplicationAttemptIdPr" +
      "oto\022\n\n\002id\030\003 \001(\003\"6\n\rResourceProto\022\016\n\006memo" +
      "ry\030\001 \001(\005\022\025\n\rvirtual_cores\030\002 \001(\005\"`\n\023Resou" +
      "rceOptionProto\022,\n\010resource\030\001 \001(\0132\032.hadoo" +
      "p.yarn.ResourceProto\022\033\n\023over_commit_time" +
      "out\030\002 \001(\005\"|\n\024NodeResourceMapProto\022)\n\007nod" +
      "e_id\030\001 \001(\0132\030.hadoop.yarn.NodeIdProto\0229\n\017" +
      "resource_option\030\002 \001(\0132 .hadoop.yarn.Reso" +
      "urceOptionProto\"!\n\rPriorityProto\022\020\n\010prio",
      "rity\030\001 \001(\005\"\220\002\n\016ContainerProto\022)\n\002id\030\001 \001(" +
      "\0132\035.hadoop.yarn.ContainerIdProto\022(\n\006node" +
      "Id\030\002 \001(\0132\030.hadoop.yarn.NodeIdProto\022\031\n\021no" +
      "de_http_address\030\003 \001(\t\022,\n\010resource\030\004 \001(\0132" +
      "\032.hadoop.yarn.ResourceProto\022,\n\010priority\030" +
      "\005 \001(\0132\032.hadoop.yarn.PriorityProto\0222\n\017con" +
      "tainer_token\030\006 \001(\0132\031.hadoop.common.Token" +
      "Proto\"\210\003\n\024ContainerReportProto\0223\n\014contai" +
      "ner_id\030\001 \001(\0132\035.hadoop.yarn.ContainerIdPr" +
      "oto\022,\n\010resource\030\002 \001(\0132\032.hadoop.yarn.Reso",
      "urceProto\022)\n\007node_id\030\003 \001(\0132\030.hadoop.yarn" +
      ".NodeIdProto\022,\n\010priority\030\004 \001(\0132\032.hadoop." +
      "yarn.PriorityProto\022\025\n\rcreation_time\030\005 \001(" +
      "\003\022\023\n\013finish_time\030\006 \001(\003\022\035\n\020diagnostics_in" +
      "fo\030\007 \001(\t:\003N/A\022\017\n\007log_url\030\010 \001(\t\022\035\n\025contai" +
      "ner_exit_status\030\t \001(\005\0229\n\017container_state" +
      "\030\n \001(\0162 .hadoop.yarn.ContainerStateProto" +
      "\"V\n\010URLProto\022\016\n\006scheme\030\001 \001(\t\022\014\n\004host\030\002 \001" +
      "(\t\022\014\n\004port\030\003 \001(\005\022\014\n\004file\030\004 \001(\t\022\020\n\010userIn" +
      "fo\030\005 \001(\t\"\341\001\n\022LocalResourceProto\022\'\n\010resou",
      "rce\030\001 \001(\0132\025.hadoop.yarn.URLProto\022\014\n\004size" +
      "\030\002 \001(\003\022\021\n\ttimestamp\030\003 \001(\003\0221\n\004type\030\004 \001(\0162" +
      "#.hadoop.yarn.LocalResourceTypeProto\022=\n\n" +
      "visibility\030\005 \001(\0162).hadoop.yarn.LocalReso" +
      "urceVisibilityProto\022\017\n\007pattern\030\006 \001(\t\"\264\002\n" +
      "#ApplicationResourceUsageReportProto\022\033\n\023" +
      "num_used_containers\030\001 \001(\005\022\037\n\027num_reserve" +
      "d_containers\030\002 \001(\005\0222\n\016used_resources\030\003 \001" +
      "(\0132\032.hadoop.yarn.ResourceProto\0226\n\022reserv" +
      "ed_resources\030\004 \001(\0132\032.hadoop.yarn.Resourc",
      "eProto\0224\n\020needed_resources\030\005 \001(\0132\032.hadoo" +
      "p.yarn.ResourceProto\022\026\n\016memory_seconds\030\006" +
      " \001(\003\022\025\n\rvcore_seconds\030\007 \001(\003\"\350\005\n\026Applicat" +
      "ionReportProto\0226\n\rapplicationId\030\001 \001(\0132\037." +
      "hadoop.yarn.ApplicationIdProto\022\014\n\004user\030\002" +
      " \001(\t\022\r\n\005queue\030\003 \001(\t\022\014\n\004name\030\004 \001(\t\022\014\n\004hos" +
      "t\030\005 \001(\t\022\020\n\010rpc_port\030\006 \001(\005\0225\n\022client_to_a" +
      "m_token\030\007 \001(\0132\031.hadoop.common.TokenProto" +
      "\022F\n\026yarn_application_state\030\010 \001(\0162&.hadoo" +
      "p.yarn.YarnApplicationStateProto\022\023\n\013trac",
      "kingUrl\030\t \001(\t\022\030\n\013diagnostics\030\n \001(\t:\003N/A\022" +
      "\021\n\tstartTime\030\013 \001(\003\022\022\n\nfinishTime\030\014 \001(\003\022J" +
      "\n\030final_application_status\030\r \001(\0162(.hadoo" +
      "p.yarn.FinalApplicationStatusProto\022L\n\022ap" +
      "p_resource_Usage\030\016 \001(\01320.hadoop.yarn.App" +
      "licationResourceUsageReportProto\022\033\n\023orig" +
      "inalTrackingUrl\030\017 \001(\t\022K\n\033currentApplicat" +
      "ionAttemptId\030\020 \001(\0132&.hadoop.yarn.Applica" +
      "tionAttemptIdProto\022\020\n\010progress\030\021 \001(\002\022\027\n\017" +
      "applicationType\030\022 \001(\t\022.\n\013am_rm_token\030\023 \001",
      "(\0132\031.hadoop.common.TokenProto\022\027\n\017applica" +
      "tionTags\030\024 \003(\t\"\345\002\n\035ApplicationAttemptRep" +
      "ortProto\022F\n\026application_attempt_id\030\001 \001(\013" +
      "2&.hadoop.yarn.ApplicationAttemptIdProto" +
      "\022\014\n\004host\030\002 \001(\t\022\020\n\010rpc_port\030\003 \001(\005\022\024\n\014trac" +
      "king_url\030\004 \001(\t\022\030\n\013diagnostics\030\005 \001(\t:\003N/A" +
      "\022U\n\036yarn_application_attempt_state\030\006 \001(\016" +
      "2-.hadoop.yarn.YarnApplicationAttemptSta" +
      "teProto\0226\n\017am_container_id\030\007 \001(\0132\035.hadoo" +
      "p.yarn.ContainerIdProto\022\035\n\025original_trac",
      "king_url\030\010 \001(\t\")\n\013NodeIdProto\022\014\n\004host\030\001 " +
      "\001(\t\022\014\n\004port\030\002 \001(\005\"\321\002\n\017NodeReportProto\022(\n" +
      "\006nodeId\030\001 \001(\0132\030.hadoop.yarn.NodeIdProto\022" +
      "\023\n\013httpAddress\030\002 \001(\t\022\020\n\010rackName\030\003 \001(\t\022(" +
      "\n\004used\030\004 \001(\0132\032.hadoop.yarn.ResourceProto" +
      "\022.\n\ncapability\030\005 \001(\0132\032.hadoop.yarn.Resou" +
      "rceProto\022\025\n\rnumContainers\030\006 \001(\005\022/\n\nnode_" +
      "state\030\007 \001(\0162\033.hadoop.yarn.NodeStateProto" +
      "\022\025\n\rhealth_report\030\010 \001(\t\022\037\n\027last_health_r" +
      "eport_time\030\t \001(\003\022\023\n\013node_labels\030\n \003(\t\"S\n",
      "\023NodeIdToLabelsProto\022(\n\006nodeId\030\001 \001(\0132\030.h" +
      "adoop.yarn.NodeIdProto\022\022\n\nnodeLabels\030\002 \003" +
      "(\t\"\340\001\n\024ResourceRequestProto\022,\n\010priority\030" +
      "\001 \001(\0132\032.hadoop.yarn.PriorityProto\022\025\n\rres" +
      "ource_name\030\002 \001(\t\022.\n\ncapability\030\003 \001(\0132\032.h" +
      "adoop.yarn.ResourceProto\022\026\n\016num_containe" +
      "rs\030\004 \001(\005\022\034\n\016relax_locality\030\005 \001(\010:\004true\022\035" +
      "\n\025node_label_expression\030\006 \001(\t\"\224\001\n\026Preemp" +
      "tionMessageProto\022B\n\016strictContract\030\001 \001(\013" +
      "2*.hadoop.yarn.StrictPreemptionContractP",
      "roto\0226\n\010contract\030\002 \001(\0132$.hadoop.yarn.Pre" +
      "emptionContractProto\"Y\n\035StrictPreemption" +
      "ContractProto\0228\n\tcontainer\030\001 \003(\0132%.hadoo" +
      "p.yarn.PreemptionContainerProto\"\222\001\n\027Pree" +
      "mptionContractProto\022=\n\010resource\030\001 \003(\0132+." +
      "hadoop.yarn.PreemptionResourceRequestPro" +
      "to\0228\n\tcontainer\030\002 \003(\0132%.hadoop.yarn.Pree" +
      "mptionContainerProto\"E\n\030PreemptionContai" +
      "nerProto\022)\n\002id\030\001 \001(\0132\035.hadoop.yarn.Conta" +
      "inerIdProto\"U\n\036PreemptionResourceRequest",
      "Proto\0223\n\010resource\030\001 \001(\0132!.hadoop.yarn.Re" +
      "sourceRequestProto\"X\n\035ResourceBlacklistR" +
      "equestProto\022\033\n\023blacklist_additions\030\001 \003(\t" +
      "\022\032\n\022blacklist_removals\030\002 \003(\t\"\247\006\n!Applica" +
      "tionSubmissionContextProto\0227\n\016applicatio" +
      "n_id\030\001 \001(\0132\037.hadoop.yarn.ApplicationIdPr" +
      "oto\022\035\n\020application_name\030\002 \001(\t:\003N/A\022\026\n\005qu" +
      "eue\030\003 \001(\t:\007default\022,\n\010priority\030\004 \001(\0132\032.h" +
      "adoop.yarn.PriorityProto\022C\n\021am_container" +
      "_spec\030\005 \001(\0132(.hadoop.yarn.ContainerLaunc",
      "hContextProto\022)\n\033cancel_tokens_when_comp" +
      "lete\030\006 \001(\010:\004true\022\033\n\014unmanaged_am\030\007 \001(\010:\005" +
      "false\022\031\n\016maxAppAttempts\030\010 \001(\005:\0010\022,\n\010reso" +
      "urce\030\t \001(\0132\032.hadoop.yarn.ResourceProto\022\035" +
      "\n\017applicationType\030\n \001(\t:\004YARN\022:\n+keep_co" +
      "ntainers_across_application_attempts\030\013 \001" +
      "(\010:\005false\022\027\n\017applicationTags\030\014 \003(\t\022.\n\"at" +
      "tempt_failures_validity_interval\030\r \001(\003:\002" +
      "-1\022H\n\027log_aggregation_context\030\016 \001(\0132\'.ha" +
      "doop.yarn.LogAggregationContextProto\0227\n\016",
      "reservation_id\030\017 \001(\0132\037.hadoop.yarn.Reser" +
      "vationIdProto\022\035\n\025node_label_expression\030\020" +
      " \001(\t\022H\n\035am_container_resource_request\030\021 " +
      "\001(\0132!.hadoop.yarn.ResourceRequestProto\"T" +
      "\n\032LogAggregationContextProto\022\033\n\017include_" +
      "pattern\030\001 \001(\t:\002.*\022\031\n\017exclude_pattern\030\002 \001" +
      "(\t:\000\"e\n\026ApplicationACLMapProto\022;\n\naccess" +
      "Type\030\001 \001(\0162\'.hadoop.yarn.ApplicationAcce" +
      "ssTypeProto\022\016\n\003acl\030\002 \001(\t:\001 \"4\n\027YarnClust" +
      "erMetricsProto\022\031\n\021num_node_managers\030\001 \001(",
      "\005\"\303\002\n\016QueueInfoProto\022\021\n\tqueueName\030\001 \001(\t\022" +
      "\020\n\010capacity\030\002 \001(\002\022\027\n\017maximumCapacity\030\003 \001" +
      "(\002\022\027\n\017currentCapacity\030\004 \001(\002\022+\n\005state\030\005 \001" +
      "(\0162\034.hadoop.yarn.QueueStateProto\0220\n\013chil" +
      "dQueues\030\006 \003(\0132\033.hadoop.yarn.QueueInfoPro" +
      "to\0229\n\014applications\030\007 \003(\0132#.hadoop.yarn.A" +
      "pplicationReportProto\022\034\n\024accessibleNodeL" +
      "abels\030\010 \003(\t\022\"\n\032defaultNodeLabelExpressio" +
      "n\030\t \001(\t\"X\n\025QueueUserACLInfoProto\022\021\n\tqueu" +
      "eName\030\001 \001(\t\022,\n\010userAcls\030\002 \003(\0162\032.hadoop.y",
      "arn.QueueACLProto\";\n\022ReservationIdProto\022" +
      "\n\n\002id\030\001 \001(\003\022\031\n\021cluster_timestamp\030\002 \001(\003\"\222" +
      "\001\n\027ReservationRequestProto\022.\n\ncapability" +
      "\030\001 \001(\0132\032.hadoop.yarn.ResourceProto\022\031\n\016nu" +
      "m_containers\030\002 \001(\005:\0011\022\026\n\013concurrency\030\003 \001" +
      "(\005:\0011\022\024\n\010duration\030\004 \001(\003:\002-1\"\254\001\n\030Reservat" +
      "ionRequestsProto\022C\n\025reservation_resource" +
      "s\030\001 \003(\0132$.hadoop.yarn.ReservationRequest" +
      "Proto\022K\n\013interpreter\030\002 \001(\0162/.hadoop.yarn" +
      ".ReservationRequestInterpreterProto:\005R_A",
      "LL\"\236\001\n\032ReservationDefinitionProto\022C\n\024res" +
      "ervation_requests\030\001 \001(\0132%.hadoop.yarn.Re" +
      "servationRequestsProto\022\017\n\007arrival\030\002 \001(\003\022" +
      "\020\n\010deadline\030\003 \001(\003\022\030\n\020reservation_name\030\004 " +
      "\001(\t\"\257\002\n\033ContainerLaunchContextProto\022@\n\016l" +
      "ocalResources\030\001 \003(\0132(.hadoop.yarn.String" +
      "LocalResourceMapProto\022\016\n\006tokens\030\002 \001(\014\0226\n" +
      "\014service_data\030\003 \003(\0132 .hadoop.yarn.String" +
      "BytesMapProto\0226\n\013environment\030\004 \003(\0132!.had" +
      "oop.yarn.StringStringMapProto\022\017\n\007command",
      "\030\005 \003(\t\022=\n\020application_ACLs\030\006 \003(\0132#.hadoo" +
      "p.yarn.ApplicationACLMapProto\"\262\001\n\024Contai" +
      "nerStatusProto\0223\n\014container_id\030\001 \001(\0132\035.h" +
      "adoop.yarn.ContainerIdProto\022/\n\005state\030\002 \001" +
      "(\0162 .hadoop.yarn.ContainerStateProto\022\030\n\013" +
      "diagnostics\030\003 \001(\t:\003N/A\022\032\n\013exit_status\030\004 " +
      "\001(\005:\005-1000\"\214\001\n%ContainerResourceIncrease" +
      "RequestProto\0223\n\014container_id\030\001 \001(\0132\035.had" +
      "oop.yarn.ContainerIdProto\022.\n\ncapability\030" +
      "\002 \001(\0132\032.hadoop.yarn.ResourceProto\"\271\001\n\036Co",
      "ntainerResourceIncreaseProto\0223\n\014containe" +
      "r_id\030\001 \001(\0132\035.hadoop.yarn.ContainerIdProt" +
      "o\022.\n\ncapability\030\002 \001(\0132\032.hadoop.yarn.Reso" +
      "urceProto\0222\n\017container_token\030\003 \001(\0132\031.had" +
      "oop.common.TokenProto\"\205\001\n\036ContainerResou" +
      "rceDecreaseProto\0223\n\014container_id\030\001 \001(\0132\035" +
      ".hadoop.yarn.ContainerIdProto\022.\n\ncapabil" +
      "ity\030\002 \001(\0132\032.hadoop.yarn.ResourceProto\"Z\n" +
      "\033StringLocalResourceMapProto\022\013\n\003key\030\001 \001(" +
      "\t\022.\n\005value\030\002 \001(\0132\037.hadoop.yarn.LocalReso",
      "urceProto\"2\n\024StringStringMapProto\022\013\n\003key" +
      "\030\001 \001(\t\022\r\n\005value\030\002 \001(\t\"1\n\023StringBytesMapP" +
      "roto\022\013\n\003key\030\001 \001(\t\022\r\n\005value\030\002 \001(\014*?\n\023Cont" +
      "ainerStateProto\022\t\n\005C_NEW\020\001\022\r\n\tC_RUNNING\020" +
      "\002\022\016\n\nC_COMPLETE\020\003*\204\001\n\031YarnApplicationSta" +
      "teProto\022\007\n\003NEW\020\001\022\016\n\nNEW_SAVING\020\002\022\r\n\tSUBM" +
      "ITTED\020\003\022\014\n\010ACCEPTED\020\004\022\013\n\007RUNNING\020\005\022\014\n\010FI" +
      "NISHED\020\006\022\n\n\006FAILED\020\007\022\n\n\006KILLED\020\010*\302\002\n Yar" +
      "nApplicationAttemptStateProto\022\023\n\017APP_ATT" +
      "EMPT_NEW\020\001\022\031\n\025APP_ATTEMPT_SUBMITTED\020\002\022\031\n",
      "\025APP_ATTEMPT_SCHEDULED\020\003\022 \n\034APP_ATTEMPT_" +
      "ALLOCATED_SAVING\020\004\022\031\n\025APP_ATTEMPT_ALLOCA" +
      "TED\020\005\022\030\n\024APP_ATTEMPT_LAUNCHED\020\006\022\026\n\022APP_A" +
      "TTEMPT_FAILED\020\007\022\027\n\023APP_ATTEMPT_RUNNING\020\010" +
      "\022\031\n\025APP_ATTEMPT_FINISHING\020\t\022\030\n\024APP_ATTEM" +
      "PT_FINISHED\020\n\022\026\n\022APP_ATTEMPT_KILLED\020\013*c\n" +
      "\033FinalApplicationStatusProto\022\021\n\rAPP_UNDE" +
      "FINED\020\000\022\021\n\rAPP_SUCCEEDED\020\001\022\016\n\nAPP_FAILED" +
      "\020\002\022\016\n\nAPP_KILLED\020\003*H\n\034LocalResourceVisib" +
      "ilityProto\022\n\n\006PUBLIC\020\001\022\013\n\007PRIVATE\020\002\022\017\n\013A",
      "PPLICATION\020\003*<\n\026LocalResourceTypeProto\022\013" +
      "\n\007ARCHIVE\020\001\022\010\n\004FILE\020\002\022\013\n\007PATTERN\020\003*s\n\016No" +
      "deStateProto\022\n\n\006NS_NEW\020\001\022\016\n\nNS_RUNNING\020\002" +
      "\022\020\n\014NS_UNHEALTHY\020\003\022\025\n\021NS_DECOMMISSIONED\020" +
      "\004\022\013\n\007NS_LOST\020\005\022\017\n\013NS_REBOOTED\020\006*0\n\016AMCom" +
      "mandProto\022\r\n\tAM_RESYNC\020\001\022\017\n\013AM_SHUTDOWN\020" +
      "\002*N\n\032ApplicationAccessTypeProto\022\026\n\022APPAC" +
      "CESS_VIEW_APP\020\001\022\030\n\024APPACCESS_MODIFY_APP\020" +
      "\002*/\n\017QueueStateProto\022\r\n\tQ_STOPPED\020\001\022\r\n\tQ" +
      "_RUNNING\020\002*H\n\rQueueACLProto\022\034\n\030QACL_SUBM",
      "IT_APPLICATIONS\020\001\022\031\n\025QACL_ADMINISTER_QUE" +
      "UE\020\002*[\n\"ReservationRequestInterpreterPro" +
      "to\022\t\n\005R_ANY\020\000\022\t\n\005R_ALL\020\001\022\013\n\007R_ORDER\020\002\022\022\n" +
      "\016R_ORDER_NO_GAP\020\003*n\n\030ContainerExitStatus" +
      "Proto\022\013\n\007SUCCESS\020\000\022\024\n\007INVALID\020\230\370\377\377\377\377\377\377\377\001" +
      "\022\024\n\007ABORTED\020\234\377\377\377\377\377\377\377\377\001\022\031\n\014DISKS_FAILED\020\233" +
      "\377\377\377\377\377\377\377\377\001B0\n\034org.apache.hadoop.yarn.prot" +
      "oB\nYarnProtos\210\001\001\240\001\001"
    };
    com.google.protobuf.Descriptors.FileDescriptor.InternalDescriptorAssigner assigner =
        new com.google.protobuf.Descriptors.FileDescriptor.    InternalDescriptorAssigner() {
          public com.google.protobuf.ExtensionRegistry assignDescriptors(
              com.google.protobuf.Descriptors.FileDescriptor root) {
            descriptor = root;
            return null;
          }
        };
    com.google.protobuf.Descriptors.FileDescriptor
      .internalBuildGeneratedFileFrom(descriptorData,
        new com.google.protobuf.Descriptors.FileDescriptor[] {
          org.apache.hadoop.security.proto.SecurityProtos.getDescriptor(),
        }, assigner);
    internal_static_hadoop_yarn_SerializedExceptionProto_descriptor =
      getDescriptor().getMessageTypes().get(0);
    internal_static_hadoop_yarn_SerializedExceptionProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_SerializedExceptionProto_descriptor,
        new java.lang.String[] { "Message", "Trace", "ClassName", "Cause", });
    internal_static_hadoop_yarn_ApplicationIdProto_descriptor =
      getDescriptor().getMessageTypes().get(1);
    internal_static_hadoop_yarn_ApplicationIdProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ApplicationIdProto_descriptor,
        new java.lang.String[] { "Id", "ClusterTimestamp", });
    internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor =
      getDescriptor().getMessageTypes().get(2);
    internal_static_hadoop_yarn_ApplicationAttemptIdProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ApplicationAttemptIdProto_descriptor,
        new java.lang.String[] { "ApplicationId", "AttemptId", });
    internal_static_hadoop_yarn_ContainerIdProto_descriptor =
      getDescriptor().getMessageTypes().get(3);
    internal_static_hadoop_yarn_ContainerIdProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerIdProto_descriptor,
        new java.lang.String[] { "AppId", "AppAttemptId", "Id", });
    internal_static_hadoop_yarn_ResourceProto_descriptor =
      getDescriptor().getMessageTypes().get(4);
    internal_static_hadoop_yarn_ResourceProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ResourceProto_descriptor,
        new java.lang.String[] { "Memory", "VirtualCores", });
    internal_static_hadoop_yarn_ResourceOptionProto_descriptor =
      getDescriptor().getMessageTypes().get(5);
    internal_static_hadoop_yarn_ResourceOptionProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ResourceOptionProto_descriptor,
        new java.lang.String[] { "Resource", "OverCommitTimeout", });
    internal_static_hadoop_yarn_NodeResourceMapProto_descriptor =
      getDescriptor().getMessageTypes().get(6);
    internal_static_hadoop_yarn_NodeResourceMapProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_NodeResourceMapProto_descriptor,
        new java.lang.String[] { "NodeId", "ResourceOption", });
    internal_static_hadoop_yarn_PriorityProto_descriptor =
      getDescriptor().getMessageTypes().get(7);
    internal_static_hadoop_yarn_PriorityProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_PriorityProto_descriptor,
        new java.lang.String[] { "Priority", });
    internal_static_hadoop_yarn_ContainerProto_descriptor =
      getDescriptor().getMessageTypes().get(8);
    internal_static_hadoop_yarn_ContainerProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerProto_descriptor,
        new java.lang.String[] { "Id", "NodeId", "NodeHttpAddress", "Resource", "Priority", "ContainerToken", });
    internal_static_hadoop_yarn_ContainerReportProto_descriptor =
      getDescriptor().getMessageTypes().get(9);
    internal_static_hadoop_yarn_ContainerReportProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerReportProto_descriptor,
        new java.lang.String[] { "ContainerId", "Resource", "NodeId", "Priority", "CreationTime", "FinishTime", "DiagnosticsInfo", "LogUrl", "ContainerExitStatus", "ContainerState", });
    internal_static_hadoop_yarn_URLProto_descriptor =
      getDescriptor().getMessageTypes().get(10);
    internal_static_hadoop_yarn_URLProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_URLProto_descriptor,
        new java.lang.String[] { "Scheme", "Host", "Port", "File", "UserInfo", });
    internal_static_hadoop_yarn_LocalResourceProto_descriptor =
      getDescriptor().getMessageTypes().get(11);
    internal_static_hadoop_yarn_LocalResourceProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_LocalResourceProto_descriptor,
        new java.lang.String[] { "Resource", "Size", "Timestamp", "Type", "Visibility", "Pattern", });
    internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor =
      getDescriptor().getMessageTypes().get(12);
    internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ApplicationResourceUsageReportProto_descriptor,
        new java.lang.String[] { "NumUsedContainers", "NumReservedContainers", "UsedResources", "ReservedResources", "NeededResources", "MemorySeconds", "VcoreSeconds", });
    internal_static_hadoop_yarn_ApplicationReportProto_descriptor =
      getDescriptor().getMessageTypes().get(13);
    internal_static_hadoop_yarn_ApplicationReportProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ApplicationReportProto_descriptor,
        new java.lang.String[] { "ApplicationId", "User", "Queue", "Name", "Host", "RpcPort", "ClientToAmToken", "YarnApplicationState", "TrackingUrl", "Diagnostics", "StartTime", "FinishTime", "FinalApplicationStatus", "AppResourceUsage", "OriginalTrackingUrl", "CurrentApplicationAttemptId", "Progress", "ApplicationType", "AmRmToken", "ApplicationTags", });
    internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor =
      getDescriptor().getMessageTypes().get(14);
    internal_static_hadoop_yarn_ApplicationAttemptReportProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ApplicationAttemptReportProto_descriptor,
        new java.lang.String[] { "ApplicationAttemptId", "Host", "RpcPort", "TrackingUrl", "Diagnostics", "YarnApplicationAttemptState", "AmContainerId", "OriginalTrackingUrl", });
    internal_static_hadoop_yarn_NodeIdProto_descriptor =
      getDescriptor().getMessageTypes().get(15);
    internal_static_hadoop_yarn_NodeIdProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_NodeIdProto_descriptor,
        new java.lang.String[] { "Host", "Port", });
    internal_static_hadoop_yarn_NodeReportProto_descriptor =
      getDescriptor().getMessageTypes().get(16);
    internal_static_hadoop_yarn_NodeReportProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_NodeReportProto_descriptor,
        new java.lang.String[] { "NodeId", "HttpAddress", "RackName", "Used", "Capability", "NumContainers", "NodeState", "HealthReport", "LastHealthReportTime", "NodeLabels", });
    internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor =
      getDescriptor().getMessageTypes().get(17);
    internal_static_hadoop_yarn_NodeIdToLabelsProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_NodeIdToLabelsProto_descriptor,
        new java.lang.String[] { "NodeId", "NodeLabels", });
    internal_static_hadoop_yarn_ResourceRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(18);
    internal_static_hadoop_yarn_ResourceRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ResourceRequestProto_descriptor,
        new java.lang.String[] { "Priority", "ResourceName", "Capability", "NumContainers", "RelaxLocality", "NodeLabelExpression", });
    internal_static_hadoop_yarn_PreemptionMessageProto_descriptor =
      getDescriptor().getMessageTypes().get(19);
    internal_static_hadoop_yarn_PreemptionMessageProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_PreemptionMessageProto_descriptor,
        new java.lang.String[] { "StrictContract", "Contract", });
    internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor =
      getDescriptor().getMessageTypes().get(20);
    internal_static_hadoop_yarn_StrictPreemptionContractProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StrictPreemptionContractProto_descriptor,
        new java.lang.String[] { "Container", });
    internal_static_hadoop_yarn_PreemptionContractProto_descriptor =
      getDescriptor().getMessageTypes().get(21);
    internal_static_hadoop_yarn_PreemptionContractProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_PreemptionContractProto_descriptor,
        new java.lang.String[] { "Resource", "Container", });
    internal_static_hadoop_yarn_PreemptionContainerProto_descriptor =
      getDescriptor().getMessageTypes().get(22);
    internal_static_hadoop_yarn_PreemptionContainerProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_PreemptionContainerProto_descriptor,
        new java.lang.String[] { "Id", });
    internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(23);
    internal_static_hadoop_yarn_PreemptionResourceRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_PreemptionResourceRequestProto_descriptor,
        new java.lang.String[] { "Resource", });
    internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(24);
    internal_static_hadoop_yarn_ResourceBlacklistRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ResourceBlacklistRequestProto_descriptor,
        new java.lang.String[] { "BlacklistAdditions", "BlacklistRemovals", });
    internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor =
      getDescriptor().getMessageTypes().get(25);
    internal_static_hadoop_yarn_ApplicationSubmissionContextProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ApplicationSubmissionContextProto_descriptor,
        new java.lang.String[] { "ApplicationId", "ApplicationName", "Queue", "Priority", "AmContainerSpec", "CancelTokensWhenComplete", "UnmanagedAm", "MaxAppAttempts", "Resource", "ApplicationType", "KeepContainersAcrossApplicationAttempts", "ApplicationTags", "AttemptFailuresValidityInterval", "LogAggregationContext", "ReservationId", "NodeLabelExpression", "AmContainerResourceRequest", });
    internal_static_hadoop_yarn_LogAggregationContextProto_descriptor =
      getDescriptor().getMessageTypes().get(26);
    internal_static_hadoop_yarn_LogAggregationContextProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_LogAggregationContextProto_descriptor,
        new java.lang.String[] { "IncludePattern", "ExcludePattern", });
    internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor =
      getDescriptor().getMessageTypes().get(27);
    internal_static_hadoop_yarn_ApplicationACLMapProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ApplicationACLMapProto_descriptor,
        new java.lang.String[] { "AccessType", "Acl", });
    internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor =
      getDescriptor().getMessageTypes().get(28);
    internal_static_hadoop_yarn_YarnClusterMetricsProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_YarnClusterMetricsProto_descriptor,
        new java.lang.String[] { "NumNodeManagers", });
    internal_static_hadoop_yarn_QueueInfoProto_descriptor =
      getDescriptor().getMessageTypes().get(29);
    internal_static_hadoop_yarn_QueueInfoProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_QueueInfoProto_descriptor,
        new java.lang.String[] { "QueueName", "Capacity", "MaximumCapacity", "CurrentCapacity", "State", "ChildQueues", "Applications", "AccessibleNodeLabels", "DefaultNodeLabelExpression", });
    internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor =
      getDescriptor().getMessageTypes().get(30);
    internal_static_hadoop_yarn_QueueUserACLInfoProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_QueueUserACLInfoProto_descriptor,
        new java.lang.String[] { "QueueName", "UserAcls", });
    internal_static_hadoop_yarn_ReservationIdProto_descriptor =
      getDescriptor().getMessageTypes().get(31);
    internal_static_hadoop_yarn_ReservationIdProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationIdProto_descriptor,
        new java.lang.String[] { "Id", "ClusterTimestamp", });
    internal_static_hadoop_yarn_ReservationRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(32);
    internal_static_hadoop_yarn_ReservationRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationRequestProto_descriptor,
        new java.lang.String[] { "Capability", "NumContainers", "Concurrency", "Duration", });
    internal_static_hadoop_yarn_ReservationRequestsProto_descriptor =
      getDescriptor().getMessageTypes().get(33);
    internal_static_hadoop_yarn_ReservationRequestsProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationRequestsProto_descriptor,
        new java.lang.String[] { "ReservationResources", "Interpreter", });
    internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor =
      getDescriptor().getMessageTypes().get(34);
    internal_static_hadoop_yarn_ReservationDefinitionProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ReservationDefinitionProto_descriptor,
        new java.lang.String[] { "ReservationRequests", "Arrival", "Deadline", "ReservationName", });
    internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor =
      getDescriptor().getMessageTypes().get(35);
    internal_static_hadoop_yarn_ContainerLaunchContextProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerLaunchContextProto_descriptor,
        new java.lang.String[] { "LocalResources", "Tokens", "ServiceData", "Environment", "Command", "ApplicationACLs", });
    internal_static_hadoop_yarn_ContainerStatusProto_descriptor =
      getDescriptor().getMessageTypes().get(36);
    internal_static_hadoop_yarn_ContainerStatusProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerStatusProto_descriptor,
        new java.lang.String[] { "ContainerId", "State", "Diagnostics", "ExitStatus", });
    internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor =
      getDescriptor().getMessageTypes().get(37);
    internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerResourceIncreaseRequestProto_descriptor,
        new java.lang.String[] { "ContainerId", "Capability", });
    internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor =
      getDescriptor().getMessageTypes().get(38);
    internal_static_hadoop_yarn_ContainerResourceIncreaseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerResourceIncreaseProto_descriptor,
        new java.lang.String[] { "ContainerId", "Capability", "ContainerToken", });
    internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor =
      getDescriptor().getMessageTypes().get(39);
    internal_static_hadoop_yarn_ContainerResourceDecreaseProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_ContainerResourceDecreaseProto_descriptor,
        new java.lang.String[] { "ContainerId", "Capability", });
    internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor =
      getDescriptor().getMessageTypes().get(40);
    internal_static_hadoop_yarn_StringLocalResourceMapProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StringLocalResourceMapProto_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_hadoop_yarn_StringStringMapProto_descriptor =
      getDescriptor().getMessageTypes().get(41);
    internal_static_hadoop_yarn_StringStringMapProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StringStringMapProto_descriptor,
        new java.lang.String[] { "Key", "Value", });
    internal_static_hadoop_yarn_StringBytesMapProto_descriptor =
      getDescriptor().getMessageTypes().get(42);
    internal_static_hadoop_yarn_StringBytesMapProto_fieldAccessorTable = new
      com.google.protobuf.GeneratedMessageV3.FieldAccessorTable(
        internal_static_hadoop_yarn_StringBytesMapProto_descriptor,
        new java.lang.String[] { "Key", "Value", });
    org.apache.hadoop.security.proto.SecurityProtos.getDescriptor();
  }

  // @@protoc_insertion_point(outer_class_scope)
}
